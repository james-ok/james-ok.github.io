---
title: 并发编程基础
date: 2019-12-28 09:33:20
categories: 并发编程
tags:
- JMM(Java Memory Model)
- Volatile
- 多线程
---
高并发一词是每个程序员都耳熟的一个词，但又有多少人接触过，或者说理解其底层原理呢，似乎这个概念已经成为了评判一个程序员等级的标准。今天我们来探索一下Java并发编程中的奥秘

## 内存模型的基本概念
计算机的每一个操作都是由CPU去执行的，而在执行的过程中，难免会有一些数据的读取和写入操作，这些数据是存在于我们的主存（物理内存）中的，然而主存的输入输出速度和CPU执行执行的速度相比要慢得多，
如果CPU的每次执行都要从主存中的加载写入数据，那么整个系统的性能就被降低了，所以，CPU就内置了高速缓存。
CPU在执行指令之前，会将需要用到的数据提前复制一个副本到高速缓存，然后CPU在运算过程中就可以直接读取和写入高速缓存中的副本数据，最后，运算结束，在退出指令之前将副本数据刷新到主存中。
例如：
```java
i = i + 1;
```
在以上操作中，CPU会首先从主存中读取i的值，并且将其复制到CPU的高速缓存中，如果此时i的值为0，那么高速缓存中就存在一个i=0的变量，再执行i+1，得到结果为1，最后在退出指令之前将i的值1刷新到主存中。
以上操作在单线程中没有任何问题，但多线程就会出现问题，在多核CPU中，每条线程可能会在不同的CPU中运行，各个CPU有独立的高速缓存，此时两个线程同时执行以上操作，线程1在执行指令之前会将i的值0复制到
CPU1的高速缓存中，线程2也同样将i的值0复制到CPU2的高速缓存中，此时两个线程中i的值都为0，然后开始运算，线程1运算完成后得到i的值为1，在其执行完指令退出前，将缓存中的值刷新到主存中；线程2运算完成
后得到i的值也为1，将其刷新到主存中，这个时候主存中i的值为1，并不是我们理想中的2。这就是著名的缓存一致性问题，我们通常称多个线程访问的变量为共享变量。也就是说，一个变量存在于多个CPU的高速缓存中
就会出现缓存一致性问题。
那么为了解决缓存一致性问题，一般有以下两种方案：
* 总线锁：早期的CPU都是通过在总线上加锁#Lock来解决的，因为CPU和其他部件都是通过总线来进行的，在总线上加锁，也就保证了CPU的多个核心串行执行，当线程1执行完再执行线程2。这虽然解决了缓存一致性问题
但是该种方式带来的效率低下是无法避免的。
* 缓存一致性协议：由于总线锁方式的效率低下，所以就出现了缓存一致性协议，最出名的就是Intel的MESI协议，它的核心思想是：当其中一个CPU在写某个变量时，如果发现该变量是共享变量（该变量存在于多个CPU
的高速缓存中），则通知其他CPU将该变量的缓存状态设置为失效，当其他CPU需要读取该变量时，发现该变量缓存是失效状态的，所以会重新从主存中读取。

## 并发编程的三个概念
明白了计算机的内存模型，现在来分析一下我们在日常开发过程中，并发编程需要面临的三个问题：可见性问题、原子性问题、有序性问题

### 可见性
多个线程访问同一个变量，一个线程对该变量的值进行了改变，其他线程能够立即看到该变量的最新数据。
当一个变量存在于多个CPU中的高速缓存中，一个线程对该变量进行了变更，其他线程中任然是该变量变更之前的数据，这个时候就出现了可见性问题。

### 原子性
一个或者多个操作，要么全部执行，执行过程中不会被其他线程打断，要么全部不执行。只有保证了原则性，才能确保得到的结果是正确的。
例如：一个32位变量的赋值分为两个步骤，为低16位赋值，为高16位赋值；当将低16位的值写入成功过后，突然中断，此时有一个线程对该变量进行了访问，这个时候得到的结果是不正确的，这就出现了原子性问题

### 有序性
程序的执行顺序按照代码的编写先后顺序执行。
处理器为了提高程序执行效率，可能会对程序代理进行优化，它不保证每句代理的执行的顺序，但可以保证程序最终执行的结果是一致的。这就是指令重排序，那么它是怎么保证最后结果的一致性的呢？举个例子：
```java
int i = 1; //{1}
int j = 2; //{2}
i = i + 1; //{3}
j = j + i; //{4}
```
以上代码执行顺序可以是：{2} -> {1} -> {3} -> {4}，但是绝对不会出现 {2} -> {1} -> {4} -> {3}，因为步骤{4}依赖于步骤{3}的执行结果。
从上面的例子可以看出，指令重排序并不会影响单线程的执行结果，但是在多线程就不一定了，例如（伪代码）：
```java
//线程1
Object a = new Object();    //{1}
flag = false;               //{2}

//线程2
while(flag) {               //{3}
    Thread.sleep(1000);
}
a.test();                   //{4}
```
从以上例子可以看出，线程1中，代码{1}和代码{2}并没有依赖性，所以根据执行重排序的规则，{1}{2}并不保证执行的顺序性，这个时候如果首先执行的是{2}，那么线程2就会终止循环结束线程，执行{4}，然而这个时候a
还没有完成初始化，这个时候程序就会抛出异常。

### 总结
要想在多线程中程序的正常执行，必须要保证可见性、原子性、有序性。

## Java内存模型（JMM）
前面两节了解了计算机的内存模型，下面来了解一下Java的内存模型。它为我们提供了哪些保证以及提供了哪些方法或者机制来解决以上问题。
JMM主要是为了屏蔽各个硬件平台和操作系统对内存访问的差异，实现JVM在各个平台下能一致的访问内存的功能。他主要定义了程序中变量的访问规则，值得注意的是，JMM为了较好的执行性能，并没有限制CPU使用高速
缓存带来的性能优化，也没有限制编译器对指令的重排序，也就是说，在JMM模型中，任然存在缓存一致性和指令重排序问题。
JMM模型中，所有的变量都存在于主存（可以看成是物理内存）中，每个线程都有自己的工作内存（可以看成是CPU的高速缓存）中，线程对变量的每个操作都是在自己的工作内存中，不能直接对主存进行操作，并且各个线程
不能对其他线程的工作内存中的数据进行操作，如果线程之间需要通信，必须经过主存进行数据传递。

### JMM中主内存和工作内存的交互
CPU高速缓存和物理内存之间交互有MESI缓存一致性协议，那么JMM中的工作内存和主存之间的交互（主存中的数据如何读取到工作内存中的，工作内存中的数据如何写入到主存中的）也有约定，
是通过JVM定义的八种操作来完成的，这八种操作，每一种都是原子性的。这八种操作分别是：
* Lock(锁定):作用于主内存中的变量，一个变量同一时间只能有一个线程锁定，表示这条线程独占这个变量
* UnLock(解锁):作用于主内存，将该条线程锁定的对象解锁，使之其他线程能锁定该变量
* Read(读取):作用于主内存，表示将一个主内存的变量的值传输到线程的工作内存中
* Load(载入):作用于线程的工作内存中，表示把主内存中read操作得到的值放到工作内存的变量副本中
* Use(使用):作用于工作内存，当JVM在执行过程中遇到一个需要使用一个变量的值时会调用该操作
* Assign(赋值):作用于工作内存，当JVM在执行过程中遇到一个需要给一个变量赋值时会调用该操作
* Store(存储):作用于工作内存，把工作内存中的值传输到主内存中
* Write(写入):作用于主内存，将工作内存中Store得到的值放入主内存的变量中
以上八种操作需要遵循以下八种规则：
* 不允许Read/Load或者Store/Write单独出现，也就是说不允许出现主内存读取了变量工作内存不接受或者工作内存回写了变量主内存不接受的情况。
* 不允许线程在自己的工作内存中执行了Assign操作（修改了变量），而不同步（不回写）到主内存的情况
* 工作内存中没有做任何变更的变量不允许会写到主内存
* 变量只能在主内存中产生，工作内存中不允许直接使用一个未被初始化的变量
* 一个变量同一时刻只能被一个线程加锁
* 对变量执行Lock操作，就会清空工作空间中该变量的值
* 不允许对没有执行Lock操作的变量执行UnLock操作
* 对一个操作执行UnLock之前，必须要把工作空间的值回写到主内存中，也就是要执行Store和Write操作

### Volatile修饰的变量的特殊规则
假设：T表示一个线程，V/W分别是Volatile关键字修饰的变量，那么在进行Read/Load/Use/Assign/Store/Write操作的时候都将遵循以下原则
* 线程T对变量V执行Use操作之前，必须先执行Load操作，同时线程T执行了Load操作过后必须执行Use操作；再依照普通变量的规则（Read/Load操作不能单独出现）：则表示Read/Load/Use三个操作必须是连续的。
* 线程T对变量V执行Store操作之前，必须先执行Assign操作，同时线程T执行了Assign操作过后必须执行Store操作；再依照普通变量的规则（Store/Write操作不能单独出现）：则表示Assign/Store/Write三个操作必须连续。
* 假设动作A代表线程T对变量V执行的Use或者Assign操作，动作B代表动作A相关联的Load或者Store操作，动作C代表动作B向关联的Read或者Write操作；类似的，动作D代表线程T对变量W执行的Use或者Assign操作，
动作E代表动作D相关联的Load或者Store操作，动作F代表动作E向关联的Read或者Write操作；如果A先于D，那么C先于F。也就是说，在同一个线程内部，被Volatile修饰的变量不会被指令重排序。
总结：前面了两条规则可以归纳为“**Volatile修饰的变量可以保证对所有线程的可见性**”，第三条可以归纳为“**Volatile修饰的变量禁止指令重排序优化**”

## Volatile关键字
从上一节中可以得知，Volatile修饰关键字具备了以下两层语义
* Volatile修饰的变量可以保证对所有线程的可见性
* Volatile修饰的变量禁止指令重排序优化

### Volatile保证原子性吗？
Volatile关键字保证了变量在多个线程下的可见性，但是否保证原子性呢，我们先通过一个例子来分析
```java
public class VolatileTest {
    private volatile int num = 0;
    public void incr(){
        num++;
    }
    public static void main(String[] args) {
        VolatileTest test = new VolatileTest();
        for (int i=0;i<100;i++) {
            new Thread(()->{
                for (int j=0;j<1000;j++) {
                    test.incr();
                }
            }).start();
        }
        //保证前面的线程都执行完毕
        while (Thread.activeCount()>1){
            Thread.yield();
        }
        System.out.println(test.num);
    }
}
```
以上代码理想的执行结果为1000*100=100000，但其实结果并不一定是100000，它的结果会小于等于100000，为什么呢？我们来一一分析。
我们知道`num++`不是一个原则操作，它包含三个操作 读取x的值，进行加1操作，写入新的值，也就是说这三个操作有可能被分割，我们来假设一下
1. 假设某一时刻num的值为100，线程1对num进行自增操作，首先线程1从主内存中读取了num的值，这个时候读入到线程1工作内存的num的值为100，就在此时线程1被阻塞。
2. 线程2对num进行自增操作，首先线程2从主内存中读取了num的值，这个时候读入到线程2工作内存的值任然为100，然后自增1，然后将101的值刷新到主内存中。
3. 线程1重新获得了CPU时间片，继续执行，在工作内存中的num值任然为100，在100的基础上执行自增，得到101，最后将101刷新到主内存中。
由上面的步骤可以看出，两个线程分别对num的值进行了自增，理论上num的值应该增长了2，但实际上只增长了1。到这里，可能会有疑问，为什么线程2修改了值并且将值刷新到主存中，线程1中工作内存的值没有被失效。
这里需要注意的是缓存失效是在读取之前的，这里线程1已经将数据读取到工作内存中了，所以线程1中的数据任然是有效的。
由以上可以得出结论，Volatile关键字并不能保证原子性。解决办法是，可以在自增的方法上加上`synchronized`关键字，或者在该方法中加入Lock块，或者使用JUC包下的原则操作类。分别如下：
采用synchronized
```java
public synchronized void incr(){
    num++;
}
```
采用Lock
```java
public void incr(){
    try {
        lock.lock();
        num++;
    } finally {
        lock.unlock();
    }
}
```
采用AtomicInteger
```java
private volatile AtomicInteger num = new AtomicInteger(0);
public void incr(){
    num.getAndIncrement();
}
```

### Volatile保证有序性吗？
前面提到了Volatile修饰的变量禁止指令重排序优化，所以Volatile在一定程度上能保证有序性。Volatile禁止指令重排序有两层意思：
* 当程序执行到Volatile变量的读或者写操作时，在其前面操作的更改肯定已经全部执行，且结果对后面的操作可见，在其后面的操作肯定还没有执行。
* 在进行指令优化时，不能将在对Volatile变量访问的语句放到其后面执行，也不能把Volatile变量后面的语句放到前面执行。
说的不太容易理解，举个例子：
```java
int a = 1;              //{1}
int b = 2;              //{2}
volatile int c = 3;     //{3}
int d = 4;              //{4}
int e = 5;              //{5}
```
以上声明了五个变量，只有变量c是Volatile修饰的，那么在进行指令重排序的时候，不会将{3}放到{1}、{2}的前面，也不会将{3}放到{4}、{5}的后面，但是{1}、{2}和{4}、{5}的执行顺序不作任何保证。并且，当执行到
语句{3}的时候，{1}、{2}必须是执行完毕了的，且{1}、{2}的执行结果对{3}、{4}、{5}都是可见的。

### Volatile原理和实现机制
Volatile关键字修饰的变量，在生成的汇编指令中，会多出一个lock前缀指令，lock前缀指令相当于一个内存屏障，该内存屏障有三个功能：
1. 他保证指令重排序时不会将内存屏障之后的指令放到之前，也不会将之前的指令放到内存屏障之后，即在执行内存屏障这块指令时，其之前的指令已经全部执行完成。
2. 强制将修改操作立即更新到主内存
3. 如果是写操作，会导致其他CPU中缓存行失效

## Synchronized关键字
Synchronized关键字可以作用到成员方法上，也可以作用到静态方法上，也可以作用到一个代码块中，当作用在代码块中时，可以指定锁的范围，分别是类对象和实例对象，当作用到实例方法上时，锁的范围是当前实例对象，
也就是this，当作用在静态方法上时，锁的范围为类对象；一个线程能否访问被Synchronized关键字修饰的方法，判断依据在于该方法的锁是否被占用，如果被占用，则不能访问，否则能访问。举个例子：一个类中有多个
Synchronized关键字修饰的实例方法，多个线程同时访问这些实例方法，访问顺序是同步进行的，因为使用的锁都是实例对象this。
>注意：Synchronized关键字是不能被继承的，也就是说父类的`synchronized func()`方法在子类中会变成`func()`

### Synchronized底层原理
在Java中，对象被创建于堆内存中，一个对象实例我们可以分为三个部分：对象头、实例数据、对齐填充。对象头主要包含两个部分信息：自身运行时数据（锁状态标志，线程持有锁）也称Mark Word、类型指针（JVM通过该指
针来只想该对象属于哪个类的）。实例数据用于存放类的属性数据，包括父类的属性数据。对齐填充用于字节对齐，由于JVM中要求对象起始地址必须是8字节的整数倍。
Synchronized的对象锁，其指针指向一个Monitor对象（该对象由C++实现）的起始地址，每个对象都会有个Monitor对象，Monitor对象由ObjectMonitor实现，该对象的C++代码如下：
```C++
//openjdk\hotspot\src\share\vm\runtime\objectMonitor.hpp
ObjectMonitor() {
    _header       = NULL;//markOop对象头
    _count        = 0;
    _waiters      = 0,//等待线程数
    _recursions   = 0;//重入次数
    _object       = NULL;
    _owner        = NULL;//指向获得ObjectMonitor对象的线程或基础锁
    _WaitSet      = NULL;//处于wait状态的线程，会被加入到wait set；
    _WaitSetLock  = 0 ;
    _Responsible  = NULL ;
    _succ         = NULL ;
    _cxq          = NULL ;
    FreeNext      = NULL ;
    _EntryList    = NULL ;//处于等待锁block状态的线程，会被加入到entry set；
    _SpinFreq     = 0 ;
    _SpinClock    = 0 ;
    OwnerIsThread = 0 ;// _owner is (Thread *) vs SP/BasicLock
    _previous_owner_tid = 0;// 监视器前一个拥有者线程的ID
}
```
从以上代码可以看出该对象有两个队列，_WaitSet和_EntryList，其中_WaitSet用来保存等待锁的线程对象，_EntryList用来保存处于阻塞状态的线程。还有一个_owner，该变量用来标志当前获得锁的线程，当多个线程同时
访问一段同步块时，会将其存放到_EntryList中，当一个线程获取了Monitor过后，_owner就会被设置为该线程，同时_count+1，当线程调用wait()方法或者线程顺利执行完毕，就会释放当前持有的Monitor，那么Monitor中的
_owner就会被设置为null，同时_count-1，并且将该线程放到_WaitSet中，等待下一次被唤醒。
>因为这个锁存在于对象头上，这就是为什么Java中每个对象都可以成功锁的原因

下面我们来看一下，加上Synchronized关键字的方法和没有加上Synchronized关键字的同步代码块所生成的字节码
在实例方法上加上Synchronized关键字的字节码
```
public synchronized void incr();
    descriptor: ()V
    flags: ACC_PUBLIC, ACC_SYNCHRONIZED
    Code:
      stack=3, locals=1, args_size=1
         0: aload_0
         1: dup
         2: getfield      #2                  // Field num:I
         5: iconst_1
         6: iadd
         7: putfield      #2                  // Field num:I
        10: return
      LineNumberTable:
        line 11: 0
        line 12: 10
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
            0      11     0  this   Lcom/example/demo/VolatileTest;
```
在方法内存加上Synchronized关键字的同步代码块的字节码
```
public void incr();
    descriptor: ()V
    flags: ACC_PUBLIC
    Code:
      stack=3, locals=3, args_size=1
         0: aload_0
         1: dup
         2: astore_1
         3: monitorenter
         4: aload_0
         5: dup
         6: getfield      #2                  // Field num:I
         9: iconst_1
        10: iadd
        11: putfield      #2                  // Field num:I
        14: aload_1
        15: monitorexit
        16: goto          24
        19: astore_2
        20: aload_1
        21: monitorexit
        22: aload_2
        23: athrow
        24: return
      Exception table:
         from    to  target type
             4    16    19   any
            19    22    19   any
      LineNumberTable:
        line 11: 0
        line 12: 4
        line 13: 14
        line 14: 24
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
            0      25     0  this   Lcom/example/demo/VolatileTest;
      StackMapTable: number_of_entries = 2
        frame_type = 255 /* full_frame */
          offset_delta = 19
          locals = [ class com/example/demo/VolatileTest, class java/lang/Object ]
          stack = [ class java/lang/Throwable ]
        frame_type = 250 /* chop */
          offset_delta = 4
```
从以上可以看出，两种方式生成的字节码是不一样的，一个是生成一个`ACC_SYNCHRONIZED`标志，另外一个是生成三条指令：`monitorenter`/`monitorexit`，其中会生成两条`monitorexit`指令。下面来分析一下这两条执行
会干什么事情：
* monitorenter：在执行该指令时，首先会尝试获取对象锁，也就是上面提到的Monitor对象，如果这个对象没有被锁定或者这个线程已经获得了这个对象锁，那么_owner就会被设置为该线程，同时_count+1。
* monitorexit：该指令与monitorenter指令对应，也就是对象锁的释放，那么_owner就会被设置为null，同时_count-1，并且将线程放入_WaitSet中。
以上字节码中出现了两个monitorexit指令，但其实只会被执行一次，第二个monitorexit指令是在出现异常时执行，也就是说，通过Synchronized关键字加锁，当程序出现异常，会自动释放锁。
再来看`ACC_SYNCHRONIZED`标志，通过Synchronized关键字标记到方法上时，并没有monitorenter和monitorexit指令，原因是JVM通过`ACC_SYNCHRONIZED`标志来标记该方法是一个同步方法，进而执行上面_count+1等等这些操作。

### JVM对Synchronized的优化
锁的状态有四种：无锁状态、偏向锁、轻量级锁、重量级锁，锁可以从偏向锁升级成轻量级锁，也可以从轻量级锁升级成为重量级锁，锁的升级是单向的。
* 自旋锁：线程的阻塞和唤醒需要从用户态切换到内核态，这个操作是很消耗资源的，如果切换的时间间隔非常短，那么我们可以采用循环的方式获得锁，不让出CPU时间片。
* 自适应自旋锁：在JDK1.6以后引入了自适应自旋锁，是在自旋锁上面再一次的优化，表示循环的时间不在固定了，而是由前一次在同一个锁上的自旋时间和锁拥有者的状态来决定。
* 锁消除：JVM在运行时，对一些代码上要求同步执行，但检查出根本不可能存在共享数据竞争的锁进行清除。避免不必要的资源浪费。
* 锁粗化：把多个小锁改成一把大锁
* 偏向锁：锁并不只是有多个线程竞争，还有可能同一个线程多次获得，这个时候就出现了偏向锁，获得锁的线程不需要做任何同步操作，这样就节省了不必要的资源损耗。
* 轻量级锁：如果偏向锁失败，即获得锁的线程和本次竞争锁的线程不是同一个，偏向锁失败以为着不能避免同步操作，这个时候JVM会将偏向锁升级成为轻量级锁。它的本意是没有多线程竞争的情况下。
* 重量级锁：Synchronized是通过Monitor来实现的，而Monitor又是依赖底层操作系统的Mutex Lock来实现的，这个时候操作系统会线程的阻塞和唤醒需要从用户态转换为内核态，这个操作非常耗时，这就是为什么Synchronized
耗时的原因，这种依赖操作系统Mutex Lock来实现的锁也称之为重量级锁。

## J.U.C(java.util.concurrent)

### CAS(Compare And Swap)

### AQS(AbstractQueuedSynchronizer)

## 参考文献

> https://www.cnblogs.com/dolphin0520/p/3920373.html
> https://baijiahao.baidu.com/s?id=1612142459503895416&wfr=spider&for=pc&isFailFlag=1