{"meta":{"title":"James","subtitle":"James","description":"人生苦短，若虚度年华，则短暂的人生就太长了。 —— 莎士比亚","author":"James","url":"http://blog.easyjava.xyz","root":"/"},"pages":[{"title":"categories","date":"2019-09-17T13:17:03.000Z","updated":"2020-02-11T01:07:11.906Z","comments":true,"path":"categories/index.html","permalink":"http://blog.easyjava.xyz/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2019-09-17T13:33:31.000Z","updated":"2020-02-11T01:07:11.905Z","comments":true,"path":"about/index.html","permalink":"http://blog.easyjava.xyz/about/index.html","excerpt":"","text":""},{"title":"friends","date":"2019-09-17T13:34:16.000Z","updated":"2020-02-11T01:07:11.907Z","comments":true,"path":"friends/index.html","permalink":"http://blog.easyjava.xyz/friends/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-09-17T13:16:30.000Z","updated":"2020-02-11T01:07:11.908Z","comments":true,"path":"tags/index.html","permalink":"http://blog.easyjava.xyz/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"ELK实战","slug":"ELK实战","date":"2020-01-09T11:39:35.000Z","updated":"2020-02-11T01:07:11.884Z","comments":true,"path":"2020/01/09/ELK实战/","link":"","permalink":"http://blog.easyjava.xyz/2020/01/09/ELK实战/","excerpt":"","text":"ElasticSearch安装 下载 解压：tar -zxvf elasticsearch-7.5.1-linux-x86_64.tar.gz 进入ElasticSearch目录：cd elasticsearch-7.5.1 启动：sh bin/elasticsearch 启动遇到的问题问题一由于ElasticSearch处于安全性考虑，ElasticSearch禁止使用root用户启动，需要新建一个用户和组，并且将ElasticSearch交给该用户和组管理。 创建组：groupadd elk 创建用户并分配组：useradd -g elk elk 将ElasticSearch分配给新建的用户：chown -R elk:elk ./elasticsearch-7.5.1 切换用户：su elk 启动：sh bin/elasticsearch 问题二ERROR: [3] bootstrap checks failed [1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535] [2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] [3]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured 切换回root用户 编辑vi /etc/security/limits.conf文件，在倒数第二行添加```shell soft nofile 65536 hard nofile 65536``` 编辑vi /etc/sysctl.conf文件，添加vm.max_map_count=655360 执行sysctl -p 问题四ERROR: [1] bootstrap checks failed [1]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured 修改配置文件vim config/elasticsearch.yml，添加内容cluster.initial_master_nodes: [&quot;node-1&quot;] Kibana安装 下载 解压：tar -zxvf kibana-7.5.1-linux-x86_64.tar.gz 将Kibana分配给新建的用户：chown -R elk:elk ./kibana-7.5.1-linux-x86_64 修改配置如下server.port: 5601 server.host: \"192.168.1.6\" elasticsearch.hosts: [\"http://192.168.1.6:9200\"] i18n.locale: \"zh-CN\" LogStash安装 下载 解压：tar -zxvf LogStash-7.5.1.tar.gz 将LogStash分配给新建的用户：chown -R elk:elk ./LogStash-7.5.1 创建LogStash配置文件 启动LogStash：sh sh/logstash -f config/logstash.conf LogStash配置LogStash可以简单分为三个部分，分别是input、filter、output。input用于输入数据来源，filter用于处理数据，output用于数据数据，一般将output输出到ES中。","categories":[{"name":"ELK","slug":"ELK","permalink":"http://blog.easyjava.xyz/categories/ELK/"}],"tags":[{"name":"ElasticSearch","slug":"ElasticSearch","permalink":"http://blog.easyjava.xyz/tags/ElasticSearch/"},{"name":"Kibana","slug":"Kibana","permalink":"http://blog.easyjava.xyz/tags/Kibana/"},{"name":"LogStash","slug":"LogStash","permalink":"http://blog.easyjava.xyz/tags/LogStash/"}]},{"title":"网络编程三剑客BIO/NIO/AIO","slug":"网络编程三剑客BIO-NIO-AIO","date":"2020-01-01T06:20:57.000Z","updated":"2020-02-11T01:07:11.902Z","comments":true,"path":"2020/01/01/网络编程三剑客BIO-NIO-AIO/","link":"","permalink":"http://blog.easyjava.xyz/2020/01/01/网络编程三剑客BIO-NIO-AIO/","excerpt":"","text":"日常工作中离不开IO，但由于Java中IO包下非常繁杂，很多同学认为IO学起来很难，其实只是没有理清IO包下各个类之间的关系 Java IOJava中IO体系大体如下图：从上图可见，Java I/O中主要分为字节操作的输入输出流InputStream/OutputStream和字符输入输出流Reader/Writer，两种类型的区别在于一个是操作字节数据一个是操作字符数据，当然字符数据也可以用字节流进行操作，只是在Java中，为字符数据单独提供一种流为了其操作的便利性。IO操作针对不同的数据来源有以下类型的流： 文件流操作：FileInputStream、FileOutputStream、FileReader、FileWriter 内存流操作：ByteArrayInputStream、ByteArrayOutputStream、CharArrayReader、CharArrayWriter 管道流操作：PipedInputStream、PipedOutputStream、PipedReader、PipedWriter 缓冲流操作：BufferedInputStream、BufferedOutputStream、BufferedReader、BufferedWriter 字节流独有的基本数据类型流操作：DataInputStream、DataOutputStream 字节流独有的对象序列化和反序列化流操作：ObjectInputStream、ObjectOutputStream 字符流独有的转换流操作：InputStreamReader、OutputStreamWriter 输出流独有的打印流操作：PrintStream、PrintWriter 同步异步阻塞非阻塞 同步和异步关注的是消息通信机制，是应用层在调用系统内核时调用的一种方式。 ** 同步调用：同步调用是指当应用程序在调用系统内核请求数据过后，该调用在没有得到结果之前不返回，在系统内核准备好数据过后将数据复制到应用系统过后再返回。 ** 异步调用：异步调用是指当应用系统在调用系统内核过后，该调用立即返回。在内核准备好数据并且复制到应用系统中过后，内核主动通知应用系统并且将其结果返回给应用系统进行处理。 阻塞和非阻塞关注的是经过同步或者异步调用过后返回结果之前应用程序所处的状态。 ** 阻塞是指应用程序在调用了系统内核过后，当前线程被挂起，等待其结果返回过后才会被继续执行。 ** 非阻塞是指应用程序在调用了系统内核过后，立即返回，该调用并不会导致当前线程被挂起。 同步阻塞I/O：当应用程序需要访问内核空间中的数据时，向内核发送一个IO读的调用，如果需要被访问的数据还没有准备好，那么客户端（应用程序）在没有得到结果之前，调用不会返回，客户端线程会被挂起。 同步非阻塞I/O：当应用程序需要访问内核空间中的数据时，应用程序发送一个IO读的调用，内核在收到客户端的调用过后，不管数据是否准备好，都将调用立即返回，如果已经准备好，则返回，如果没有准备好，则告诉客户端没有准备好，这个时候，客户端在收到调用结果过后，根据结果判断是否需要继续询问内核，客户端会通过轮询的方式，直到得到结果。 异步阻塞I/O（I/O多路复用）：也就是经典的Reactor设计模式，多个IO注册到一个线程中，该线程不断的去询问内核这多个IO是否有可操作的IO，如果有，则通知客户端某个IO可操作，然后再进行读写操作，NIO中Selector就是这种规模性。 异步非阻塞I/O：当应用程序需要访问内核空间中的数据时，应用程序向内核发送一个IO读的调用，该调用立即返回，在内核将数据准备好并且复制到用户空间中，通过回调的方式通知应用程序，由于调用会立即返回，所有在等待结果期间，客户端线程并不会被挂起。 BIO示例Server //Ignore package import public class ChatServer { private static final int SERVER_PORT = 8888; public static final String QUIT = \"quit\"; private ServerSocket serverSocket; private Map&lt;Integer, Writer> clientsMap; //线程池 private ExecutorService executorService = Executors.newFixedThreadPool(2); public ChatServer(){ clientsMap = new HashMap&lt;>(); } public void addClient(Socket socket) throws IOException { if(socket!=null){ if(!clientsMap.containsKey(socket.getPort())){ clientsMap.put(socket.getPort(),new BufferedWriter(new OutputStreamWriter(socket.getOutputStream()))); } } } public void removeClient(Integer key){ if(key!=null){ //关闭流 Writer writer = clientsMap.get(key); close(writer); //移除客户端 clientsMap.remove(key); } } private void close(Closeable closeable){ if(closeable!=null){ try { closeable.close(); } catch (IOException e) { e.printStackTrace(); } } } public void forwordMessage(Writer writer,String message) throws IOException { writer.write(message); writer.flush(); } public void start(){ try { serverSocket = new ServerSocket(SERVER_PORT); while (true) { //接受客户端连接 Socket socket = serverSocket.accept(); //使用线程池的方式 executorService.execute(new ProcessHandler(this,socket)); //创建一个新的线程 //new Thread(new ProcessHandler(this,socket)).start(); } } catch (IOException e) { e.printStackTrace(); } } public Map&lt;Integer, Writer> getClientsMap() { return clientsMap; } public static void main(String[] args) { ChatServer chatServer = new ChatServer(); chatServer.start(); } } Client //Ignore package import public class ChatClient { private static final int SERVER_PORT = 8888; private static final String LOCAL_HOST = \"127.0.0.1\"; public static final String QUIT = \"quit\"; private Socket socket; private void close(Closeable closeable){ if(closeable!=null){ try { closeable.close(); } catch (IOException e) { e.printStackTrace(); } } } public void connect(){ BufferedReader consoleReader = null; try { //创建连接 socket = new Socket(LOCAL_HOST,SERVER_PORT); //创建线程用于处理用户发送消息 BufferedReader reader = new BufferedReader(new InputStreamReader(socket.getInputStream())); new Thread(new UserInputHandler(socket)).start(); //主线程读取其他用户发送的消息 while (true) { String msg = reader.readLine(); if (socket.isInputShutdown() || msg == null){ break; } System.out.println(msg); } } catch (IOException e) { e.printStackTrace(); } finally { close(socket); close(consoleReader); } } public static void main(String[] args) { ChatClient chatClient = new ChatClient(); chatClient.connect(); } } 客户端用户输入线程 //Ignore package import public class UserInputHandler implements Runnable { private Socket socket; public UserInputHandler(Socket socket) { this.socket = socket; } @Override public void run() { try { //等待用户输入 BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(socket.getOutputStream())); BufferedReader consoleReader = new BufferedReader(new InputStreamReader(System.in)); while (true) { String msg = consoleReader.readLine(); writer.write(msg + \"\\n\"); writer.flush(); if(ChatClient.QUIT.equals(msg)){ break; } } } catch (IOException e) { e.printStackTrace(); } } } NIO示例Server //Ignore package import public class ChatServer { private static final String QUIT = \"quit\"; private static final int DEFAULT_SERVER_PORT = 8888; private ServerSocketChannel serverSocketChannel; private Selector selector; private static final int BUFFER_LENGTH = 1024; private ByteBuffer rbuf = ByteBuffer.allocate(BUFFER_LENGTH); private ByteBuffer wbuf = ByteBuffer.allocate(BUFFER_LENGTH); private Charset charset = Charset.forName(\"UTF-8\"); public void start(){ try { //初始化 serverSocketChannel = ServerSocketChannel.open(); //配置非阻塞channel serverSocketChannel.configureBlocking(false); //绑定端口 serverSocketChannel.socket().bind(new InetSocketAddress(DEFAULT_SERVER_PORT)); //初始化Selector selector = Selector.open(); //注册 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println(\"启动服务器， 监听端口：\" + DEFAULT_SERVER_PORT + \"...\"); //处理请求 while (true) { //该方法会阻塞，只到有新的时间产生 selector.select(); //拿到当前selector中所有到达的事件 Set&lt;SelectionKey> selectionKeys = selector.selectedKeys(); for (SelectionKey key : selectionKeys) { //处理 handlers(key); } selectionKeys.clear(); } } catch (IOException e) { e.printStackTrace(); } finally { close(); } } /** * 处理客户端连接和读取客户端事件 * @param key * @throws IOException */ private void handlers(SelectionKey key) throws IOException { if(key.isAcceptable()){ //在Accept事件中拿到客户端channel，然后将其注册到selector中 ServerSocketChannel channel = (ServerSocketChannel) key.channel(); SocketChannel socketChannel = channel.accept(); socketChannel.configureBlocking(false); //注册 socketChannel.register(selector,SelectionKey.OP_READ); System.out.println(getClientName(socketChannel) + \"已连接\"); } else if (key.isReadable()) { SocketChannel channel = (SocketChannel)key.channel(); //读取客户端消息 String msg = readMsg(channel); if(msg.isEmpty()){ key.cancel(); selector.wakeup(); } else { System.out.println(getClientName(channel) + \":\" + msg); //转发客户端的消息 forwardMsg(channel,msg); if(isQuit(msg)){ key.cancel(); selector.wakeup(); System.out.println(getClientName(channel) + \"已断开\"); } } } } private String getClientName(SocketChannel client) { return \"客户端[\" + client.socket().getPort() + \"]\"; } /** * 转发消息 * @param socketChannel * @param msg * @throws IOException */ private void forwardMsg(SocketChannel socketChannel, String msg) throws IOException { Set&lt;SelectionKey> keys = selector.keys(); for (SelectionKey key : keys) { Channel channel = key.channel(); if (channel instanceof ServerSocketChannel || channel.equals(socketChannel)) { continue; } else { SocketChannel clientChannel = (SocketChannel) channel; wbuf.clear(); wbuf.put(charset.encode(getClientName(socketChannel) + \":\" + msg)); wbuf.flip(); while (wbuf.hasRemaining()) { clientChannel.write(wbuf); } } } } /** * 读取消息 * @param channel * @return * @throws IOException */ private String readMsg(SocketChannel channel) throws IOException { rbuf.clear(); while (channel.read(rbuf)>0); rbuf.flip(); return String.valueOf(charset.decode(rbuf)); } /** * 判断客户端是否退出 * @param msg * @return */ public boolean isQuit(String msg){ return QUIT.equals(msg); } /** * 关闭 */ private void close(){ try { if (selector!=null) { selector.close(); } } catch (IOException e) { e.printStackTrace(); } } public static void main(String[] args) { ChatServer chatServer = new ChatServer(); chatServer.start(); } } Client //Ignore package import public class ChatClient { private static final String QUIT = \"quit\"; private static final String DEFAULT_SERVER_HOST = \"127.0.0.1\"; private static final int DEFAULT_SERVER_PORT = 8888; private SocketChannel socketChannel; private Selector selector; private static final int BUFFER_LENGTH = 1024; private ByteBuffer rbuf = ByteBuffer.allocate(BUFFER_LENGTH); private ByteBuffer wbuf = ByteBuffer.allocate(BUFFER_LENGTH); private Charset charset = Charset.forName(\"UTF-8\"); /** * 建立连接 */ private void connect(){ try { //初始化 socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); //初始化Selector selector = Selector.open(); //注册 socketChannel.register(selector, SelectionKey.OP_CONNECT); socketChannel.connect(new InetSocketAddress(DEFAULT_SERVER_HOST,DEFAULT_SERVER_PORT)); while (true) { selector.select(); //如果客户端关闭，则跳出循环 if (!selector.isOpen()){ break; } Set&lt;SelectionKey> selectionKeys = selector.selectedKeys(); for (SelectionKey key : selectionKeys) { handlers(key); } selectionKeys.clear(); } } catch (IOException e) { e.printStackTrace(); } finally { close(); } } /** * 处理客户端连接和读取服务器端数据 * @param key * @throws IOException */ private void handlers(SelectionKey key) throws IOException { if(key.isConnectable()){ SocketChannel channel = (SocketChannel)key.channel(); if (channel.isConnectionPending()){ channel.finishConnect(); //创建一个线程去阻塞用户输入 new Thread(new UserInputHandler(this)).start(); } channel.register(selector,SelectionKey.OP_READ); } else if(key.isReadable()) { SocketChannel channel = (SocketChannel)key.channel(); //读取服务器数据 String msg = receive(channel); if(msg.isEmpty()){ close(); } else { System.out.println(msg); } } } /** * 读取服务器消息 * @param channel * @return * @throws IOException */ private String receive(SocketChannel channel) throws IOException { rbuf.clear(); while (channel.read(rbuf)>0); rbuf.flip(); return String.valueOf(charset.decode(rbuf)); } /** * 判断客户端是否退出 * @param msg * @return */ public boolean isQuit(String msg){ return QUIT.equals(msg); } /** * 关闭资源 */ public void close(){ try { if (selector!=null) { selector.close(); } } catch (IOException e) { e.printStackTrace(); } } public static void main(String[] args) { ChatClient chatClient = new ChatClient(); chatClient.connect(); } /** * 发送消息 * @param msg * @throws IOException */ public void send(String msg) throws IOException { if (msg.isEmpty()) { return; } wbuf.clear(); wbuf.put(charset.encode(msg)); wbuf.flip(); while (wbuf.hasRemaining()) { socketChannel.write(wbuf); } if (isQuit(msg)){ close(); } } } UserInputHandler //Ignore package import public class UserInputHandler implements Runnable { private ChatClient chatClient; public UserInputHandler(ChatClient chatClient){ this.chatClient = chatClient; } @Override public void run() { try { BufferedReader reader = new BufferedReader(new InputStreamReader(System.in)); while (true) { String line = reader.readLine(); chatClient.send(line); //判断是否退出客户端 if(chatClient.isQuit(line)){ break; } } } catch (IOException e) { e.printStackTrace(); } } } AIO示例Server //Ignore package import public class ChatServer { public static final int BUFFER_LENGTH = 1024; private static final int DEFAULT_PORT = 8888; private AsynchronousServerSocketChannel asynchronousServerSocketChannel; private CountDownLatch countDownLatch = new CountDownLatch(1); public void start(){ try { //初始化 asynchronousServerSocketChannel = AsynchronousServerSocketChannel.open(); //绑定监听端口 asynchronousServerSocketChannel.bind(new InetSocketAddress(DEFAULT_PORT)); //接受客户端请求 asynchronousServerSocketChannel.accept(null,new AcceptHandler(asynchronousServerSocketChannel)); //阻塞主线程 countDownLatch.await(); } catch (IOException e) { e.printStackTrace(); } catch (InterruptedException e) { e.printStackTrace(); } finally { close(asynchronousServerSocketChannel); } } private void close(Closeable closeable) { try { if(closeable!=null){ closeable.close(); } } catch (IOException e) { e.printStackTrace(); } } public static void main(String[] args) { ChatServer chatServer = new ChatServer(); chatServer.start(); } } 接受用户请求Handler //Ignore package import public class AcceptHandler implements CompletionHandler&lt;AsynchronousSocketChannel,Object> { private AsynchronousServerSocketChannel asynchronousServerSocketChannel; public AcceptHandler(AsynchronousServerSocketChannel asynchronousServerSocketChannel) { this.asynchronousServerSocketChannel = asynchronousServerSocketChannel; } @Override public void completed(AsynchronousSocketChannel asynchronousSocketChannel, Object attachment) { //继续接受客户端请求 asynchronousServerSocketChannel.accept(null,this); //读取数据 ByteBuffer buffer = ByteBuffer.allocate(ChatServer.BUFFER_LENGTH); buffer.clear(); Map&lt;String,Object> info = new HashMap&lt;>(); info.put(\"type\",\"read\"); info.put(\"buffer\",buffer); asynchronousSocketChannel.read(buffer,info,new ClientHandler(asynchronousSocketChannel)); } @Override public void failed(Throwable exc, Object attachment) { exc.printStackTrace(); } } 处理读写请求Handler //Ignore package import public class ClientHandler implements CompletionHandler&lt;Integer,Object> { private AsynchronousSocketChannel asynchronousSocketChannel; public ClientHandler(AsynchronousSocketChannel asynchronousSocketChannel) { this.asynchronousSocketChannel = asynchronousSocketChannel; } @Override public void completed(Integer result, Object attachment) { Map&lt;String,Object> info = (Map&lt;String, Object>) attachment; String type = (String) info.get(\"type\"); if(\"read\".equals(type)){ ByteBuffer buffer = (ByteBuffer) info.get(\"buffer\"); buffer.flip(); //回写到客户端 info.put(\"type\",\"write\"); asynchronousSocketChannel.write(buffer,info,this); } else if(\"write\".equals(type)){ ByteBuffer buffer = ByteBuffer.allocate(ChatServer.BUFFER_LENGTH); info.put(\"type\",\"read\"); info.put(\"buffer\",buffer); asynchronousSocketChannel.read(buffer,info,this); } } @Override public void failed(Throwable exc, Object attachment) { exc.printStackTrace(); } } 客户端 //Ignore package import public class ChatClient { public static final int BUFFER_LENGTH = 1024; public static final String DEFAULT_HOST = \"127.0.0.1\"; public static final int DEFAULT_PORT = 8888; private AsynchronousSocketChannel asynchronousSocketChannel; public void connect(){ try { asynchronousSocketChannel = AsynchronousSocketChannel.open(); Future&lt;Void> connect = asynchronousSocketChannel.connect(new InetSocketAddress(DEFAULT_HOST, DEFAULT_PORT)); //等待连接返回 connect.get(); BufferedReader reader = new BufferedReader(new InputStreamReader(System.in)); while (true) { String line = reader.readLine(); ByteBuffer buffer = ByteBuffer.allocate(BUFFER_LENGTH); buffer.put(line.getBytes()); buffer.flip(); Future&lt;Integer> write = asynchronousSocketChannel.write(buffer); write.get(); buffer.clear(); Future&lt;Integer> read = asynchronousSocketChannel.read(buffer); read.get(); buffer.flip(); System.out.println(new String(buffer.array())); } } catch (IOException e) { e.printStackTrace(); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } finally { close(asynchronousSocketChannel); } } private void close(Closeable closeable) { try { if(closeable!=null){ closeable.close(); } } catch (IOException e) { e.printStackTrace(); } } public static void main(String[] args) { ChatClient chatClient = new ChatClient(); chatClient.connect(); } }","categories":[{"name":"网络编程","slug":"网络编程","permalink":"http://blog.easyjava.xyz/categories/网络编程/"}],"tags":[{"name":"BIO","slug":"BIO","permalink":"http://blog.easyjava.xyz/tags/BIO/"},{"name":"NIO","slug":"NIO","permalink":"http://blog.easyjava.xyz/tags/NIO/"},{"name":"AIO","slug":"AIO","permalink":"http://blog.easyjava.xyz/tags/AIO/"}]},{"title":"并发编程基础","slug":"并发编程基础","date":"2019-12-28T01:33:20.000Z","updated":"2020-02-13T02:06:58.338Z","comments":true,"path":"2019/12/28/并发编程基础/","link":"","permalink":"http://blog.easyjava.xyz/2019/12/28/并发编程基础/","excerpt":"","text":"高并发一词是每个程序员都耳熟的一个词，但又有多少人接触过，或者说理解其底层原理呢，似乎这个概念已经成为了评判一个程序员等级的标准。今天我们来探索一下Java并发编程中的奥秘 内存模型的基本概念计算机的每一个操作都是由CPU去执行的，而在执行的过程中，难免会有一些数据的读取和写入操作，这些数据是存在于我们的主存（物理内存）中的，然而主存的输入输出速度和CPU执行执行的速度相比要慢得多，如果CPU的每次执行都要从主存中的加载写入数据，那么整个系统的性能就被降低了，所以，CPU就内置了高速缓存。CPU在执行指令之前，会将需要用到的数据提前复制一个副本到高速缓存，然后CPU在运算过程中就可以直接读取和写入高速缓存中的副本数据，最后，运算结束，在退出指令之前将副本数据刷新到主存中。例如： i = i + 1; 在以上操作中，CPU会首先从主存中读取i的值，并且将其复制到CPU的高速缓存中，如果此时i的值为0，那么高速缓存中就存在一个i=0的变量，再执行i+1，得到结果为1，最后在退出指令之前将i的值1刷新到主存中。以上操作在单线程中没有任何问题，但多线程就会出现问题，在多核CPU中，每条线程可能会在不同的CPU中运行，各个CPU有独立的高速缓存，此时两个线程同时执行以上操作，线程1在执行指令之前会将i的值0复制到CPU1的高速缓存中，线程2也同样将i的值0复制到CPU2的高速缓存中，此时两个线程中i的值都为0，然后开始运算，线程1运算完成后得到i的值为1，在其执行完指令退出前，将缓存中的值刷新到主存中；线程2运算完成后得到i的值也为1，将其刷新到主存中，这个时候主存中i的值为1，并不是我们理想中的2。这就是著名的缓存一致性问题，我们通常称多个线程访问的变量为共享变量。也就是说，一个变量存在于多个CPU的高速缓存中就会出现缓存一致性问题。那么为了解决缓存一致性问题，一般有以下两种方案： 总线锁：早期的CPU都是通过在总线上加锁#Lock来解决的，因为CPU和其他部件都是通过总线来进行的，在总线上加锁，也就保证了CPU的多个核心串行执行，当线程1执行完再执行线程2。这虽然解决了缓存一致性问题但是该种方式带来的效率低下是无法避免的。 缓存一致性协议：由于总线锁方式的效率低下，所以就出现了缓存一致性协议，最出名的就是Intel的MESI协议，它的核心思想是：当其中一个CPU在写某个变量时，如果发现该变量是共享变量（该变量存在于多个CPU的高速缓存中），则通知其他CPU将该变量的缓存状态设置为失效，当其他CPU需要读取该变量时，发现该变量缓存是失效状态的，所以会重新从主存中读取。 并发编程的三个概念明白了计算机的内存模型，现在来分析一下我们在日常开发过程中，并发编程需要面临的三个问题：可见性问题、原子性问题、有序性问题 可见性多个线程访问同一个变量，一个线程对该变量的值进行了改变，其他线程能够立即看到该变量的最新数据。当一个变量存在于多个CPU中的高速缓存中，一个线程对该变量进行了变更，其他线程中任然是该变量变更之前的数据，这个时候就出现了可见性问题。 原子性一个或者多个操作，要么全部执行，执行过程中不会被其他线程打断，要么全部不执行。只有保证了原则性，才能确保得到的结果是正确的。例如：一个32位变量的赋值分为两个步骤，为低16位赋值，为高16位赋值；当将低16位的值写入成功过后，突然中断，此时有一个线程对该变量进行了访问，这个时候得到的结果是不正确的，这就出现了原子性问题 有序性程序的执行顺序按照代码的编写先后顺序执行。处理器为了提高程序执行效率，可能会对程序代理进行优化，它不保证每句代理的执行的顺序，但可以保证程序最终执行的结果是一致的。这就是指令重排序，那么它是怎么保证最后结果的一致性的呢？举个例子： int i = 1; //{1} int j = 2; //{2} i = i + 1; //{3} j = j + i; //{4} 以上代码执行顺序可以是：{2} -&gt; {1} -&gt; {3} -&gt; {4}，但是绝对不会出现 {2} -&gt; {1} -&gt; {4} -&gt; {3}，因为步骤{4}依赖于步骤{3}的执行结果。从上面的例子可以看出，指令重排序并不会影响单线程的执行结果，但是在多线程就不一定了，例如（伪代码）： //线程1 Object a = new Object(); //{1} flag = false; //{2} //线程2 while(flag) { //{3} Thread.sleep(1000); } a.test(); //{4} 从以上例子可以看出，线程1中，代码{1}和代码{2}并没有依赖性，所以根据执行重排序的规则，{1}{2}并不保证执行的顺序性，这个时候如果首先执行的是{2}，那么线程2就会终止循环结束线程，执行{4}，然而这个时候a还没有完成初始化，这个时候程序就会抛出异常。 总结要想在多线程中程序的正常执行，必须要保证可见性、原子性、有序性。 Java内存模型（JMM）前面两节了解了计算机的内存模型，下面来了解一下Java的内存模型。它为我们提供了哪些保证以及提供了哪些方法或者机制来解决以上问题。JMM主要是为了屏蔽各个硬件平台和操作系统对内存访问的差异，实现JVM在各个平台下能一致的访问内存的功能。他主要定义了程序中变量的访问规则，值得注意的是，JMM为了较好的执行性能，并没有限制CPU使用高速缓存带来的性能优化，也没有限制编译器对指令的重排序，也就是说，在JMM模型中，任然存在缓存一致性和指令重排序问题。JMM模型中，所有的变量都存在于主存（可以看成是物理内存）中，每个线程都有自己的工作内存（可以看成是CPU的高速缓存）中，线程对变量的每个操作都是在自己的工作内存中，不能直接对主存进行操作，并且各个线程不能对其他线程的工作内存中的数据进行操作，如果线程之间需要通信，必须经过主存进行数据传递。 JMM中主内存和工作内存的交互CPU高速缓存和物理内存之间交互有MESI缓存一致性协议，那么JMM中的工作内存和主存之间的交互（主存中的数据如何读取到工作内存中的，工作内存中的数据如何写入到主存中的）也有约定，是通过JVM定义的八种操作来完成的，这八种操作，每一种都是原子性的。这八种操作分别是： Lock(锁定):作用于主内存中的变量，一个变量同一时间只能有一个线程锁定，表示这条线程独占这个变量 UnLock(解锁):作用于主内存，将该条线程锁定的对象解锁，使之其他线程能锁定该变量 Read(读取):作用于主内存，表示将一个主内存的变量的值传输到线程的工作内存中 Load(载入):作用于线程的工作内存中，表示把主内存中read操作得到的值放到工作内存的变量副本中 Use(使用):作用于工作内存，当JVM在执行过程中遇到一个需要使用一个变量的值时会调用该操作 Assign(赋值):作用于工作内存，当JVM在执行过程中遇到一个需要给一个变量赋值时会调用该操作 Store(存储):作用于工作内存，把工作内存中的值传输到主内存中 Write(写入):作用于主内存，将工作内存中Store得到的值放入主内存的变量中以上八种操作需要遵循以下八种规则： 不允许Read/Load或者Store/Write单独出现，也就是说不允许出现主内存读取了变量工作内存不接受或者工作内存回写了变量主内存不接受的情况。 不允许线程在自己的工作内存中执行了Assign操作（修改了变量），而不同步（不回写）到主内存的情况 工作内存中没有做任何变更的变量不允许会写到主内存 变量只能在主内存中产生，工作内存中不允许直接使用一个未被初始化的变量 一个变量同一时刻只能被一个线程加锁 对变量执行Lock操作，就会清空工作空间中该变量的值 不允许对没有执行Lock操作的变量执行UnLock操作 对一个操作执行UnLock之前，必须要把工作空间的值回写到主内存中，也就是要执行Store和Write操作 Volatile修饰的变量的特殊规则假设：T表示一个线程，V/W分别是Volatile关键字修饰的变量，那么在进行Read/Load/Use/Assign/Store/Write操作的时候都将遵循以下原则 线程T对变量V执行Use操作之前，必须先执行Load操作，同时线程T执行了Load操作过后必须执行Use操作；再依照普通变量的规则（Read/Load操作不能单独出现）：则表示Read/Load/Use三个操作必须是连续的。 线程T对变量V执行Store操作之前，必须先执行Assign操作，同时线程T执行了Assign操作过后必须执行Store操作；再依照普通变量的规则（Store/Write操作不能单独出现）：则表示Assign/Store/Write三个操作必须连续。 假设动作A代表线程T对变量V执行的Use或者Assign操作，动作B代表动作A相关联的Load或者Store操作，动作C代表动作B向关联的Read或者Write操作；类似的，动作D代表线程T对变量W执行的Use或者Assign操作，动作E代表动作D相关联的Load或者Store操作，动作F代表动作E向关联的Read或者Write操作；如果A先于D，那么C先于F。也就是说，在同一个线程内部，被Volatile修饰的变量不会被指令重排序。总结：前面了两条规则可以归纳为“Volatile修饰的变量可以保证对所有线程的可见性”，第三条可以归纳为“Volatile修饰的变量禁止指令重排序优化” Volatile关键字从上一节中可以得知，Volatile修饰关键字具备了以下两层语义 Volatile修饰的变量可以保证对所有线程的可见性 Volatile修饰的变量禁止指令重排序优化 Volatile保证原子性吗？Volatile关键字保证了变量在多个线程下的可见性，但是否保证原子性呢，我们先通过一个例子来分析 public class VolatileTest { private volatile int num = 0; public void incr(){ num++; } public static void main(String[] args) { VolatileTest test = new VolatileTest(); for (int i=0;i&lt;100;i++) { new Thread(()->{ for (int j=0;j&lt;1000;j++) { test.incr(); } }).start(); } //保证前面的线程都执行完毕 while (Thread.activeCount()>1){ Thread.yield(); } System.out.println(test.num); } } 以上代码理想的执行结果为1000*100=100000，但其实结果并不一定是100000，它的结果会小于等于100000，为什么呢？我们来一一分析。我们知道num++不是一个原则操作，它包含三个操作 读取x的值，进行加1操作，写入新的值，也就是说这三个操作有可能被分割，我们来假设一下 假设某一时刻num的值为100，线程1对num进行自增操作，首先线程1从主内存中读取了num的值，这个时候读入到线程1工作内存的num的值为100，就在此时线程1被阻塞。 线程2对num进行自增操作，首先线程2从主内存中读取了num的值，这个时候读入到线程2工作内存的值任然为100，然后自增1，然后将101的值刷新到主内存中。 线程1重新获得了CPU时间片，继续执行，在工作内存中的num值任然为100，在100的基础上执行自增，得到101，最后将101刷新到主内存中。由上面的步骤可以看出，两个线程分别对num的值进行了自增，理论上num的值应该增长了2，但实际上只增长了1。到这里，可能会有疑问，为什么线程2修改了值并且将值刷新到主存中，线程1中工作内存的值没有被失效。这里需要注意的是缓存失效是在读取之前的，这里线程1已经将数据读取到工作内存中了，所以线程1中的数据任然是有效的。由以上可以得出结论，Volatile关键字并不能保证原子性。解决办法是，可以在自增的方法上加上synchronized关键字，或者在该方法中加入Lock块，或者使用JUC包下的原则操作类。分别如下：采用synchronizedpublic synchronized void incr(){ num++; } 采用Lockpublic void incr(){ try { lock.lock(); num++; } finally { lock.unlock(); } } 采用AtomicIntegerprivate volatile AtomicInteger num = new AtomicInteger(0); public void incr(){ num.getAndIncrement(); } Volatile保证有序性吗？前面提到了Volatile修饰的变量禁止指令重排序优化，所以Volatile在一定程度上能保证有序性。Volatile禁止指令重排序有两层意思： 当程序执行到Volatile变量的读或者写操作时，在其前面操作的更改肯定已经全部执行，且结果对后面的操作可见，在其后面的操作肯定还没有执行。 在进行指令优化时，不能将在对Volatile变量访问的语句放到其后面执行，也不能把Volatile变量后面的语句放到前面执行。说的不太容易理解，举个例子：int a = 1; //{1} int b = 2; //{2} volatile int c = 3; //{3} int d = 4; //{4} int e = 5; //{5} 以上声明了五个变量，只有变量c是Volatile修饰的，那么在进行指令重排序的时候，不会将{3}放到{1}、{2}的前面，也不会将{3}放到{4}、{5}的后面，但是{1}、{2}和{4}、{5}的执行顺序不作任何保证。并且，当执行到语句{3}的时候，{1}、{2}必须是执行完毕了的，且{1}、{2}的执行结果对{3}、{4}、{5}都是可见的。 Volatile原理和实现机制Volatile关键字修饰的变量，在生成的汇编指令中，会多出一个lock前缀指令，lock前缀指令相当于一个内存屏障，该内存屏障有三个功能： 他保证指令重排序时不会将内存屏障之后的指令放到之前，也不会将之前的指令放到内存屏障之后，即在执行内存屏障这块指令时，其之前的指令已经全部执行完成。 强制将修改操作立即更新到主内存 如果是写操作，会导致其他CPU中缓存行失效 Synchronized关键字Synchronized关键字可以作用到成员方法上，也可以作用到静态方法上，也可以作用到一个代码块中，当作用在代码块中时，可以指定锁的范围，分别是类对象和实例对象，当作用到实例方法上时，锁的范围是当前实例对象，也就是this，当作用在静态方法上时，锁的范围为类对象；一个线程能否访问被Synchronized关键字修饰的方法，判断依据在于该方法的锁是否被占用，如果被占用，则不能访问，否则能访问。举个例子：一个类中有多个Synchronized关键字修饰的实例方法，多个线程同时访问这些实例方法，访问顺序是同步进行的，因为使用的锁都是实例对象this。 注意：Synchronized关键字是不能被继承的，也就是说父类的synchronized func()方法在子类中会变成func() Synchronized底层原理在Java中，对象被创建于堆内存中，一个对象实例我们可以分为三个部分：对象头、实例数据、对齐填充。对象头主要包含两个部分信息：自身运行时数据（锁状态标志，线程持有锁）也称Mark Word、类型指针（JVM通过该指针来只想该对象属于哪个类的）。实例数据用于存放类的属性数据，包括父类的属性数据。对齐填充用于字节对齐，由于JVM中要求对象起始地址必须是8字节的整数倍。Synchronized的对象锁，其指针指向一个Monitor对象（该对象由C++实现）的起始地址，每个对象都会有个Monitor对象，Monitor对象由ObjectMonitor实现，该对象的C++代码如下： //openjdk\\hotspot\\src\\share\\vm\\runtime\\objectMonitor.hpp ObjectMonitor() { _header = NULL;//markOop对象头 _count = 0; _waiters = 0,//等待线程数 _recursions = 0;//重入次数 _object = NULL; _owner = NULL;//指向获得ObjectMonitor对象的线程或基础锁 _WaitSet = NULL;//处于wait状态的线程，会被加入到wait set； _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ;//处于等待锁block状态的线程，会被加入到entry set； _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ;// _owner is (Thread *) vs SP/BasicLock _previous_owner_tid = 0;// 监视器前一个拥有者线程的ID } 从以上代码可以看出该对象有两个队列，_WaitSet和_EntryList，其中_WaitSet用来保存等待锁的线程对象，_EntryList用来保存处于阻塞状态的线程。还有一个_owner，该变量用来标志当前获得锁的线程，当多个线程同时访问一段同步块时，会将其存放到_EntryList中，当一个线程获取了Monitor过后，_owner就会被设置为该线程，同时_count+1，当线程调用wait()方法或者线程顺利执行完毕，就会释放当前持有的Monitor，那么Monitor中的_owner就会被设置为null，同时_count-1，并且将该线程放到_WaitSet中，等待下一次被唤醒。 因为这个锁存在于对象头上，这就是为什么Java中每个对象都可以成功锁的原因 下面我们来看一下，加上Synchronized关键字的方法和没有加上Synchronized关键字的同步代码块所生成的字节码在实例方法上加上Synchronized关键字的字节码 public synchronized void incr(); descriptor: ()V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #2 // Field num:I 5: iconst_1 6: iadd 7: putfield #2 // Field num:I 10: return LineNumberTable: line 11: 0 line 12: 10 LocalVariableTable: Start Length Slot Name Signature 0 11 0 this Lcom/example/demo/VolatileTest;在方法内存加上Synchronized关键字的同步代码块的字节码 public void incr(); descriptor: ()V flags: ACC_PUBLIC Code: stack=3, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter 4: aload_0 5: dup 6: getfield #2 // Field num:I 9: iconst_1 10: iadd 11: putfield #2 // Field num:I 14: aload_1 15: monitorexit 16: goto 24 19: astore_2 20: aload_1 21: monitorexit 22: aload_2 23: athrow 24: return Exception table: from to target type 4 16 19 any 19 22 19 any LineNumberTable: line 11: 0 line 12: 4 line 13: 14 line 14: 24 LocalVariableTable: Start Length Slot Name Signature 0 25 0 this Lcom/example/demo/VolatileTest; StackMapTable: number_of_entries = 2 frame_type = 255 /* full_frame */ offset_delta = 19 locals = [ class com/example/demo/VolatileTest, class java/lang/Object ] stack = [ class java/lang/Throwable ] frame_type = 250 /* chop */ offset_delta = 4从以上可以看出，两种方式生成的字节码是不一样的，一个是生成一个ACC_SYNCHRONIZED标志，另外一个是生成三条指令：monitorenter/monitorexit，其中会生成两条monitorexit指令。下面来分析一下这两条执行会干什么事情： monitorenter：在执行该指令时，首先会尝试获取对象锁，也就是上面提到的Monitor对象，如果这个对象没有被锁定或者这个线程已经获得了这个对象锁，那么_owner就会被设置为该线程，同时_count+1。 monitorexit：该指令与monitorenter指令对应，也就是对象锁的释放，那么_owner就会被设置为null，同时_count-1，并且将线程放入_WaitSet中。以上字节码中出现了两个monitorexit指令，但其实只会被执行一次，第二个monitorexit指令是在出现异常时执行，也就是说，通过Synchronized关键字加锁，当程序出现异常，会自动释放锁。再来看ACC_SYNCHRONIZED标志，通过Synchronized关键字标记到方法上时，并没有monitorenter和monitorexit指令，原因是JVM通过ACC_SYNCHRONIZED标志来标记该方法是一个同步方法，进而执行上面_count+1等等这些操作。 JVM对Synchronized的优化锁的状态有四种：无锁状态、偏向锁、轻量级锁、重量级锁，锁可以从偏向锁升级成轻量级锁，也可以从轻量级锁升级成为重量级锁，锁的升级是单向的。 自旋锁：线程的阻塞和唤醒需要从用户态切换到内核态，这个操作是很消耗资源的，如果切换的时间间隔非常短，那么我们可以采用循环的方式获得锁，不让出CPU时间片。 自适应自旋锁：在JDK1.6以后引入了自适应自旋锁，是在自旋锁上面再一次的优化，表示循环的时间不在固定了，而是由前一次在同一个锁上的自旋时间和锁拥有者的状态来决定。 锁消除：JVM在运行时，对一些代码上要求同步执行，但检查出根本不可能存在共享数据竞争的锁进行清除。避免不必要的资源浪费。 锁粗化：把多个小锁改成一把大锁 偏向锁：锁并不只是有多个线程竞争，还有可能同一个线程多次获得，这个时候就出现了偏向锁，获得锁的线程不需要做任何同步操作，这样就节省了不必要的资源损耗。 轻量级锁：如果偏向锁失败，即获得锁的线程和本次竞争锁的线程不是同一个，偏向锁失败以为着不能避免同步操作，这个时候JVM会将偏向锁升级成为轻量级锁。它的本意是没有多线程竞争的情况下。 重量级锁：Synchronized是通过Monitor来实现的，而Monitor又是依赖底层操作系统的Mutex Lock来实现的，这个时候操作系统会线程的阻塞和唤醒需要从用户态转换为内核态，这个操作非常耗时，这就是为什么Synchronized耗时的原因，这种依赖操作系统Mutex Lock来实现的锁也称之为重量级锁。 J.U.C(java.util.concurrent)Java并发的分类并发由一下三个方面组成 并发安全：并发安全也可以分为三个部分，互斥同步，非互斥同步，无同步方案 并发性能：线程池 线程协作：并发工具 CAS(Compare And Swap)AQS(AbstractQueuedSynchronizer)参考文献 https://www.cnblogs.com/dolphin0520/p/3920373.htmlhttps://baijiahao.baidu.com/s?id=1612142459503895416&amp;wfr=spider&amp;for=pc&amp;isFailFlag=1","categories":[{"name":"并发编程","slug":"并发编程","permalink":"http://blog.easyjava.xyz/categories/并发编程/"}],"tags":[{"name":"JMM(Java Memory Model)","slug":"JMM-Java-Memory-Model","permalink":"http://blog.easyjava.xyz/tags/JMM-Java-Memory-Model/"},{"name":"Volatile","slug":"Volatile","permalink":"http://blog.easyjava.xyz/tags/Volatile/"},{"name":"多线程","slug":"多线程","permalink":"http://blog.easyjava.xyz/tags/多线程/"}]},{"title":"Nginx入门及实战","slug":"Nginx入门及实战","date":"2019-12-27T02:47:43.000Z","updated":"2020-02-11T01:07:11.893Z","comments":true,"path":"2019/12/27/Nginx入门及实战/","link":"","permalink":"http://blog.easyjava.xyz/2019/12/27/Nginx入门及实战/","excerpt":"","text":"一说到Nginx，想到的就是反向代理，负载均衡，动静分离，这些都只是Nginx的一些模块，也是我们经常在生产环境中使用到的主要模块，其实Nginx远远不止这些模块，他还可以做RTMP推拉流服务器，可以做直播服务器等等，还可以自定义扩展。 Nginx安装 下载 解压：tar -zxvf nginx-1.17.7.tar.gz ./configure {--prefix} {--with-xxx-module}:–prefix是可选的，表示指定编译安装目录，默认/usr/local/nginx。以及安装其他模块使用–with-xxx-module make &amp;&amp; make install 启动和停止：./nginx/./nginx -s stop 安装问题解决 问题一[root@localhost nginx-1.16.1]# ./configure checking for OS + Linux 3.10.0-514.el7.x86_64 x86_64 checking for C compiler ... not found ./configure: error: C compiler cc is not found 需要安装gcc，`yum -y install gcc` * 问题二 ```shell ./configure: error: the HTTP rewrite module requires the PCRE library. You can either disable the module by using --without-http_rewrite_module option, or install the PCRE library into the system, or build the PCRE library statically from the source with nginx by using --with-pcre=&lt;path&gt; option.安装yum install pcre-devel 问题三./configure: error: the HTTP gzip module requires the zlib library. You can either disable the module by using --without-http_gzip_module option, or install the zlib library into the system, or build the zlib library statically from the source with nginx by using --with-zlib= option. 安装yum install zlib-devel 反向代理Nginx反向代理既可以是IP+PORT也可以是域名，只需要配置proxy_pass就可以实现反向代理。配置如下： server { listen 80; server_name localhost; location / { proxy_pass http://192.168.1.1:8080; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } }proxy_set_header：表示设置HTTP Header信息，因为在后端Servlet容器中无法获取客户端的真实IP，只能获取反向代理的IP，所以我们可以在反向代理这一层做一次转发，将客户端的真实IP转发到Servlet容器。 负载均衡负载均衡是通过一定的算法分配策略将请求分摊到集群中的各个节点上，使得各个节点并行处理客户端请求，以及故障转移等功能，来达到高可用、高性能的一种手段。在Nginx中，配置负载均衡非常简单，直接将反向代理从原来的IP+PORT或者域名代理到upstream上就可以实现负载均衡，配置如下： upstream tomcat { server 192.168.11.161:8080 max_fails=2 fail_timeout=60s; server 192.168.11.159:8080; } server { listen 80; server_name localhost; location / { proxy_pass http://tomcat; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout http_500 http_503; proxy_connect_timeout 60s; proxy_send_timeout 60s; proxy_read_timeout 60s; add_header &#39;Access-Control-Allow-Origin&#39; &#39;*&#39;; add_header &#39;Access-Control-Allow-Methods&#39; &#39;GET,POST,DELETE&#39;; add_header &#39;Aceess-Control-Allow-Header&#39; &#39;Content-Type,*&#39;; } }如上，配置一个upstream名为tomcat，将proxy_pass http://tomcat;即可实现负载均衡。proxy_next_upstream：表示当请求的一台服务器出错时，自动切换到下一个节点继续执行客户端的请求，错误类型可以指定，例如:error timeout http_500 http_503，表示错误、超时、500、503proxy_connect_timeout：用于设置Nginx于upstream server连接的超时时间，当超出该时间范围，则会报错。proxy_send_timeout：向后端写数据的超时时间，两次写操作的时间间隔超过该值，连接会被关闭。proxy_read_timeout：从后端服务器读取数据的超时时间，两次读取操作的时间间隔超过该值，连接会被关闭，如果后端处理逻辑较复杂导致请求响应很慢时可以将此值设置大一些。 负载均衡策略（算法）Nginx有三种负载均衡算法，分别是： 轮询算法（默认）：将客户端请求轮流分配到集群中的节点，当有节点出现宕机时，Nginx会自动将其剔除。 ip_hash：根据客户端请求的IP进行hash得到一个值，往后该客户端会永远访问同一个节点，除非客户端更换IP 权重轮询：在轮询的基础上添加权重。 动静分离我们可以吧静态资源放到Nginx上，把动态资源放到后端服务器上，这样就可以减少后端服务器的请求，减小了服务器的请求压力。实现动静分离配置如下： server { #... location / { #... } location ~ .*\\.(js|css|png|svg|ico|jpg)$ { root static-resource; expires 1d; } }把指定后缀的请求转发到指定静态文件目录中就实现了动静分离，其中static-resource就是静态文件的存放路径。动静分离过后我们可以对静态资源做一些特定的优化，例如： 静态资源缓存：我们可以通过expires 1d;来指定资源在客户端缓存的过期时间。 压缩：静态资源包含很多html、css、js、图片、视频等文件，这些文件本身就很大，客户端请求要返回这些资源，可能就会影响整个系统的渲染速度。所以我们可以使用压缩，将资源压缩过后再传输到客户端，在浏览器中解压渲染。配置如下:http { gzip on; #开启压缩功能 gzip_min_length 5k; #达到最小压缩的条件 gzip_comp_level 3; #压缩级别，该值越大压缩率越高，性能损耗越大，范围[1-9] gzip_types application/javascript image/jpeg image/svg+xml; #压缩的资源mine-type gzip_buffers 4 32k; #设置压缩申请内存的大小，作用是按照指定大小的倍数申请内存，4 32k表示按照原始数据大小以32k单位的4倍申请内存 gzip_vary on; #是否传输压缩标志给客户端，避免有的浏览器不支持压缩而造成的资源浪费。 } 防盗链有的时候我们并不希望静态资源被其他网站使用，例如：图片、视频，那么为这些资源配置防盗链是非常有必要的。防盗链的原理是判断HTTP请求头中的refer，如果refer的值不在我们允许的范围内则进行其他操作。配置如下： location ~ .*\\.(js|css|png|svg|ico|jpg)$ { valid_referers none blocked 192.168.1.1 easyjava.xyz; if ($invalid_referer) { return 404; } root static-resource; expires 1d; }跨域访问如果客户端和服务器端的协议、域名、端口、子域名不同，那么所有的请求都是跨域的，是浏览器对跨域资源访问的一种限制手段。我们可以在应用层面去解决跨域问题，也可以在代理层面（Nginx）来解决跨域访问问题，配置也是非常简单： location / { #... add_header &#39;Access-Control-Allow-Origin&#39; &#39;*&#39;; add_header &#39;Access-Control-Allow-Methods&#39; &#39;GET,POST,DELETE&#39;; add_header &#39;Aceess-Control-Allow-Header&#39; &#39;Content-Type,*&#39;; }Nginx进程模型Nginx采用多进程单线程的方式来运行的，在Nginx中有一个Master进程和多个Worker进程，Master进程管理着多个Worker进程，Worker进程主要处理客户端请求，Master进程Worker进程是通过共享内存的方式和信号量进行通信的，我们可以再ngixn.conf配置文件中配置nginx的Worker进程数和每个Worker进程的最大连接数，通过这两个配置，就可以计算出当前这台Nginx节点就处理最大的连接数，最大连接数 = Worker进程数 * 单个Worker最大连接数。配置如下： worker_processes 1; #尽量设置成CPU的核心数 events { worker_connections 1024; #理论上 processes* connections }Nginx高可用方案Nginx作为我们系统的入口，所以Nginx本身的可用性也是我们首先考虑的问题。//TODO OpenRestyOpenResty是基于Nginx内核新增了Lua支持的扩展，便于在Nginx的基础上编写Lua脚本达到用户自定义的功能实现，使之更加健壮。 安装OpenResty是在Nginx上做的扩展，所以实际上也是一个Nginx，安装方式和Nginx一致。 Nginx执行阶段和OpenRestyNginx把一次请求划分了11个阶段，各个阶段按照顺序执行，顺序是post-read、server-rewrite、find-config、rewrite、post-rewrite、preaccess、access、post-access、try-files、content、log，下面来一一介绍一下这些阶段都是干啥用的，并且在什么时候被调用。 post-read：Nginx读取并解析完请求头过后立即执行该阶段。 server-rewrite：URI和Location匹配前，修改URI，可用于重定向，该阶段执行位于Server语句块内，Location块外 find-config：根据URI匹配Location，该阶段可能会执行多次 rewrite：匹配到Location过后的URI重写，该阶段可能执行多次 post-rewrite：检查上个阶段是否有URI重写，根据重写的URI跳转到合适的阶段 preaccess：访问权限控制的前一阶段，一般用于访问控制 access：访问权限控制阶段，判断该请求是否允许进入Nginx服务器 post-access：权限控制的后一阶段，根据前一阶段的执行结果进行相应的处理 try-files：为访问静态文件资源设定，如果没有配置try-files指令，该阶段会被跳过 content：处理HTTP请求内容的阶段，该阶段产生响应，并返回到客户端 log：日志记录阶段，记录请求访问日志OpenResty也有如下阶段 init_by_lua：Master进程加载conf配置文件时执行该阶段，一般用来注册全局变量和预加载Lua库 init_worker_by_lua：各个worker进程启动时会执行该阶段，可以用来做健康检查 ssl_certificate_by_lua：在Nginx和下游服务器进行SSL握手之前执行该阶段 set_by_lua: 流程分之处理判断变量初始化 rewrite_by_lua: 转发、重定向、缓存等功能(例如特定请求代理到外网) access_by_lua: IP准入、接口权限等情况集中处理(例如配合iptable完成简单防火墙) content_by_lua: 内容生成 balancer_by_lua：实现动态负载均衡 header_filter_by_lua: 应答HTTP过滤处理(例如添加头部信息) body_filter_by_lua: 应答BODY过滤处理(例如完成应答内容统一成大写) log_by_lua: 回话完成后本地异步完成日志记录(日志可以记录在本地，还可以同步到其他机器)","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.easyjava.xyz/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://blog.easyjava.xyz/tags/Nginx/"},{"name":"服务器","slug":"服务器","permalink":"http://blog.easyjava.xyz/tags/服务器/"},{"name":"负载均衡","slug":"负载均衡","permalink":"http://blog.easyjava.xyz/tags/负载均衡/"},{"name":"反向代理","slug":"反向代理","permalink":"http://blog.easyjava.xyz/tags/反向代理/"},{"name":"Openresty","slug":"Openresty","permalink":"http://blog.easyjava.xyz/tags/Openresty/"}]},{"title":"Redis原理及实战","slug":"Redis原理及实战","date":"2019-12-23T11:14:14.000Z","updated":"2020-02-11T01:07:11.895Z","comments":true,"path":"2019/12/23/Redis原理及实战/","link":"","permalink":"http://blog.easyjava.xyz/2019/12/23/Redis原理及实战/","excerpt":"","text":"相信大家对Redis并不陌生，我们在做数据缓存、分布式锁、分布式事务等业务中经常会见到Redis的身影，今天带大家来深入了解一下Redis的原理以及在实际应用场景中的使用。 初识RedisRedis可以看成是NoSQL数据库，也可以看成是缓存中间件，Redis缺省有16（分别是0-15）个库，每个库中包含多个key，每个key对应的数据类型有五种，分别是String、List、Hash、Set、SortSet 安装 下载 注意：第二位数字为偶数则代表稳定版，奇数为非稳定版 解压：tar -zxvf redis-5.0.7.tar.gz 进入Redis目录：cd redis-5.0.7 编译：make 注意：这里或许会报错，根据提示安装依赖的库即可解决，例如gcc 测试编译：make test 安装：make install {PREFIX=/path} Redis数据类型Redis支持五种数据类型，分别是String、List、Hash、Set、SortSet，五种类型的特性如下： String(字符串)字符串是Redis中最基本的数据类型，它能存储任何字符数据，例如JSON，Base64编码的图片等，String最大支持存储512M的字符数据。 内部数据结构String支持三种数据类型，分别是int、浮点数据和字符数据，int数据类型使用int存储，浮点数据和字符数据使用SDS（Simple Dynamic String）存储，SDS是在C的标准字符串结构上作了封装，Redis3.2有五种sdshdr类型，目的是根据存储的字符串长度选择不同的sdshdr，不同的sdshdr占用的内存大小各有不同，这样就达到了节省内存开销的目的。 List(列表)List列表是一个有序的字符串列表，由于List底层采用的是双向链表的数据结构，所以不管List列表中的数据有多大，向列表的两端存取数据都是很快的，常用操作也是向列表的两端存取数据。 内部数据结构在3.2之前，List中元素个数较少或者单个元素长度较小的时候，采用ZipList数据接口存储数据，当List中元素个数或者单个元素长度较大的时候，就会采用LinkedList存储。这两种数据结构各有优缺点，LinkedList在两端数据的存储复杂度较低，但是内存开销比较大；ZipList内存开销比较小，但是插入和删除需要频繁申请内存。在3.2之后，Redis在数据存储结构上做了优化，采用QuickList数据结构，QuickList其实是LinkedList和ZipList数据结构的整合，QuickList任然是一个LinkedList，只是每个元素都是一个ZipList，每个元素都能存储多个数据元素；即QuickList是多个ZipList组成的LinkedList Hash(可以认为是Java中的Map)Hash可以看成是Java中的Map，由一个Sting类型的key和多个String类型的field和value组成。适合存储对象。 内部数据结构Hash底层数据结构可以使用ZipList和HashTable，当Hash中field和value的字符串长度都小于64字节，一个Hash的field和value的个数小于512个时，使用ZipList数据结构存储 Set(集合)Set存储一个无序不能重复的元素集合，最多可以存储232-1个元素，集合和列表的最大区别就是唯一性和有序性。 内部数据结构Set底层数据结构有IntSet和HashTable，当所有元素是int类型时，这使用IntSet，否则使用HashTable（只用Key，Value为null） SortSet(有序集合)SortSet和Set的区别就是增加了排序功能，在集合的基础上，有序集合为集合中的每个元素绑定了一个score（分数）。有序集合中的元素和集合一样是唯一的，但是元素的score是可以重复的。我们可以通过score进行排序，查找，删除等操作。 内部数据结构SortSet采用ZipList或者SkipList+HashTable数据结构存储数据。 Redis过期时间Redis中可以为一个key设置一个过期时间，当设置了过期时间的key到期过后会被删除。在Redis中，为某个key设置过期时间有三种方式： EXPIRE key seconds:为key设置过期时间，单位为妙，返回值1表示设置成功，0表示失败（例如：键不存在）。 PEXPIRE key millis:为key设置过期时间，单位为毫秒 setex key seconds value:该方式为字符串独有，设置key的过期时间，单位为秒查看一个key的有效期使用TTL key或者PTTL key，两种方式分别对应EXPIRE和PEXPIRE两种方式设置的过期时间。如果TTL或者PTTL返回-2，则表示键不存在，-1则表示没有设置过期时间，其他数字则表示过期剩余时间。如果想让某个设置了过期时间的key恢复成持久的key，可以使用PERSIST key，成功返回1，失败返回0. 过期删除原理在Redis中，对于已经过期的key的删除有两种方式，如下： 积极方式：采用随机抽取算法，周期性的对已经设置了过期时间的key随机抽取一批key，将已经过期的key进行删除，该方式有一个缺陷，并不能确保所有过期的key被删除。具体流程如下： 随机抽取20个带有timeout的key 将已经过期的key进行删除 如果被删除（已过期）的key超过抽取总数的25%（5个），则重复执行该操作 消极方式：当key被访问的时候判断是否过期，如果过期则删除它，该方式有一个缺陷，对于没有被查询到的已经过期的key，会常住内存。Redis采用以上两种过期删除方式来互补，达到过期key的删除逻辑。 发布/订阅（publish/subscribe）Redis提供发布/订阅的功能，可以在多个进程之间进行消息通信。PUBLISH channel.1 message表示向channel.1发送了一条消息，内容为message，该命令返回一个数值，表示订阅了当前channel的订阅者数量，当返回0的时候表示该channel没有订阅者；订阅者使用SUBSCRIBE channel.1 channel.2 ...订阅channel.1，一个channel可以有多个订阅者，一个消费者也可以订阅多个消息，当发送者发送一条详细到一个channel，该channel中的所有订阅者都会受到该条消息。需要注意的是：发送到channel中的消息不会持久化，也就是说，订阅者只能收到订阅过后的消息，订阅之前该channel所产生的消息不能收到。channel可以分为两类，普通的channel和Pattern Channel（规则匹配），例如：现在有两个channel，分别是普通channel abc和Pattern Channel *bc，发送者向abc中发送一条消息PUBLISH abc hello,首先abc这个channel能收到一条消息hello，*bc也能匹配到abc这个channel，所以*bc也能收到这条消息hello。 Redis数据的持久化在Redis中，数据的持久化有两种方式 RDB：Fork一个子进程根据配置的规则定时的将内存中的数据写入到磁盘中。 AOF(Append Only File)：每次执行过后将命令追加到AOF文件中，类似于MySQL的binlog。 RDB当符合RDB持久化条件时，Redis会Fork和主进程一样的子进程，先将内存中的所有数据写入到一个临时文件中，当内存中的所有数据都写入完毕过后，再将之前的备份文件替换。该方式的缺点是最后一次持久化过后的数据有可能会丢失，也就是说，两次数据的持久化间隔产生的数据有可能丢失。什么叫符合RDB持久化条件呢？ 当满足配置文件的规则时：在redis.conf文件中配置save 900 1,save 300 10,save 60 10000，以上配置，save后面的第一个参数表示时间（单位秒），第二个表示键的个数，并且满足以上任意一个配置都会执行，以上配置表示的意思就是：当900秒内有一个键发送变动或者300秒内有10个键发生变动或者60秒内有10000个键发生变动都会触发RDB快照。 客户端发送了SAVE或者BGSAVE命令：当我们需要对Redis服务进行重启的时候，我们可以操作SAVE或者BGSAVE命令手动执行RDB快照，SAVE和BGSAVE命令的区别在于，一个是同步执行，一个是异步执行，同步执行会阻塞其他客户端的请求，而BGSAVE则不会阻塞。我们还可以通过LASTSAVE命令来查看最后一次执行RDB快照的时间。 客户端发送了FLUSHALL命令：该操作依赖配置规则，如果没有配置RDB的执行规则，该命令也不会触发RDB快照的执行。 执行复制（Replication）：该操作一般指在主从模式下，Redis会在复制初始时执行RDB快照。 AOF当我们的业务需求对Redis的使用不限于缓存时，可能会使用Redis存储一些比较重要的数据，这个时候我们可以开启AOF来降低RDB持久化方式对内存数据的丢失，当然，开启AOF对Redis对外提供服务的性能是有一定的影响的，但是这种影响一般能接受，解决办法可以使用一些写入性能较高的磁盘。默认情况下，Redis并没有开启AOF持久化方式，我们可以在配置文件中配置AOF是否开启。appendonly yes将appendonly属性值改为yes，则表示开启AOF持久化。还可以指定AOF持久化到磁盘的文件名称appendfilename &quot;appendonly.aof&quot;。查看appendonly.aof文件，我们可以发现，里面保存了客户端操作Redis的所有事务操作（增删改）命令，但其实有的时候我们对Redis的操作是针对同一个key的，也就是说，其实真正有用的数据是最新存在于内存中的数据，而AOF持久化文件则保存了各个key的变动轨迹，有很多命令轨迹是没有用的，所以这个时候需要对这样一个问题进行优化。Redis也考虑到了这一点，我们可以通过配置的方式来解决这一问题，在redis.conf配置文件中配置auto-aof-rewrite-percentage 100和auto-aof-rewrite-min-size 64mb。 auto-aof-rewrite-percentage 100:表示当前AOF文件的大小超过上一次重写AOF文件大小的百分之多少时会再次执行重写，如果之前没有重写过，则以启动时AOF文件的大小为准。 auto-aof-rewrite-min-size 64mb:表示限制允许重写最小AOF文件的大小。当然我们也可以通过手动执行BGREWRITEAOF命令的方式让AOF文件重写。AOF方式的数据恢复会一个一个将AOF文件中的命令在Redis服务器上执行，性能上会比RDB方式慢。 AOF重写原理同样的，为了不影响对外提供服务，AOF重写时主进程会Fork一个子进程来执行，该操作并不是和之前AOF追加的方式，而是类似于RDB的方式，将内存中的数据遍历出来，然后解析成set命令保存到AOF文件中，在这期间，由于Redis还持续对外提供服务，那么在期间客户端发送的操作执行该如何保证数据同步呢，Redis的解决方案是在执行AOF重写的过程中，主进程接受到的所有客户端的事务操作会缓存到aof_rewrite_buf缓存（单独开辟一块内存空间来存储执行AOF重写期间收到的客户端命令）中，当重写操作执行完成过后，在将aof_rewrite_buf缓存中将所有命令追加到重写过后的文件中，当然这个文件也是一个临时文件，当以上操作都执行完毕过后，Redis会把之前旧的AOF文件替换，这样做的好处在于，就算在AOF重写时失败了，也不会影响之前已经持久化的AOF文件。 Redis的内存回收策略内存是有限且昂贵的，Redis作为一个内存缓存中间件，必须要考虑如何合理有效的使用内存空间。例如：当内存不足时，如何保证Redis程序的正常运行。Redis提供多种内存回收策略，当内存不足时，Redis为了保证持续的对外提供服务，根据不同的策略淘汰一些对象，来达到Redis的可靠性。那么Redis有哪些淘汰策略？ allkeys-lru:从数据集中挑选最近最少使用的key淘汰，该方式适用于缓冲中的数据都是热点数据 allkeys-random:随机选择一些key进行淘汰，该方式适用于如果我们应用对缓冲key访问的概率相等 volatile-lru:从已经设置了过期时间的数据集中挑选最近最少使用的key进行淘汰 volatile-random:从已经设置了过期时间的数据集中随机挑选一些key进行淘汰 volatile-ttl:从已经设置了过期时间的数据集中选择快要过期的key进行淘汰注意：Redis中的LRU算法并不是真正意义上的LRU算法，是采用抽样的LRU算法，在一定程度上接近真正LRU算法。 单线程的Redis在性能上为什么这么突出首先来说为什么使用单线程，我们知道多线程主要是对CPU资源的最大化使用，而Redis的性能瓶颈并不在CPU，而是在于内存和网络。为了在单线程模式下性能达到更高，Redis采用IO多路复用的解决方案来解决Redis在单线程下的性能问题。 多路复用//TODO 在Redis中使用Lua脚本在客户端使用Redis会面临很多问题，例如：原子性问题、性能问题等 原子性问题：Redis作为数据服务器，多个客户端连接到Redis上，这个时候多个客户端发送的命令可能会因为网络或者其他元素导致Redis服务器收到的命令顺序会被打乱，这样就造成了客户端发送的一批命令没有顺序性的执行，导致数据错乱。 性能问题：客户端执行一段逻辑可能需要多次访问Redis服务器，这期间的多次网络请求就会成为Redis性能的瓶颈。为了解决以上问题，Redis内嵌了对Lua脚本的支持，客户端可以通过Lua脚本发送一批Redis命令到Redis服务器，这一操作，既解决了Redis的原子性问题又解决了性能问题。使用Lua脚本的好处： 减少网络开销，可以吧多个Redis命令放到一个Lua脚本中执行 原子操作：Redis会叫这个Lua脚本作为一个整体执行，中间不会接受客户端的其他请求。 复用性：Redis可以把一个Lua脚本保存到服务器中，其他客户端都可以使用该脚本。 在Lua脚本中调用Redis命令redis.call(&quot;set&quot;,&quot;key&quot;,&quot;value&quot;) local val = redis.call(&quot;get&quot;,&quot;key&quot;)以上脚本是在Lua脚本中调用Redis命令，并且返回结果到Lua脚本中，那么在开发场景中，Lua脚本其实也可以看成是我们封装的一个带有逻辑性的Redis命令，那么是Redis命令就一定会有返回值，应该任何从Lua脚本中获取返回值呢，也就是执行完Lua脚本过后，得到执行结果，其实可以通过在Lua脚本中通过return关键字将结果返回，如果没有return，则默认返回nil。PS:定义一个lua脚本用于设置一个字符串类型的key # demo.lua return redis.call(&quot;set&quot;,KEYS[1],ARGS[1])执行lua脚本，使用EVAL demo.lua 1 key value，其中1表示一个key，也就是1后面的多少个参数作为key会被放到KEYS变量中，其余的参数都会放到ARGS中。使用Lua脚本可以将一系列的Redis命令封装在脚本中，减少了多次请求网络的开销和原子性问题，但其实当客户端发送一次Lua脚本的时候，Lua脚本本身比较大，对网络开销也很大，所以我们可以将Lua脚本缓存到Redis中并生成SHA1摘要，客户端只需要发送摘要就可以代替对应的Lua脚本。操作命令如下： script load demo.lua eavlsha sha摘要 0Redis集群在日常开发过程中，我们使用任何中间件都一定会考虑其单点问题，都会使用集群的方式来达到中间件本身的高可用。 主从复制Redis支持一主多从的高可用方案，就是一个主节点对应多个从节点，主节点能处理客户端的读写操作，而从节点则只能接受读操作，当主节点出现宕机不可用等情况时，从节点可以升级成为主节点持续对外提供服务。那么主节点和从节点就一定会有数据同步的过程，这个过程是在当主节点中数据发生变更时会触发，该操作是异步的，即数据同步过程中不会影响主节点对外提供服务。实现Redis主从复制也是很简单的，只需要在从节点的redis.conf配置文件中增加配置slaveof masterIp masterPort并且允许所有IP访问（注释掉bindip）即可，主节点不需要修改任何配置。启动主从节点过后，可以通过info replication查看集群状态。 原理 全量复制：全量复制一般发生在初始化过程中，步骤如下： 从节点启动连接到主节点过后，向主节点发送SYNC命令 主节点收到SYNC命令过后，执行BGSAVE命令进行RDB快照，并且将从现在开始收到的客户端的增删改操作命令保存到缓冲区中 主节点执行完BGSAVE命令过后将生成的RDB发送给从节点，发送期间继续保存主节点执行的命令 从节点收到RDB文件过后，丢弃旧的数据，从RDB文件中恢复数据 主节点在发送完快照文件过后向从节点发送缓冲区的操作命令 从节点收到主节点的操作命令过后执行当完成以上操作过后Redis主从的初始化就完成了，从节点这个时候就可以接受客户端发送的读请求了。Redis中主从复制其实是利用RDB快照的方式，然而使用该方式会存在一些问题，例如： 当Master为开启RDB快照时，主从复制的初始化任然会执行RDB快照，生成一个文件到响应目录中，当Master下次启动时，会根据这个RDB文件进行数据恢复，由于快照生成的时间可以是任何时间点的所有就会造成数据问题。 当硬盘性能本身很低时，可能会造成主节点的性能瓶颈为了解决以上问题，Redis2.8.18版本以后，提供了无硬盘复制，也就是说不会生成RDB文件，直接发送数据。我们可以通过repl-diskless-sync yes配置来开启该功能。 增量复制：增量复制是指当主节点数据发生变更时，主节点将接收到的客户端发送的命令原封不动的发送给从节点，从节点收到主节点发送的命令过后执行来达到数据的同步。 哨兵机制前面说到了当Redis集群中的主节点宕机或者不可用时，需要从其他从节点中选举一个作为主节点继续对外提供服务，那么谁去选举Master呢，在Redis中提供了一个角色来专门做Master故障切换和选举。这就是哨兵。在Redis中，哨兵主要干两件事情，一是监控Master和Slave节点是否正常运行，二是当Master出现宕机不可用时，从从节点中选举一个节点作为Master节点。哨兵是一个独立的进程，监控着集群中的Master节点，通过Master节点，哨兵可以找到该集群中的其他从节点，进而监控着整个集群中的所有主从节点。 虽然这一架构解决了Redis集群中故障切换的问题，但是有引发了另外一个问题，就是哨兵作为集群中故障切换的关键角色，哨兵的单点问题也需要解决。所以，这个时候的架构应该改进为，主从集群和哨兵集群，来达到整个Redis服务集群的高可用。哨兵集群中的所有哨兵节点是相互感知的，原理大概是：所有哨兵节点都监控同一个Master节点，并且订阅同一个channel（名为 channel:sentinel:hello），新加入的哨兵节点会向该channel中发送一条消息（包含自身信息），新加入的哨兵节点和其他哨兵节点建立一个长连接。 哨兵节点会定期向Master发送心跳包来判断Master节点是否存货，一旦发现Master没有正确相应，哨兵会将该Master节点状态设置为“主观不可用”，然后把这个状态发送给其他哨兵节点进行确认，如果确认的节点超过配置的“quorum”值时，则会认为Master是客观不可用。接着就会进入Master选举流程。这个时候又会出现一个问题，哨兵是一个集群，具体的由哪一个哨兵来执行该操作呢，这里就涉及到了领头哨兵的选举，这里其实使用是Raft算法，具体流程如下： 发现主库客观下线的哨兵节点（这里称为A）向每个哨兵节点发送命令要求对方选举自己为领头哨兵（leader） 如果目标哨兵没有选举过其他人，则同意将A选举为领头哨兵 如果A发现有超过半数且超过quorum参数值的哨兵节点同意选自己成为领头哨兵，则A哨兵成功选举为领头哨兵 当有多个哨兵节点同时参与领头哨兵选举时，出现没有任何节点当选可能，此时每个参选节点等待一个随机时间进行下一轮选举，直到选出领头哨兵 哨兵的配置实现在运行哨兵节点的服务器上新建一个sentinel.conf文件，添加以下属性： port 6040 sentinel monitor mymaster 192.168.1.1 6379 1 # name为自定义master名称，1表示最少多少个哨兵节点同意才能执行后面的操作 sentinel down-after-milliseconds mymaster 5000 # 表示如果5s内mymaster没响应，就认为SDOWN sentinel failover-timeout mymaster 15000 # 表示如果15秒后,mysater仍没活过来，则启动failover，从剩下的slave中选一个升级为master启动哨兵的两种方式./redis-server.sh /path/sentinel.conf --sentinel/./redis-sentinel /path/sentinel.conf Redis-Cluster//TODO Redis缓存及数据一致性的问题Redis缓存和数据库在事务上是不能达到统一的，那么我们如何保证最终一致性。 先操作缓存还是先操作数据库？答：如果我们使用缓存失效这种方式来代替缓存数据的更新，那么应该先更新数据库再失效缓存。如果使用更新缓存的方式，我们需要根据业务场景来权衡。 更新缓存还是让缓存失效？答：如果更新缓存的代价较小，可以更新缓存，如果更新缓存的代价较大，我们可以直接将缓存失效，下一次访问时缓存未命中，则会自动从数据库中获取数据并且将其缓存 缓存雪崩当大规模的缓存数据同时失效或者说缓存集群不可用时，大量的客户端请求直接性的对DB层造成了重大的冲击，最终导致整个系统瘫痪，这种现象称之为缓存雪崩。那么面对这一现象应该考虑的解决方式如下： 当缓存中未命中客户端想要的数据，则通过加锁形成排队的方式访问数据库，避免同时并发的访问底层存储系统带来的重大冲击。 避免大批量缓存数据同时失效，将缓存过期时间点分散。 保证缓存服务的高可用。 缓存穿透当客户端查询一个不存在的数据，缓存和数据库都不会命中，又由于数据库中没有数据，所以不会被缓存。由于底层存储系统往往不具备高并发性，频繁并发的穿透可能会导致存储系统宕机。对于这一现象的解决思路如下： 将不存在的key也缓存到缓存中 将key按照规则命名，将不符合规则的key过滤掉 采用布隆过滤器的方式来判断当前查询的key是否存在于缓存当中，如果不存在，则过滤掉。 布隆过滤器主要作用是判断一个元素是否存在于集合中，因为它是一个概率算法，所以会存在误差。它的优点在于空间效率和查询时间都比其他算法快。例如：当传入一个元素，结果表示其存在但有可能不存在，但是绝对不会出现结果表示不存在的但实际存在。也就是说，布隆过滤器判断一个元素不存在则绝对不存在，判断一个元素存在则会出现误差。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://blog.easyjava.xyz/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://blog.easyjava.xyz/tags/Redis/"},{"name":"Jedis","slug":"Jedis","permalink":"http://blog.easyjava.xyz/tags/Jedis/"}]},{"title":"Kafka原理分析","slug":"Kafka原理分析","date":"2019-12-12T12:14:00.000Z","updated":"2020-02-11T01:07:11.885Z","comments":true,"path":"2019/12/12/Kafka原理分析/","link":"","permalink":"http://blog.easyjava.xyz/2019/12/12/Kafka原理分析/","excerpt":"","text":"我们都知道Kafka具有很高的吞吐量、数据分片、冗余和容错等优点，一般用于用户行为追踪以及分布式系统日志收集等场景，那么Kafka是如何做到这些优点的呢，今天就让我们来一一分析。 Kafka入门安装 点击下载 解压:tar -zxvf kafka_2.11-2.3.1.tgz 启动zookeeper:sh ${zookeeperDir}/bin/zkServer.sh start，zookeeper集群则需要将集群中所有节点启动 配置config目录下的server.properties中:zookeeper.connect=192.168.3.224:2181 启动/停止:sh kafka-server-start.sh -daemon ../config/server.properties/sh kafka-server-stop.sh ../config/server.properties 集群配置配置config目录下server.properties文件 将broker.id属性配置为当前节点id，集群中的所有节点id不能相同，例如broker.id=0/1/2... 将advertised.listeners属性改为当前节点的主机地址，例如advertised.listeners=PLAINTEXT://192.168.3.224:9092这样，当Broker启动的时候，会向zookeeper注册自己的主机及端口，其他Broker就可以通过ip和端口来连接 基本操作命令行操作 创建Topic:sh kafka-topics.sh --create --zookeeper 192.168.3.224:2181 --replication-factor 1 --partitions 1 --topic test 列出所有Topic:sh kafka-topics.sh --list --zookeeper 192.168.3.224:2181 查看Topic详情:sh kafka-topics.sh --describe --zookeeper localhost:2181 --topic test[root@MiWiFi-R3L-srv bin]# sh kafka-topics.sh --describe --zookeeper localhost:2181 --topic test Topic:test PartitionCount:1 ReplicationFactor:1 Configs: Topic: test Partition: 0 Leader: 0 Replicas: 0 Isr: 0 发送消息:sh kafka-console-producer.sh --broker-list 192.168.3.224:9092 --topic test 消费消息:sh kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning Java API使用 producer public class Producer { public static void main(String[] args) { Properties properties = new Properties(); properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,\"192.168.3.207:9092,192.168.3.9:9092,192.168.3.155:9092\"); properties.put(ProducerConfig.ACKS_CONFIG,\"all\"); properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,\"org.apache.kafka.common.serialization.IntegerSerializer\"); properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,\"org.apache.kafka.common.serialization.StringSerializer\"); KafkaProducer producer = new KafkaProducer&lt;Integer,String>(properties); for (int i=0;i&lt;100;i++) { ProducerRecord&lt;Integer,String> record = new ProducerRecord&lt;Integer, String>(\"firstTopic\",\"HelloWorld\" + i); Future future = producer.send(record); System.out.println(future); } producer.close(); } } consumer public class Consumer { public static void main(String[] args) throws IOException { Properties properties = new Properties(); properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,\"192.168.3.207:9092,192.168.3.9:9092,192.168.3.155:9092\"); properties.put(ConsumerConfig.GROUP_ID_CONFIG,\"MrATooConsumer\"); properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,\"true\"); properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,\"org.apache.kafka.common.serialization.IntegerDeserializer\"); properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,\"org.apache.kafka.common.serialization.StringDeserializer\"); KafkaConsumer&lt;Integer,String> consumer = new KafkaConsumer&lt;Integer, String>(properties); /*TopicPartition partition = new TopicPartition(\"firstTopic\",1); consumer.assign(Arrays.asList(partition));*/ consumer.subscribe(Arrays.asList(\"firstTopic\")); ConsumerRecords&lt;Integer, String> records = consumer.poll(Duration.ofDays(7)); Iterator&lt;ConsumerRecord&lt;Integer, String>> iterator = records.iterator(); while (iterator.hasNext()) { ConsumerRecord&lt;Integer, String> record = iterator.next(); System.out.println(record.value()); } consumer.close(); } } 配置分析Producer可选配置 acks:该配置表示producer发送到Broker上的确认值，该值有三个选项，分别是： 0:producer发送消息过后不需要等待Broker确认，该方式延时小但消息容易丢失 1:producer发送消息过后只需要等待kafka集群的leader节点确认，该方式延时和可靠性适中 all(-1):producer发送消息过后需要等待ISR列表中的所有节点确认，该方式延时较长，但消息不容易丢失。但ISR可以缩小到1，所以并不能百分之百保证消息不丢失。 batch.size:当生产者发送多个消息到Broker上时，为了节约网络开销，可以通过批量的方式来提交消息，可以通过该配置来设置批量提交消息的大小，默认是16kb。也就是，当一批消息达到了batch.size大小的时候统一发送。 注意：这里的batch.size大小是针对同一个partition linger.ms:消息发送请求的延迟（间隔），即：当消息发送间隔时间较短，并且还没有达到batch.size大小时，这个时候客户端并不会立即发送请求到Broker上，而是延迟linger.ms过后，将多个消息合并成一个消息发送，该配置为0，则代表没有延迟，如果配置成正整数值，则会减少请求数量，但也会有消息发送延迟。如果同时配置了linger.ms和batch.size，则满足一个条件就会发送。 max.request.size:现在请求数据的最大字节数，默认为1M Consumer可选配置 group.id:kafka中的每个消费者都有一个组，组和消费者是一对多的关系，对于一个Topic而言，如果Topic对应多个组，则类似于ActiveMQ中Topic的概念，如果Topic对应一个组，则类似于ActiveMQ中Queue的概念，同一个组下的多个消费者可以同时消费一个Topic下的多个分区，一个分区只能分配给一个消费者进行消费。 enable.auto.commit:消息消费后自动提交，只有当消息被提交过后才会确保消息不会再次被消费，可以接口auto.commit.interval.ms来优化自动提交的频率。当然，我们也可以通过consumer.commitSync()方法来手动提交消息。 auto.offset.reset: max.poll.records:配置每次poll消息的数量 Topic和PartitionTopicTopic是一个逻辑的概念，可以认为是一个消息集合，不同的Topic是分开存储的，一个Topic可以有多个生产者向它发送消息，也可由有多个消费者消费消息。 Partition一个Topic可以个多个Partition（至少有一个分区），同一个Topic下的不同分区的消息是不同的，每个消息在分配到分区时，都会被分配一个offset（偏移量），kafka通过offset保证消息在同一个分区的顺序，也就是说，同一个分区的消息是有序的。 Partition存储Partition以文件的形式存在于文件系统中，例如：sh kafka-topics.sh --create --zookeeper 192.168.3.224:2181 --replication-factor 1 --partitions 3 --topic test，以上命令会创建一个有三个分区的名称为test的Topic，那么这三个分区会生成三个文件夹均匀分布在不同Broker中，文件夹的命名规则为&lt;topic_name&gt;-&lt;partition_id&gt;，partition_id范围为0~3。 消息分发策略一个消息由key和value组成，发送一条消息之前，我们可以指定消息的key和value，然后kafka会根据指定的key和partition机制来决定当前这条消息应该被存储到那个分区中，默认情况下，kafka采用的消息分发机制是Hash取模算法，如果key为空，则会随机分配一个分区，这个随机分区会在metadata.max.age.ms配置指定的时间内固定选择一个，这个值默认是10分钟，也就是说，每10分钟，随机分区会更新一次。 消息消费原理每个Topic有多个Partition，每个Consumer Group有多个消费者，同一个Partition只允许被一个Consumer Group中的一个消费者消费。那么同一个消费者中的消费者是如何去消费同一个Topic下的多个Partition的呢？这就牵扯到了分区分配策略 分区分配策略kafka中提供两种分区分配策略，分别是Range（范围分区）、RoundRobin（轮询），通过partition.assignment.strategy配置来指定分区分配策略。 Range（范围分区）首先将同一个Topic下的所有Partition通过分区ID进行排序，然后将同一个Consumer Group下的所有Consumer按照一定规则排序，然后用Partition总数除以消费者总数，如果除不尽，则将余数按照顺序分配到排序过后的Consumer上。例如：现在有一个Topic test，10个分区;一个Consumer Group,三个消费者; 将Partition通过ID排序过后得到test-0,test-1,test-2,test-3,test-4,test-5,test-6,test-7,test-8,test-9 将消费者排序，假如是C0,C1,C2 先计算10/3=3，然后计算10%3=1，最后得到三个组，分别是0,1,2,3/4,5,6/7,8,9 最后得到的结果是： C0消费test-0,test-1,test-2,test-3 C1消费test-4,test-5,test-6 C2消费test-7,test-8,test-9通过上面的例子，可以看出，消费者C0多消费了一个分区，这时设想一下，如果该消费组中同时订阅了n个Topic，采用范围分区算法，那么消费者C0将比该组中的其他消费者多消费了n个分区。 RoundRobin（轮询）把所有的Partition和Consumer按照HashCode排序，然后通过轮询算法将各个Partition分配给Consumer。例如：现在有一个Topic test，10个分区;一个Consumer Group,三个消费者； 将Partition通过HashCode排序，假如得到test-5,test-8,test-2,test-4,test-3,test-6,test-7,test-9,test-0,test-1 将消费者通过HashCode排序，假如是C2,C0,C1 最后得到的结果是： C2消费test-5,test-4,test-7,test-1 C0消费test-8,test-3,test-9 C1消费test-2,test-6,test-0虽然这里C2消费者比其他消费者多一个，但是如果该消费组订阅了多个Topic，那么将会从C0开始分配，也就是说，消费组中的所有消费者消费的分区差距不会超过1。注意：使用轮询分区分配策略需要满足一下两个条件 每个主题的消费者实例具有相同数量的流 每个消费者订阅的主题必须是相同的 什么时候会触发分区分配策略？以下几种情况会触发分区分配策略（也可称之为Rebalance），分别是： 当有新的消费者加入当前Consumer Group 有消费者离开当前消费组，例如宕机或者主动关闭 Topic新增了分区 谁来执行分区分配？kafka提供一种角色Coordinator来执行对消费组Consumer Group的管理，当消费者启动的时候，会向Broker确定谁是它们组的Coordinator，之后该组中的所有Consumer都会向Coordinator进行协调通信。 如何确定Coordinator角色？消费者向kafka集群中任意一个Broker发送一个GroupCoordinatorRequest请求，Broker会返回一个负载最小的BrokerID，并且将其设置成为Coordinator。 Rebalance（重新负载）在执行Rebalance之前，需要保证Coordinator是已经确定好了的，整个Rebalance分为两个步骤 1. joinGroup:所有Consumer都会想Coordinator发送JoinGroupRequest请求，请求中带有group_id/member_id/protocol_matedata等信息，Coordinator会从中选择一个Consumer作为Leader， 并且把leader_id、组成员信息members、序列化后的订阅信息protocol_metadata以及generation_id(类似于zookeeper epoch)发送给消费者。 2. syncJoin:Leader Consumer在确定好分区分配方案过后，所有消费者向Coordinator发送一个SyncGroupRequest请求，当然这里只有Leader Consumer会真正发送分区分配方案，其他的Consumer 只是打酱油的，Coordinator在收到Leader Consumer的分区分配方案过后，将其封装成一个SyncGroupResponse响应返回给所有的Consumer，所有的Consumer在收到分区分配方案过后，自行消费 方案中指定的分区。 Offset前面讲到每个Topic有多个Partition，每个Partition中的消息都不一样，并且每个Partition中的消息都会存在一个offset值，在同一个Partition中的offset是有序的，即kafka可以保证同一个Partition中的消息是有序的，但是这一特性并不跨分区，也即kafka不能保证跨分区的消息的有序性。 Offset在哪里维护？kafka提供一个名为__consumer_offsets_*的Topic，该Topic就是来保存每个Consumer Group的消费的每个Partition某一时刻的offset信息，该Topic默认有50个分区，那么，kafka是如何将某个Consumer Group保存到具体的那个分区的呢？其实，kafka是通过这样一个算法来决定该Consumer Group应该保存在那个分区的，公式：Math.abs(&quot;group_id&quot;.hashCode())%groupMetadataTopicPartitionCount。确定了分区过后，我们可以通过如下命令查看当前Consumer Group的offset信息 sh kafka-simple-consumer-shell.sh --topic __consumer_offsets --partition 35 --broker-list 192.168.3.224:9092 --formatter \"kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter\" 多个分区在集群中的分配一个Topic有多个Partition，那么这么多的Partition是如何在Broker中分布的呢？ 将i个Partition和n个Broker排序 将第1个Partition分配到i%n个Broker上 消息的存储我们都知道在kafka中消息都是以日志文件存储在文件系统中的，由于kafka中一般都存储着海量的数据，所有，kafka中的消息日志分区并不是直接对应一个日志文件，而是对应着一个分区目录，命名为&lt;topic_name&gt;_&lt;partition_id&gt;，例如一个名为test的Topic，有三个分区，那么在集群Broker的/tmp/kafka-log(该目录是一个临时目录，一般线上环境都会更改此目录)中就有三个目录，分别是test-0/test-1/test-2 消息的文件存储机制我们知道了Partition的存储是指向一个目录的，其实目录并不具备数据存储的能力，那么kafka中的消息是如何存在于Partition中的呢。kafka为了以后消息的清理以及压缩的便利性和处于性能方面的考虑，引入一个LogSegment的逻辑概念，但实际上消息是以文件的形式存在于Partition目录中的。在一个Partition中可以存在多个LogSegment，一个LogSegment由一下三个文件组成： 1. 00000000000000000000.index:offset索引文件，对应offset和物理位置position 2. 00000000000000000000.timeindex:时间索引文件，映射时间戳和offset的对应关系 3. 00000000000000000000.log:日志文件，存储Topic消息，包含内容有offset、position、timestamp、消息内容等等每个LogSegment分段的大小可以通过server.properties中的log.segment.bytes属性设置，默认是1GB。LogSegment命名的规则是由一个最大支持64位long大小的20位数字字符串组成，每个Partition中的第一个LogSegment从0开始，后面的LogSegment命名为上一个LogSegment消息中最后一个offset+1，我们可以通过sh kafka-run-class.sh kafka.tools.DumpLogSegments --files /tmp/kafka-logs/test-0/00000000000000000000.log --print-data-log命令查看分区0的第一个LogSegment。 LogSegment中index文件和log文件的关联关系我们知道每个LogSegment都是由index,timeindex,log三个后缀结尾的文件组成。可以通过以下命令查看索引文件内容： sh kafka-run-class.sh kafka.tools.DumpLogSegments --files /tmp/kafka-logs/test-0/00000000000000000000.index --print-data-log index和log文件的对应关系如下图： 通过offset查找Message的原理分析通过上一节我们了解到，offset其实是保存的log文件中的简略信息，是log文件中offset和position的跳跃版，也叫稀疏索引，那么消息是如何通过offset查找的呢例如：我们需要查找test Topic中offset为88的message，那么kafka会经过一下步骤查找消息 分过二分查找法确定该消息存在于那个LogSegment中，那么显然这里offset为88的message肯定存在于00000000000000000000的LogSegment中 同样通过二分查找法找索引文件中小于等于目标消息（offset为88）offset的记录，以上图为例，很显然是{offset:54,position:4190}，从该条记录中可以知道offset为54的消息的position为4190 打开log文件，从position为4190的地方顺序查找知道找到offset为88的message，然后返回。 消息的写入性能为什么kafka会有这么高的吞吐量，其原因在于kafka在很多地方做了优化，那么在网络传输和磁盘IO上，有很大的优化空间 顺序写入：kafka采用顺序写入的方式将消息持久化到磁盘，避免了常规随机写入数据寻址等一系列操作带来的性能损耗。 零拷贝：一般情况下，我们将文件数据发送到网络上时，需要将文件冲磁盘读取到操作系统内核空间中，然后拷贝到用户空间，最后将数据发送到网卡，通过网络传输，在kafka中，采用零拷贝的方式，直接将数据从内核空间发送到网卡通过网络传输，节省了用户空间这一步骤，在性能上有一定的提升。 在linux系统中使用sendFile实现零拷贝 在Java中使用FileChannel.transfer实现零拷贝 日志清理策略kafka日志使用分段存储，一方面方便日志的清理，另一方面能确保单个文件的大小从来提升一定的性能。kafka会起一个后台线程来执行日志的清理工作，kafka的日志清理策略有两种 根据保留时间：当消息在kafka中存在超过指定的时间，就会触发日志清理，默认时间为7天，可以通过在server.properties中的log.retention.hours属性指定 根据日志大小：当kafka中消息的大小超过指定大小，就会触发日志清理， 可以通过在server.properties中的log.retention.bytes属性指定以上两种策略只要满足一种则会触发清理。 日志压缩策略我们可以开启kafka的日志压缩功能，开启后，kafka会起一个Cleaner线程，定时的去压缩日志，kafka压缩日志的原理是，只保留各个key对应最新的value，而所有修改之前的value则被删除。类似于数据库中某条数据的更新历史，比如用户1的用户名由张三改为李四再改为王五，那么只保留王五。 kafka高可用副本机制kafka中每个Topic可以有多个Partition，并且各个Partition会均匀分布在各个Broker中，但是对于Partition来说，Partition本身存在单点问题，也就是说，当一个Topic中的某个Partition不可用则代表该Partition中的消息无法被消费，考虑到这一问题，kafka提供了高可用的Partition解决方案，那就是Partition的副本机制。 每个Partition可以有多个副本，并且存在一个leader副本，所有的读写请求都是由leader副本执行，副本集中的其他Partition作为follower副本存在，follower副本的职责只是从leader副本中同步数据所以，我们可以理解为，在Partition的副本集中存在一主多从的架构模型。 一般情况下，一个分区的多个副本会均匀分布在各个Broker上，当其中一个Broker宕机或者其中一个Partition不可用时，可以重新选举一个新的leader副本继续对外提供服务，这样就可以保持kafka集群的可用性。 副本分配算法 将N个Broker和i个Partition排序 将i个Partition分配到(i mod n)个Broker上（这是多个分区在Broker的分配算法，可以参考 多个分区在集群中的分配） 将i个Partition的j个副本分配到((i + j) mod n)个Broker上 我们可以在zookeeper中查看各个Topic的各个分区的状态信息，通过get /brokers/topics/test/partitions/0/state命令可以得到以下信息： {\"controller_epoch\":1,\"leader\":0,\"version\":1,\"leader_epoch\":0,\"isr\":[0]} 我这里使用的是单机环境，所以只配置有一个副本（也就是没有副本），这里的ISR只有一个节点，从以上信息可以看出，test Topic中的leader节点也是0。 副本机制名词解释 Leader副本：负责处理客户端的读写操作 Follower副本：被动的从Leader副本中同步数据 ISR副本集：包含Leader副本和所有和Leader副本保持数据同步的Follower副本 LEO：日志末端位移 HW：水位值，当HW的值等于LEO的时候，表示Follower副本中的数据和Leader副本中的数据已经完全同步，HW永远不会大于LEO的值。当消费者拉取消息的时候，只能拉取该值以前的消息，HW值以后的消息对于消费者来说是不可见的，也就是说HW的值取决于ISR副本集中最小的LEO值。每个replica都有HW，各个副本都维护着自己的HW。一条消息只有被所有的Follower副本从Leader同步过后才会被认为已提交。这样有利于避免一条消息还没有来得及同步就宕机，导致消息丢失的情况。当然，我们可以在发送端指定消息的acks模式，该模式在之前讲过。 副本协同机制所有客户端的读写请求都会由Leader副本处理，Follower只负责从Leader副本中同步数据，当Leader副本所在的Broker出现宕机和不可用时，会从Follower副本中重新选举一个成为Leader。写请求首先由Leader副本处理，之后Follower副本同步，这个步骤会有一定的延迟，当这个延迟在预定的阈值范围内则可以容忍，当这个延迟超出了阈值（可能存在的原因有很多，例如：网络，宕机），Leader副本就会将这个Follower副本从ISR中踢出去。 ISR经过前面的协同机制过后，ISR副本集里面存在的Leader副本和Follower就是 Leader副本和当前可用并且消息量与Leader副本差不多的Follower副本，是整个副本集的一个子集（因为整个副本集可能存在宕机的副本，被踢出了），具体来说，ISR中的副本必须满足一下条件： 副本所在的Broker必须与Zookeeper保持连接 副本最后一条消息的offset和Leader副本中最后一条消息的offset差距不能大于执行阈值，该阈值可以通过replica.lag.time.max.ms指定 replica.lag.time.max.ms:如果该Follower在此时间间隔内没有追上Leader副本中的所有消息，则将该副本从ISR副本集中剔除 数据同步过程Producer在发送消息到某个Partition时，先通过Zookeeper找到该Partition的Leader副本，Leader首先会将消息写入到Log日志文件中，然后Follower会从Leader中pull消息，Follower保存消息的顺序和Leader的顺序一致。Follower在pull消息并且写入Log文件过后，向Leader发送ACK，一旦Leader收到所有Follower的ACk过后，该消息就被认为已经Commit了，最后Leader就会增加HW值并且向Producer发送ACK。 副本数据同步机制初始状态下，Leader和Follower副本的LEO和HW的值都为0，并且Leader中还保存着remoteLEO(表示所有Follower的LEO，初始值也是0)，Follower会不断的向Leader副本发送fetch请求，假如当前没有任何Producer向Leader副本发送消息，则这个请求会被Leader寄存，当超过了指定阈值（通过replica.fetch.wait.max.ms设置）还没有Producer发送消息，则该请求会被强制完成。如果在该阈值指定时间内有新的消息，那么该fetch请求会被唤醒，继续执行。这里可以分为两种情况： Follower的fetch请求是在Leader处理了Producer消息过后发送的 Producer发送一条消息，Leader在收到消息过后做以下事情： 将消息保存到Log文件中，同时更新自己的LEO值 更新自己的HW值，但是由于当前还没有Follower发送fetch请求，那么Leader副本那种的RemoteLEO值任然是0，Leader将自己的LEO和RemoteLEO值进行比较，发现最小值是0，所以HW的值还是0。 Follower第一次fetch消息Leader的处理逻辑是： 读取Log消息，更新RemoteLEO值（RemoteLEO值由fetch请求中的offset来决定，由于是Follower第一次发送fetch请求，所有请求的offset值为0）。 更新HW值，但是这时自己的LEO和RemoteLEO任然是0，所有HW的值任然为0。 将消息内容和当前分区的HW值封装成Response返回给FollowerFollower的处理逻辑是： 将消息保存到Log文件中，同时更新LEO值 更新自己的HW值，将本地的LEO和Leader返回的HW进行比较，取最小值作为自己的HW值，此时最小值为0，所以这时的HW值为0 Follower第二次fetch消息Leader的处理逻辑是： 读取Log消息，更新RemoteLEO值（这时fetch请求的offset为1）。 更新HW值，这时Leader的LEO和RemoteLEO都是1，所有HW的值为1。 将消息内容和当前分区的HW值封装成Response返回给Follower，这个时候么有消息内容，所以只返回HW值。Follower的处理逻辑是： 如果有消息则保存消息到Log文件中，如果没有则不执行该操作，同时更新LEO值 更新自己的HW值，将本地的LEO和Leader返回的HW进行比较，取最小值作为自己的HW值，此时两个值都为1，所以这时的HW值为1到目前为止，数据同步完成。 Leader还没有处理Producer消息时Follower发送了fetch请求：当Follower发送fetch请求是，Leader中没有Producer发送消息时，这个fetch请求会被阻塞，当在指定阈值超时时间范围内有新的消息发送过来，Leader处理完成过后，该fetch请求就会被唤醒，继续执行执行的逻辑和上面一样。 kafka中是如何处理所有的Replica不工作的情况在一个分区的ISR中至少有一个副本可用时，kafka就可以保证已经Commit的消息不被丢失，但是当ISR中所有的副本都不可用时，就无法保证了，这时会有两种处理办法 等待ISR中任意一个Replica活过来，并且将其设置为Leader 等待任意一个Replica活过来，不过是不是存在于ISR副本集中，并且将其设置为Leader此时就需要在可用性和一致性上做出选择如果选择第一种方式，那么可能等待的时间较长，就意味着不可用的时间会变长；如果选择第二种方式，虽然等待的时间或许没有第一种那么长，但是因为不存在与ISR中的副本数据同步的延迟较大，所以数据的一致性就会体现出来。 ISR设计所解决的问题在分布式系统中，冗余备份是很常见的一种高可用手段，但是也会带来一些性能上的损耗，例如：在kafka中，副本中Leader和Follower副本如果采用同步的方式复制消息，那么所有Follower副本的消息都完成复制才算完成了数据的同步，那么如果个别Follower网络延迟较长或者性能本身不太好导致整个集群出现性能瓶颈甚至阻塞；如果采用异步的方式复制消息，Leader收到消息过后则返回成功，则认为该消息已被提交，Follower异步的从Leader复制消息，如果此时Follower副本复制消息比较慢，此时Leader突然宕机，重新选举Leader过后，Follower副本和Leader副本的消息存在差距，那么这个差距的消息就会被丢失。所以Kafka权衡了两种方式的有点，采用ISR副本集来确保各个Follower副本和Leader副本的延迟在阈值范围内，如果超出阈值范围，则将该Follower剔除，这个时候就可以采用同步的方式来复制消息，当Leader处理的Producer发送的消息过后，kafka只需要等待ISR副本集中的所有Follower同步完成即可认为消息被提交。","categories":[{"name":"Kafka","slug":"Kafka","permalink":"http://blog.easyjava.xyz/categories/Kafka/"}],"tags":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://blog.easyjava.xyz/tags/消息中间件/"},{"name":"Kafka","slug":"Kafka","permalink":"http://blog.easyjava.xyz/tags/Kafka/"}]},{"title":"ActiveMQ使用","slug":"ActiveMQ使用","date":"2019-11-30T02:09:29.000Z","updated":"2020-02-11T01:07:11.868Z","comments":true,"path":"2019/11/30/ActiveMQ使用/","link":"","permalink":"http://blog.easyjava.xyz/2019/11/30/ActiveMQ使用/","excerpt":"","text":"相信大家遇到过这样的场景，用户注册这个简单的功能里面集成了太多不是很重要步骤，但又不得不做。比如发送邮件、发放优惠券、发送推销短信、记录日志，这样就导致了我们注册功能特别繁重，极大的拉低了接口性能，给用户带来体验度大大降低，明明就一个注册用户信息持久化的功能居然需要做这么多不是主线流程的事情。当你遇到这样的业务场景的时候就可以考虑使用消息队列来实现解耦，经过优化过后，我们的注册功能就只需要将用户信息持久化到数据库，然后向MQ中间件发送一条消息，然后返回，如果说之前的每个操作需要一秒，那总得就需要5S，但是经过使用MQ解耦过后只需要1S左右，大大提升了用户体验。 JMSJMS(Java Message Service)是Java为各个消息中间件提供的一套统一API规范，其目的是规避各个中间件协议、接口的不同而带来的不便。以下是JMS连接流程图： 消息传递模式JMS提供两种常见的消息传递模式或域，分别是： P2P(点对点的消息传递模式):一个消息生成者对应一个消费者，两者之间不存在时间上的相关性（即，就算消费者不在线，生产者照样可以发送消息到Broker上，等消费者上线过后继续消费） PUB/SUB(发布订阅的消息传递模式):一个消息生产者对应多个消息消费者，两者之间存在时间上的相关性（即，消费者只能收到订阅过后并且在线时生产者发送的消息，但不是绝对，JMS允许消费者创建持久化订阅，持久订阅允许消费者消费他不在线时发送的消息） 消息类型或结构组成消息的结构由消息头、消息体、属性组成 消息头：消息头包含消息识别和路由信息 消息体：一般是我们发送的消息内容 消息属性：属性分为应用设置的属性、标准属性、中间件定义的属性JMS提供六种消息类型，分别是： TextMessage:文本消息 MapMessage:键值对消息，键是String类型，值可以是Java的任何类型 BytesMessage:字节流消息 StreamMessage:输入输出流消息 ObjectMessage:可序列化对象消息 Message:空消息，不包含有消息体，只有消息头和属性 ActiveMQ安装 下载 解压:tar -zxvf apache-activemq-5.15.9-bin.tar.gz 启动:sh activemq start 访问:http://localhost:8161 P2P(Queue)消息传递方式 消息生产者 public class QueueProvider { public static void main(String[] args) throws JMSException { //创建连接工厂 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(\"tcp://192.168.3.224:61616\"); //创建连接 Connection connection = connectionFactory.createConnection(); //建立连接 connection.start(); //创建会话 Session session = connection.createSession(Boolean.TRUE, Session.AUTO_ACKNOWLEDGE); //创建目的地 Destination destination = new ActiveMQQueue(\"testQueue\"); //创建消息生产者 MessageProducer producer = session.createProducer(destination); //创建消息 TextMessage message = new ActiveMQTextMessage(); message.setText(\"Hello World\"); //发送消息 producer.send(message); //提交消息事务，该方法只有在事务型会话时使用 session.commit(); //关闭会话 session.close(); //关闭连接 connection.close(); } } 消息消费者 public class QueueConsumer { public static void main(String[] args) throws JMSException { //创建连接工厂 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(\"tcp://192.168.3.224:61616\"); //创建连接 Connection connection = connectionFactory.createConnection(); //建立连接 connection.start(); //创建会话 Session session = connection.createSession(Boolean.TRUE, Session.AUTO_ACKNOWLEDGE); //创建目的地 Destination destination = new ActiveMQQueue(\"testQueue\"); //创建消费者 MessageConsumer consumer = session.createConsumer(destination); //消费消息 TextMessage message = (TextMessage)consumer.receive(); //输出消息（处理消息） System.out.println(message.getText()); //确认消息，该方法只有在事务型会话时使用 session.commit(); //关闭会话 session.close(); //关闭连接 connection.close(); } } 消息消费还可以使用监听器的方式，代码如下(片段)： //... //创建消费者 MessageConsumer consumer = session.createConsumer(destination); MessageListener messageListener = new MessageListener() { public void onMessage(Message message) { TextMessage textMessage = (TextMessage) message; System.out.println(textMessage); } }; //设置消息监听 consumer.setMessageListener(messageListener); //确认消息，该方法只有在事务型会话时使用 session.commit(); //... PUB/SUB(发布/订阅)消息传递方式 消息生产者 public class TopicProvider { public static void main(String[] args) throws JMSException { //创建连接工厂 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(\"tcp://192.168.3.224:61616\"); //创建连接 Connection connection = connectionFactory.createConnection(); //建立连接 connection.start(); //创建会话 Session session = connection.createSession(Boolean.TRUE, Session.AUTO_ACKNOWLEDGE); //创建目的地 Destination destination = new ActiveMQTopic(\"testTopic\"); //创建消息生产者 MessageProducer producer = session.createProducer(destination); //创建消息 TextMessage message = new ActiveMQTextMessage(); message.setText(\"Hello World\"); //发送消息 producer.send(message); //提交消息事务，该方法只有在事务型会话时使用 session.commit(); //关闭会话 session.close(); //关闭连接 connection.close(); } } 消息消费者 public class TopicConsumer { public static void main(String[] args) throws JMSException { //创建连接工厂 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(\"tcp://192.168.3.224:61616\"); //创建连接 Connection connection = connectionFactory.createConnection(); //建立连接 connection.start(); //创建会话 Session session = connection.createSession(Boolean.TRUE, Session.AUTO_ACKNOWLEDGE); //创建目的地 Destination destination = new ActiveMQTopic(\"testTopic\"); //创建消费者 MessageConsumer consumer = session.createConsumer(destination); //消费消息 TextMessage message = (TextMessage)consumer.receive(); //输出消息（处理消息） System.out.println(message.getText()); //确认消息，该方法只有在事务型会话时使用 session.commit(); //关闭会话 session.close(); //关闭连接 connection.close(); } } 前面讲到JMS允许消费者创建持久化订阅，持久订阅允许消费者消费他不在线时发送的消息，实现这一需求需要改动消费者三个地方，分别是： public class TopicConsumer { public static void main(String[] args) throws JMSException { //创建连接工厂 ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(\"tcp://192.168.3.224:61616\"); //创建连接 Connection connection = connectionFactory.createConnection(); //配置客户端ID connection.setClientID(\"MrAToo-001\");//[1] //建立连接 connection.start(); //创建会话 Session session = connection.createSession(Boolean.TRUE, Session.AUTO_ACKNOWLEDGE); //创建目的地 Topic destination = new ActiveMQTopic(\"testTopic\");//[2] //创建消费者 MessageConsumer consumer = session.createDurableSubscriber(destination,\"MrAToo-001\");//[3] //消费消息 TextMessage message = (TextMessage)consumer.receive(); //输出消息（处理消息） System.out.println(message.getText()); //确认消息，该方法只有在事务型会话时使用 session.commit(); //关闭会话 session.close(); //关闭连接 connection.close(); } } 标注[1]:connection.setClientID(&quot;MrAToo-001&quot;);为客户的设置一个ID 标注[2]:Topic destination = new ActiveMQTopic(&quot;testTopic&quot;);接受参数使用Destination的子类Topic 标注[3]:MessageConsumer consumer = session.createDurableSubscriber(destination,&quot;MrAToo-001&quot;);调用session.createDurableSubscriber方法 通过上面的配置，在Broker上会存在一条客户端记录 JMS消息的可靠方式正常情况下，消息消费有三个阶段：消息接收、消息处理、消息确认，在消息在被收到处理完毕并且确认过后被视为消息被成功消费。 事务型会话在事务型会话中，消息生产者和消息消费者均需要调用session.commit方法，对于生产者而言，commit表示消息提交，只有提交的消息才会存在Broker中，才能被消费者消费对于消费者而言，commit表示消息被确认，只有被确认的消息，Broker才不会再次重发消息，很大程度上能避免消息重发的问题（但是并不能正在意义上解决消息的重复消费）。相反的还有session.rollback，该方法表示对之前做的所有操作进行作废处理，对于生成者而言，已经发送的消息回滚。对于消费者而言，当前消息标记为未接受，Broker会重发消息。 注意：必须保证生产者和消费者都是事务型会话 非事务型会话在非事务型会话中，消息何时被确认取决于创建会话时的应答模式(acknowledgement mode)，应答模式有三种： Session.AUTO_ACKNOWLEDGE(自动确认):消息在被收到时自动确认消息 Session.CLIENT_ACKNOWLEDGE(手动确认):消费者在收到消息过后，处理完毕通过手动调用message.acknowledge();进行手动确认，需要注意的是：该方法确认该会话中所有被处理的消息。 Session.DUPS_ACKNOWLEDGE(消息延迟确认):该选择只是会话迟钝的确认消息的提交 消息的持久化存储非持久化该模式不会将消息存储到可靠的存储介质中（例如：磁盘，DB），只会存在于内存中，如果Broker出现宕机，则消息会丢失 持久化该模式会将生产者发送到Broker的消息持久化到可靠存储介质中，即使是Broker出现宕机，也不会出现消息丢失的情况，但是，由于生产者或者消费者在发送或者确认消息的过程中，Broker需要将消息从可靠存储介质中保存或者删除，从而带来了IO开销，性能上比非持久化存储方式相对来说较低 持久化消息和非持久化消息的发送策略消息的同步发送和异步发送同步发送：消息生产者发送一条消息到Broker上，会被阻塞直到Broker返回一条确认收到ACK，线程才会被释放，该方式确保了消息的可靠投递，但由于会阻塞，因此会有性能上的损耗。异步发送：消息生产者发送一条消息过后立即返回，当Broker处理完成过后，会回调返回消息确认ACK，这种方式性能相对较高，但丢失消息的可能性相对较高。 默认情况下：非持久化的消息都是异步发送的。持久化消息在非事务模式下是同步发送的。在开启事务的情况下，消息都是异步发送。 除了默认的发送策略外，我们可以设置消息发送的策略，通过在连接URL中添加参数tcp://localhost:61616?jms.useAsyncSend=true，也可以调用ActiveMQConnectionFactory的setUseAsyncSend为true 消息发送原理分析源码分析我们从producer.send(message);开始，当然前面还有producer的创建过程，先不看。producer.send(message);方法首先会调用到ActiveMQMessageProducer的send方法。该方法如下： class ActiveMQMessageProducer { public void send(Destination destination, Message message, int deliveryMode, int priority, long timeToLive, AsyncCallback onComplete) throws JMSException { checkClosed(); if (destination == null) { if (info.getDestination() == null) { throw new UnsupportedOperationException(\"A destination must be specified.\"); } throw new InvalidDestinationException(\"Don't understand null destinations\"); } ActiveMQDestination dest; if (destination.equals(info.getDestination())) { dest = (ActiveMQDestination)destination; } else if (info.getDestination() == null) { dest = ActiveMQDestination.transform(destination); } else { throw new UnsupportedOperationException(\"This producer can only send messages to: \" + this.info.getDestination().getPhysicalName()); } if (dest == null) { throw new JMSException(\"No destination specified\"); } if (transformer != null) { Message transformedMessage = transformer.producerTransform(session, this, message); if (transformedMessage != null) { message = transformedMessage; } } if (producerWindow != null) { try { producerWindow.waitForSpace(); } catch (InterruptedException e) { throw new JMSException(\"Send aborted due to thread interrupt.\"); } } this.session.send(this, dest, message, deliveryMode, priority, timeToLive, producerWindow, sendTimeout, onComplete); stats.onMessage(); } } 该方法中首先判断当前会话状态是否关闭，然后如果producerWindow不为null则判断当前消息根据发送窗口的大小判断是否阻塞，最后调用ActiveMQSession的send方法，该方法如下： class ActiveMQSession { protected void send(ActiveMQMessageProducer producer, ActiveMQDestination destination, Message message, int deliveryMode, int priority, long timeToLive, MemoryUsage producerWindow, int sendTimeout, AsyncCallback onComplete) throws JMSException { checkClosed(); if (destination.isTemporary() &amp;&amp; connection.isDeleted(destination)) { throw new InvalidDestinationException(\"Cannot publish to a deleted Destination: \" + destination); } synchronized (sendMutex) { // tell the Broker we are about to start a new transaction doStartTransaction();//[1] TransactionId txid = transactionContext.getTransactionId(); long sequenceNumber = producer.getMessageSequence(); //Set the \"JMS\" header fields on the original message, see 1.1 spec section 3.4.11 message.setJMSDeliveryMode(deliveryMode); long expiration = 0L; if (!producer.getDisableMessageTimestamp()) { long timeStamp = System.currentTimeMillis(); message.setJMSTimestamp(timeStamp); if (timeToLive > 0) { expiration = timeToLive + timeStamp; } } message.setJMSExpiration(expiration);//[2] message.setJMSPriority(priority);//[3] message.setJMSRedelivered(false);//[4] // transform to our own message format here ActiveMQMessage msg = ActiveMQMessageTransformation.transformMessage(message, connection); msg.setDestination(destination); msg.setMessageId(new MessageId(producer.getProducerInfo().getProducerId(), sequenceNumber)); // Set the message id. if (msg != message) { message.setJMSMessageID(msg.getMessageId().toString()); // Make sure the JMS destination is set on the foreign messages too. message.setJMSDestination(destination); } //clear the brokerPath in case we are re-sending this message msg.setBrokerPath(null); msg.setTransactionId(txid); if (connection.isCopyMessageOnSend()) { msg = (ActiveMQMessage)msg.copy(); } msg.setConnection(connection); msg.onSend(); msg.setProducerId(msg.getMessageId().getProducerId()); if (LOG.isTraceEnabled()) { LOG.trace(getSessionId() + \" sending message: \" + msg); } //[5] if (onComplete==null &amp;&amp; sendTimeout &lt;= 0 &amp;&amp; !msg.isResponseRequired() &amp;&amp; !connection.isAlwaysSyncSend() &amp;&amp; (!msg.isPersistent() || connection.isUseAsyncSend() || txid != null)) { this.connection.asyncSendPacket(msg); if (producerWindow != null) { // Since we defer lots of the marshaling till we hit the // wire, this might not // provide and accurate size. We may change over to doing // more aggressive marshaling, // to get more accurate sizes.. this is more important once // users start using producer window // flow control. //[6] int size = msg.getSize(); producerWindow.increaseUsage(size); } } else { if (sendTimeout > 0 &amp;&amp; onComplete==null) { this.connection.syncSendPacket(msg,sendTimeout); }else { this.connection.syncSendPacket(msg, onComplete); } } } } } 该方法中也是先判断当前会话，然后采用同步的方式有序的执行. 标注[1]:这里表示开启一个事务 标注[2]:设置过期时间 标注[3]:设置优先级 标注[4]:设置为非重发消息 标注[5]:这里的if判断决定消息是异步发送还是同步发送，这里有两种情况：当onComplete没有设置，并且发送超时时间小于0，并且不是必须返回response响应，并且不是同步发送模式，并且消息是非持久化或者连接器是异步发送模式或者存在事务ID时走异步发送，否则走同步发送 标注[6]:异步发送会设置消息发送的大小 异步发送异步发送会调用ActiveMQConnection中的doAsyncSendPacket方法，该方法中会调用transport.oneway方法，那么这里的transport是什么呢，其实transport在创建ActiveMQConnection链接的时候就已经创建了代码在ActiveMQConnectionFactory.createActiveMQConnection方法中，Transport transport = createTransport();通过createTransport方法创建一个transport，代码如下： class ActiveMQConnectionFactory{ protected Transport createTransport() throws JMSException { try { URI connectBrokerUL = brokerURL; String scheme = brokerURL.getScheme(); if (scheme == null) { throw new IOException(\"Transport not scheme specified: [\" + brokerURL + \"]\"); } if (scheme.equals(\"auto\")) { connectBrokerUL = new URI(brokerURL.toString().replace(\"auto\", \"tcp\")); } else if (scheme.equals(\"auto+ssl\")) { connectBrokerUL = new URI(brokerURL.toString().replace(\"auto+ssl\", \"ssl\")); } else if (scheme.equals(\"auto+nio\")) { connectBrokerUL = new URI(brokerURL.toString().replace(\"auto+nio\", \"nio\")); } else if (scheme.equals(\"auto+nio+ssl\")) { connectBrokerUL = new URI(brokerURL.toString().replace(\"auto+nio+ssl\", \"nio+ssl\")); } return TransportFactory.connect(connectBrokerUL); } catch (Exception e) { throw JMSExceptionSupport.create(\"Could not create Transport. Reason: \" + e, e); } } } 通过TransportFactory.connect静态方法创建一个Transport class TransportFactory { private static final FactoryFinder TRANSPORT_FACTORY_FINDER = new FactoryFinder(\"META-INF/services/org/apache/activemq/transport/\"); public static Transport connect(URI location) throws Exception { TransportFactory tf = findTransportFactory(location); return tf.doConnect(location); } public static TransportFactory findTransportFactory(URI location) throws IOException { String scheme = location.getScheme(); if (scheme == null) { throw new IOException(\"Transport not scheme specified: [\" + location + \"]\"); } TransportFactory tf = TRANSPORT_FACTORYS.get(scheme); if (tf == null) { // Try to load if from a META-INF property. try { tf = (TransportFactory)TRANSPORT_FACTORY_FINDER.newInstance(scheme); TRANSPORT_FACTORYS.put(scheme, tf); } catch (Throwable e) { throw IOExceptionSupport.create(\"Transport scheme NOT recognized: [\" + scheme + \"]\", e); } } return tf; } } 这里大概的逻辑是：先从META-INF/services/org/apache/activemq/transport/路径下找到指定scheme(这里的scheme是tcp)然后通过反射加载得到org.apache.activemq.transport.tcp.TcpTransportFactory，然后调用TcpTransportFactory的doConnect(该方法在父类TransportFactory中实现)，在该方法中，有这样一句代码Transport rc = configure(transport, wf, options);，该方法代码如下： class TransportFactory { public Transport configure(Transport transport, WireFormat wf, Map options) throws Exception { transport = compositeConfigure(transport, wf, options); transport = new MutexTransport(transport); transport = new ResponseCorrelator(transport); return transport; } } 该方法的作用是包装Transport，所以，最终得到的是ResponseCorrelator(MutexTransport(WireFormatNegotiator(InactivityMonitor(TcpTransport))))调用链，这是几个Filter，这几个Filter大致的作用是： ResponseCorrelator：用于实现异步请求 MutexTransport：实现写锁，作用是保证了客户端向Broker发送消息时是按照顺序进行的，即同一时间只允许一个请求 InactivityMonitor：心跳机制，客户端每10s发送一次心跳，服务端每30s接受一次心跳 WireFormatNegotiator：实现客户端连接Broker时先发送协议数据信息然后调用TcpTransportFactory的createTransport方法，最终new TcpTransport对象，然后回到ActiveMQConnectionFactory中，在createActiveMQConnection方法中调用了transport.start方法，这里在后面讲。在这里面建立和Broker的连接，然后将该连接的Socket输出流保存到dataOut对象中。 回到ActiveMQConnection中的doAsyncSendPacket方法中，调用transport.oneway方法，其实是调用的TcpTransport.oneway方法，这里会通过dataOut将消息发送到Broker上。 同步发送在ActiveMQ中，同步发送其实也是调用的异步发送的方法，然后阻塞等待异步结果返回。 持久化消息和非持久化消息的存储原理当我们的应用场景不允许消息的丢失的时候，可以采用消息的持久化存储的方式来达到消息的永久存在，ActiveMQ支持五种消息的持久化机制。 持久化消息的物种存储方式 KahaDB：默认ActiveMQ官方推荐的消息持久化方式，配置方式：&lt;persistenceAdapter> &lt;kahaDB directory=\"${activemq.data}/kahadb\"/> &lt;/persistenceAdapter> JDBC：将消息持久化到关系型数据库中，支持MySQL，Oracle等主流数据库，该方式会在数据库中生成三张表，分别是： ACTIVEMQ_MSGS:用于存储持久化消息，Queue和Topic消息都在该表中 ACTIVEMQ_ACKS:存储持久订阅消息和最后一个持久订阅接收的消息ID ACTIVEMQ_LOCKS:锁表，用来确保同一时刻只有一个Broker访问数据配置方式：&lt;persistenceAdapter> &lt;jdbcPersistenceAdapter dataSource=\"#MySQL-DS \" createTablesOnStartup=\"true\" /> &lt;/persistenceAdapter> LevelDB：性能高于KahaDB，并且支持LevelDB+Zookeeper实现数据复制，但是官方不推荐 Memory：内存，不做消息的持久化时的默认方式 JDBC With ActiveMQ Journal：该方式是为了优化JDBC的方式，延迟批量将消息持久化到关系型数据库中，ActiveMQ Journal使用高缓存写入技术，大大提示性能，当消费者的消费能力很强的时候能大大减少关系型数据库的事务操作，配置方式：&lt;persistenceFactory> &lt;journalPersistenceAdapterFactory dataSource=\"#Mysql-DS\" dataDirectory=\"activemqdata\"/> &lt;/persistenceFactory> 消息消费原理分析消息消费从ActiveMQMessageConsumer的receive开始，该方法首先检查连接，然后检查是否设置了Listener（ActiveMQ消费端只允许一种方式接受消息，原因是多种方式消息消费的事务性不好管控），然后判断prefetchSize和unconsumeMessages是否为空，如果为空则向Broker发送一个拉取消息的pull命令，然后调用dequeue方法，该方法从unConsumeMessages中获取一个消息（如果unConsumeMessages中没有消息，则会阻塞当前线程直到Brokerpush一个消息或者超时释放），unConsumeMessages是一个未消费消息的通道，该通道的作用是每次从Broker上拉取prefetchSize条消息保存到本地，减少了客户端和服务端频繁请求造成的网络开销。继续往下，会调用beforeMessageIsConsumed(md);方法，该方法主要作用是做一些消息消费前的一些准备工作，如果ACK类型不是DUPS_OK_ACKNOWLEDGE或者不是队列类型（也就是除了Topic类型和DUPS_OK_ACKNOWLEDGE）所有的消息先放到deliveredMessages链表的开头，并且如果是事务类型，则判断transactedIndividualAck，如果是true，表示单条消息直接返回ACK，否则，调用ackLater批量应答，消费端在消费消息过后，先不发送ACK(pendingACK)，等到堆积的pendingACK达到一定的阈值过后，通过一个ACK指定将之前的所有全部确认，在性能上，这种方式会高很多。然后继续往下，会调用afterMessageIsConsumed方法，该方法主要作用是执行应答，这里有以下几种情况 如果消息过期，则返回消息过期的ack 如果是事务类型的会话，则不做任何处理 如果是AUTOACK或者（DUPS_OK_ACK且是队列），并且是优化ack操作，则走批量确认ack 如果是DUPS_OK_ACK，则走ackLater逻辑 如果是CLIENT_ACK，则执行ackLater代码如下： class ActiveMQMessageConsumer { private void afterMessageIsConsumed(MessageDispatch md, boolean messageExpired) throws JMSException { if (unconsumedMessages.isClosed()) { return; } if (messageExpired) { acknowledge(md, MessageAck.EXPIRED_ACK_TYPE); stats.getExpiredMessageCount().increment(); } else { stats.onMessage(); if (session.getTransacted()) { // Do nothing. } else if (isAutoAcknowledgeEach()) { if (deliveryingAcknowledgements.compareAndSet(false, true)) { synchronized (deliveredMessages) { if (!deliveredMessages.isEmpty()) { if (optimizeAcknowledge) { ackCounter++; // AMQ-3956 evaluate both expired and normal msgs as // otherwise consumer may get stalled if (ackCounter + deliveredCounter >= (info.getPrefetchSize() * .65) || (optimizeAcknowledgeTimeOut > 0 &amp;&amp; System.currentTimeMillis() >= (optimizeAckTimestamp + optimizeAcknowledgeTimeOut))) { MessageAck ack = makeAckForAllDeliveredMessages(MessageAck.STANDARD_ACK_TYPE); if (ack != null) { deliveredMessages.clear(); ackCounter = 0; session.sendAck(ack); optimizeAckTimestamp = System.currentTimeMillis(); } // AMQ-3956 - as further optimization send // ack for expired msgs when there are any. // This resets the deliveredCounter to 0 so that // we won't sent standard acks with every msg just // because the deliveredCounter just below // 0.5 * prefetch as used in ackLater() if (pendingAck != null &amp;&amp; deliveredCounter > 0) { session.sendAck(pendingAck); pendingAck = null; deliveredCounter = 0; } } } else { MessageAck ack = makeAckForAllDeliveredMessages(MessageAck.STANDARD_ACK_TYPE); if (ack!=null) { deliveredMessages.clear(); session.sendAck(ack); } } } } deliveryingAcknowledgements.set(false); } } else if (isAutoAcknowledgeBatch()) { ackLater(md, MessageAck.STANDARD_ACK_TYPE); } else if (session.isClientAcknowledge()||session.isIndividualAcknowledge()) { boolean messageUnackedByConsumer = false; synchronized (deliveredMessages) { messageUnackedByConsumer = deliveredMessages.contains(md); } if (messageUnackedByConsumer) { ackLater(md, MessageAck.DELIVERED_ACK_TYPE); } } else { throw new IllegalStateException(\"Invalid session state.\"); } } } } unconsumedMessages数据获取过程unconsumedMessages未消费的消息通道是在什么时候被赋值的，这应该从连接的创建过程说起，在ActiveMQConnectionFactory#createActiveMQConnection连接创建是调用了TcpTransport#start方法（实际上是ServiceSupport#start），该方法中调用TcpTransport#doStart，在该方法中通过connect方法和Broker创建连接，然后调用TransportThreadSupport#doStart，该方法中创建了一个线程，线程的内容在TcpTransport中，也就是TcpTransport#run，然后在该方法中，只要TcpTransport没有停止，则一直调用TcpTransport#doRun，然后调用Object command = readCommand();从Broker上读取一个command，最后调用TransportSupport#doConsume消费消息。整个过程调用链如下： ActiveMQConnectionFactory#createConnection -&gt; ActiveMQConnectionFactory#createActiveMQConnection -&gt; ServiceSupper#start -&gt; TcpTransport#doStart -&gt; TransportThreadSupport#doStart -&gt; TcpTransport#run -&gt; TcpTransport#doRun -&gt; TransportSupport#doConsume -&gt; ActiveMQConnection#onCommandActiveMQConnection#onCommand该方法中所有消息都会调用visit方法，该方法接受一个CommandVisitor，针对不同的消息做不同的处理，代码如下： class ActiveMQConnection { public void onCommand(final Object o) { final Command command = (Command)o; if (!closed.get() &amp;&amp; command != null) { try { command.visit(new CommandVisitorAdapter() { @Override public Response processMessageDispatch(MessageDispatch md) throws Exception { waitForTransportInterruptionProcessingToComplete(); ActiveMQDispatcher dispatcher = dispatchers.get(md.getConsumerId()); if (dispatcher != null) { // Copy in case a embedded broker is dispatching via // vm:// // md.getMessage() == null to signal end of queue // browse. Message msg = md.getMessage(); if (msg != null) { msg = msg.copy(); msg.setReadOnlyBody(true); msg.setReadOnlyProperties(true); msg.setRedeliveryCounter(md.getRedeliveryCounter()); msg.setConnection(ActiveMQConnection.this); msg.setMemoryUsage(null); md.setMessage(msg); } dispatcher.dispatch(md); } else { LOG.debug(\"{} no dispatcher for {} in {}\", this, md, dispatchers); } return null; } @Override public Response processProducerAck(ProducerAck pa) throws Exception { if (pa != null &amp;&amp; pa.getProducerId() != null) { ActiveMQMessageProducer producer = producers.get(pa.getProducerId()); if (producer != null) { producer.onProducerAck(pa); } } return null; } @Override public Response processBrokerInfo(BrokerInfo info) throws Exception { brokerInfo = info; brokerInfoReceived.countDown(); optimizeAcknowledge &amp;= !brokerInfo.isFaultTolerantConfiguration(); getBlobTransferPolicy().setBrokerUploadUrl(info.getBrokerUploadUrl()); return null; } @Override public Response processConnectionError(final ConnectionError error) throws Exception { executor.execute(new Runnable() { @Override public void run() { onAsyncException(error.getException()); } }); return null; } @Override public Response processControlCommand(ControlCommand command) throws Exception { return null; } @Override public Response processConnectionControl(ConnectionControl control) throws Exception { onConnectionControl((ConnectionControl)command); return null; } @Override public Response processConsumerControl(ConsumerControl control) throws Exception { onConsumerControl((ConsumerControl)command); return null; } @Override public Response processWireFormat(WireFormatInfo info) throws Exception { onWireFormatInfo((WireFormatInfo)command); return null; } }); } catch (Exception e) { onClientInternalException(e); } } for (Iterator&lt;TransportListener> iter = transportListeners.iterator(); iter.hasNext();) { TransportListener listener = iter.next(); listener.onCommand(command); } } } 如果传入的消息是MessageDispatch，则会调用processMessageDispatch方法，在该方法中最终会调用ActiveMQMessageConsumer中的dispatch方法，unConsumedMessages的值就是在该方法中enqueue的。 总结：消费者在启动的时候会创建一个线程不断的从客户端和Broker的Socket连接中读取数据，然后交给TransportListener（这里的实现是ActiveMQConnection）处理，消息的消费其实是从一个未消费的消息通道unConsumedMessages里面拿的，拿消息之前会判断当前unConsumedMessages中是否存在未消费的消息，如果不存在消息并且prefetchSize等于0，则向Broker发送一条pullCommand指令，然后调用dequeue方法（该方法会被阻塞知道拿到消息后返回），然后Broker会向客户端push指定条数（prefetchSize）的消息（这里是异步实现，消息会被Transport线程读取，然后交给ActiveMQConnection#onCommand监听器分发消息，最终会把消息enqueue到unConsumedMessages中），当unConsumedMessages有消息过后，dequeue方法解除阻塞，返回消息，然后执行消息确认过程。 prefetchSize与optimizeAcknowledge prefetchSize:窗口机制（消息的批量拉取）不同的类型的队列，prefetchSize 的默认值也是不一样的，如下： 持久化队列和非持久化Queue（队列），prefetchSize默认值为1000； 持久化 topic ，prefetchSize 默认值为100； 非持久化消息，prefetchSize 默认值为 Short.MAX_VALUE -1 配置方式： Destination destination = session.createQueue(&quot;myQueue?consumer.prefetchSize=88&quot;); optimizeAcknowledge:消息优化确认，优化ACK，只有optimizeAcknowledge为true时，prefetchSize和optimizeAcknowledgeTimeout才有意义。消息的批量确认，也是一种减少网络开销的一种手段，如果我们不开启优化ACK，那么Brokerpush一批消息到客户端过后，客户端消费一条消息向Broker确认一次，Broker向客户端push一条消息，这样达不到批量的效果（假批量），所以一般情况下，这两个配置是同事存在的，默认消息消费超过65%会发送一次批量确认（也就是1000*.65=650）。 配置方式： ConnectionFactory connectionFactory= new ActiveMQConnectionFactory(&quot;tcp://localhost:61616?jms.optimizeAcknowledge=true&amp;jms.optimizeAcknowledgeTimeOut=10000&quot;);消息的重发机制正常情况下，触发消息重发的有两种情况 事务性会话中，没有调用session.commit或者调用session.rollback 非事务性会话中，没有调用acknowledge或者调用recover 一个消息被redelivedred超过6次，客户端会给Broker发送一个poisonACK，告诉Broker不要再重发消息了，然后Broker会将该条消息放入到DLQ（死信队列）中。 死信队列ActiveMQ中默认的死信队列是ActiveMQ.DLQ，没有特殊的的配置，重发超过6次的消息都会被放到该队列中，默认情况下，如果持久消息过期后，也会被放到该死信队列中。默认所有队列的死信队列都是ActiveMQ.DLQ，不便于管理，可以通过配置来针对某个队列配置特定的私信队列，配置如下： &lt;destinationPolicy> &lt;policyMap> &lt;policyEntries> &lt;policyEntry topic=\">\" > &lt;pendingMessageLimitStrategy> &lt;constantPendingMessageLimitStrategy limit=\"1000\"/> &lt;/pendingMessageLimitStrategy> &lt;/policyEntry> &lt;!-->:表示对所有队列生效，指定队列直接写队列名称--> &lt;policyEntry queue=\">\"> &lt;deadLetterStrategy> &lt;!--queuePrefix:设置死信队列前缀--> &lt;individualDeadLetterStrategy queuePrefix=\"DLQ.\" useQueueForQueueMessages=\"true\" processExpired=\"false\"/> &lt;!--是否丢弃过期消息--> &lt;!--&lt;sharedDeadLetterStrategy processExpired=\"false\" />--> &lt;/deadLetterStrategy> &lt;/policyEntry> &lt;/policyEntries> &lt;/policyMap> &lt;/destinationPolicy> 死信队列的再次消费死信队列也是一个队列，在定位到问题原因过后，可以手动消费死信队列的消息。 ActiveMQ静态网络配置ActiveMQ支持使用网络配置的方式来达到集群的效果，ActiveMQ中的网络配置方式有两种，静态网络配置和动态网络配置。 静态网络配置，配置方式如下 &lt;networkConnectors> &lt;networkConnector uri=\"static://(tcp://192.168.10.1:61616,tcp://192.168.10.2:61616)\" duplex=\"true\"/> &lt;/networkConnectors> 动态网络配置，该方式使用广播协议将其他的Broker连接起来，可以自动发现其他的Broker节点，这种方式替代了静态网络连接配置方式。 消息回流：从5.6版本开始，ActiveMQ的网络配置方式集群支持消息回流，该功能解决了当Broker1上有需要转发的消息未消费时，将消息回流到原来的Broker上。需要配置如下： &lt;policyEntry queue=\">\" enableAudit=\"false\"> &lt;networkBridgeFilterFactory> &lt;conditionalNetworkBridgeFilterFactory replayWhenNoConsumers=\"true\"/> &lt;/networkBridgeFilterFactory> &lt;/policyEntry> 配置消息回流需要配置networkConnector节点的duplex的属性为true。 参考文献 https://blog.csdn.net/lzb348110175/article/details/100132006","categories":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://blog.easyjava.xyz/categories/ActiveMQ/"}],"tags":[{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://blog.easyjava.xyz/tags/ActiveMQ/"},{"name":"JMS","slug":"JMS","permalink":"http://blog.easyjava.xyz/tags/JMS/"}]},{"title":"Dubbo源码分析","slug":"Dubbo源码分析","date":"2019-11-21T13:18:50.000Z","updated":"2020-02-11T01:07:11.876Z","comments":true,"path":"2019/11/21/Dubbo源码分析/","link":"","permalink":"http://blog.easyjava.xyz/2019/11/21/Dubbo源码分析/","excerpt":"","text":"Dubbo SPIDubbo SPI使用以及规范 创建接口并且加上@SPI注解表示该接口是一个Dubbo扩展点，将该扩展点打成一个jar包发布@SPI public interface IHelloService { String sayHello(String msg); } 在需要实现的扩展插件项目中依赖以上接口扩展点，并且实现该接口扩展点public class HelloServiceImpl implements IHelloService { @Override public String sayHello(String msg) { return \"Dubbo SPI Hello:\" + msg; } } 并且在resources目录先创建META-INF/dubbo/(META-INF/dubbo/;META-INF/dubbo/internal/;META-INF/services/;任选一个)目录，并且在该目录下创建以扩展点接口为名称的文件：xyz.easyjava.dubbo.spi.extend.service.IHelloService在该文件中填写该扩展点实现的名称以及实现类的全路径，例如：hello=xyz.easyjava.dubbo.spi.achieve.service.HelloServiceImpl hello2=xyz.easyjava.dubbo.spi.achieve.service.HelloServiceImpl2 现在就可以在需要使用该扩展的地方使用了，方式如下：public class DubboSpiTest { public static void main(String[] args) { IHelloService extension = ExtensionLoader.getExtensionLoader(IHelloService.class).getExtension(\"hello2\"); System.out.println(extension.sayHello(\"MrAToo\")); IHelloService adaptiveExtension = ExtensionLoader.getExtensionLoader(IHelloService.class).getAdaptiveExtension(); System.out.println(adaptiveExtension.sayHello(\"MrAToo2\")); } } 源码分析先从ExtensionLoader.getExtensionLoader(IHelloService.class).getAdaptiveExtension();开始 首先是调用了ExtensionLoader类的静态方法getExtensionLoader(IHelloService.class)，在该方法中除了校验，主要是实例化了一个ExtensionLoader实例，并且在ExtensionLoader的构造方法中通过objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension());创建了一个objectFactory对象，该对象是一个ExtensionFactory 得到ExtensionLoader实例对象过后，调用了该对象的getAdaptiveExtension()方法，在该方法中调用createAdaptiveExtension()创建实例，在createAdaptiveExtension()里面调用injectExtension((T) getAdaptiveExtensionClass().newInstance());，该方法是一个注入的方法，先不看injectExtension()方法是如何注入的，我们先看实例是如何创建的，很显然，实例作为injectExtension()方法的参数传入，那么getAdaptiveExtensionClass().newInstance()这句代码中的getAdaptiveExtensionClass()方法返回的Class中T是如何确定的。在getAdaptiveExtensionClass()方法中，首先调用了getExtensionClasses();然后判断cachedAdaptiveClass是否为null，如果不为null，则直接返回cachedAdaptiveClass，那么再看看getExtensionClasses();方法中又干了什么，在该方法中又调用了loadExtensionClasses()，下面来看看该方法的代码： private Map&lt;String, Class&lt;?>> loadExtensionClasses() { final SPI defaultAnnotation = type.getAnnotation(SPI.class); if (defaultAnnotation != null) { String value = defaultAnnotation.value(); if ((value = value.trim()).length() > 0) { String[] names = NAME_SEPARATOR.split(value); if (names.length > 1) { throw new IllegalStateException(\"more than 1 default extension name on extension \" + type.getName() + \": \" + Arrays.toString(names)); } if (names.length == 1) { cachedDefaultName = names[0]; } } } Map&lt;String, Class&lt;?>> extensionClasses = new HashMap&lt;String, Class&lt;?>>(); loadDirectory(extensionClasses, DUBBO_INTERNAL_DIRECTORY, type.getName()); loadDirectory(extensionClasses, DUBBO_INTERNAL_DIRECTORY, type.getName().replace(\"org.apache\", \"com.alibaba\")); loadDirectory(extensionClasses, DUBBO_DIRECTORY, type.getName()); loadDirectory(extensionClasses, DUBBO_DIRECTORY, type.getName().replace(\"org.apache\", \"com.alibaba\")); loadDirectory(extensionClasses, SERVICES_DIRECTORY, type.getName()); loadDirectory(extensionClasses, SERVICES_DIRECTORY, type.getName().replace(\"org.apache\", \"com.alibaba\")); return extensionClasses; } 首先是判断type的类对象是否包含@SPI注解，如果包含该注解，则将该注解的value值放到cachedDefaultName属性中（该属性在createAdaptiveExtensionClassCode方法中使用到，可以通过getDefaultExtensionName方法获取默认扩展点，如果自适应扩展点中URL协议为空该值可以作为默认协议），最后调用loadDirectory(extensionClasses, DUBBO_DIRECTORY, type.getName());分别加载META-INF/dubbo/;META-INF/dubbo/internal/;META-INF/services/;三个目录下的文件，最终会调用一下方法 /** * extensionClasses: 扩展类集合 * resourceURL: 资源URL * clazz: 扩展类Class（实现了扩展接口的类，配置在接口文件中的Class） * name: 名称 */ private void loadClass(Map&lt;String, Class&lt;?>> extensionClasses, java.net.URL resourceURL, Class&lt;?> clazz, String name) throws NoSuchMethodException { if (!type.isAssignableFrom(clazz)) { throw new IllegalStateException(\"Error when load extension class(interface: \" + type + \", class line: \" + clazz.getName() + \"), class \" + clazz.getName() + \"is not subtype of interface.\"); } if (clazz.isAnnotationPresent(Adaptive.class)) { if (cachedAdaptiveClass == null) { cachedAdaptiveClass = clazz; } else if (!cachedAdaptiveClass.equals(clazz)) { throw new IllegalStateException(\"More than 1 adaptive class found: \" + cachedAdaptiveClass.getClass().getName() + \", \" + clazz.getClass().getName()); } } else if (isWrapperClass(clazz)) { Set&lt;Class&lt;?>> wrappers = cachedWrapperClasses; if (wrappers == null) { cachedWrapperClasses = new ConcurrentHashSet&lt;Class&lt;?>>(); wrappers = cachedWrapperClasses; } wrappers.add(clazz); } else { clazz.getConstructor(); if (name == null || name.length() == 0) { name = findAnnotationName(clazz); if (name.length() == 0) { throw new IllegalStateException(\"No such extension name for the class \" + clazz.getName() + \" in the config \" + resourceURL); } } String[] names = NAME_SEPARATOR.split(name); if (names != null &amp;&amp; names.length > 0) { Activate activate = clazz.getAnnotation(Activate.class); if (activate != null) { cachedActivates.put(names[0], activate); } else { // support com.alibaba.dubbo.common.extension.Activate com.alibaba.dubbo.common.extension.Activate oldActivate = clazz.getAnnotation(com.alibaba.dubbo.common.extension.Activate.class); if (oldActivate != null) { cachedActivates.put(names[0], oldActivate); } } for (String n : names) { if (!cachedNames.containsKey(clazz)) { cachedNames.put(clazz, n); } Class&lt;?> c = extensionClasses.get(n); if (c == null) { extensionClasses.put(n, clazz); } else if (c != clazz) { throw new IllegalStateException(\"Duplicate extension \" + type.getName() + \" name \" + n + \" on \" + c.getName() + \" and \" + clazz.getName()); } } } } } 先看第一个判断clazz.isAnnotationPresent(Adaptive.class)，如果扩展类包含@Adaptive注解，则将该扩展作为自定义适配扩展点，赋值给cachedAdaptiveClass，前面提到在getExtensionClasses方法中，如果cachedAdaptiveClass值不为null，则直接返回，所以，当实现接口的类上有@Adaptive注解，则getAdaptiveExtension();返回的实例就是当前实例，即自定义适配扩展点。 再看第二个判断isWrapperClass(clazz),判断当前这个扩展是不是一个wrapper，如果是，则将该扩展类放入到cachedWrapperClasses中，该变量在getExtension方法调用链createExtension方法中被使用，大概源码内容为，如果cachedWrapperClasses变量有值，则需要包装原始对象。 如果以上两个条件都不成立，则走else逻辑，在该逻辑中，首先判断当前扩展类中是否包含@Activate注解，如果包含，则put到cachedActivates中。在判断cachedNames中是否包含当前扩展类的类对象，如果不存在，则将class放到cachedNames里面，最后循环将name作为key，class作为value放到extensionClasses中。 我们在回过头来看，在getAdaptiveExtensionClass方法中，如果cachedAdaptiveClass为null，则会调用createAdaptiveExtensionClass方法，并且将该方法的返回值放入到cachedAdaptiveClass中，然后返回。在createAdaptiveExtensionClass方法中，通过调用createAdaptiveExtensionClassCode方法返回一串代码，然后动态编译生成Class对象，然后返回。那么在createAdaptiveExtensionClassCode（该方法主要是生成一个代理类）中，这串代码到底是什么，又是如何生成的呢？首先，dubbo只会为该接口中带有@Adaptive注解的方法进行代理，如果该接口中没有带@Adaptive注解的方法，则会抛出异常，并且，Dubbo是一个基于URL驱动的RPC框架，方法中标注有@Adaptive注解的方法参数上必须带有java.net.URL参数，否则，会抛出异常。生成的代理类代码如下： package xyz.easyjava.dubbo.spi.achieve.service; import org.apache.dubbo.common.extension.ExtensionLoader; public class Protocol$Adaptive implements org.apache.dubbo.rpc.Protocol { public void destroy() {throw new UnsupportedOperationException(\"method public abstract void org.apache.dubbo.rpc.Protocol.destroy() of interface org.apache.dubbo.rpc.Protocol is not adaptive method!\"); } public int getDefaultPort() {throw new UnsupportedOperationException(\"method public abstract int org.apache.dubbo.rpc.Protocol.getDefaultPort() of interface org.apache.dubbo.rpc.Protocol is not adaptive method!\"); } public org.apache.dubbo.rpc.Exporter export(org.apache.dubbo.rpc.Invoker arg0) throws org.apache.dubbo.rpc.RpcException { if (arg0 == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument == null\"); if (arg0.getUrl() == null) throw new IllegalArgumentException(\"org.apache.dubbo.rpc.Invoker argument getUrl() == null\");org.apache.dubbo.common.URL url = arg0.getUrl(); String extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() ); if(extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.export(arg0); } public org.apache.dubbo.rpc.Invoker refer(java.lang.Class arg0, org.apache.dubbo.common.URL arg1) throws org.apache.dubbo.rpc.RpcException { if (arg1 == null) throw new IllegalArgumentException(\"url == null\"); org.apache.dubbo.common.URL url = arg1; String extName = ( url.getProtocol() == null ? \"dubbo\" : url.getProtocol() ); if(extName == null) throw new IllegalStateException(\"Fail to get extension(org.apache.dubbo.rpc.Protocol) name from url(\" + url.toString() + \") use keys([protocol])\"); org.apache.dubbo.rpc.Protocol extension = (org.apache.dubbo.rpc.Protocol)ExtensionLoader.getExtensionLoader(org.apache.dubbo.rpc.Protocol.class).getExtension(extName); return extension.refer(arg0, arg1); } } 从上面生成的类来看，dubbo对扩展接口上带有@Adaptive注解的方法进行了代理，没有标注@Adaptive的方法，直接抛出UnsupportedOperationException异常。被代理的方法通过URL协议来获取一个扩展点。 接下来，分析injectExtension()方法，也就是Dubbo中的依赖注入，Duboo支持Spring的依赖注入以及Dubbo自己的SPI自适应扩展点。在该方法中可以看出，当前自适应扩展点中是否包含一个setter方法，有且只有一个参数的public的方法，并且该方法没有标注@DisableInject注解，那么Dubbo会为该自适应扩展点依赖注入。被注入的对象核心代码在objectFactory.getExtension(pt, property)通过objectFactory的getExtension方法获得被注入的对象，然后放到当前自适应扩展点，实现依赖注入。那么objectFactory对象是什么，在什么时候被实例化的？还记得在最开始通过getExtensionLoader(IHelloService.class)获得一个ExtensionLoader对象的时候，由于ExtensionLoader类的构造方法是私有化的，所以在getExtensionLoader方法中创建了ExtensionLoader对象，然而就在这个私有化的构造方法中，有这样一句代码 objectFactory = (type == ExtensionFactory.class ? null : ExtensionLoader.getExtensionLoader(ExtensionFactory.class).getAdaptiveExtension()); 这就是objectFactory对象实例化的地方。这里有创建了一个ExtensionFactory类的ExtensionLoader对象，并且将这个对象缓存在了EXTENSION_LOADERS（所以，整个运行过程中ExtensionFactory只有一个，并且都是AdaptiveExtensionFactory），然后调用了该对象的getAdaptiveExtension方法，该方法前面已经分析过来，返回一个自适应扩展点。然后我们看ExtensionFactory的实现类，有一个名为AdaptiveExtensionFactory的自适应扩展点（因为该类上面标注了@Adaptive注解），所以我们可以发现objectFactory对象的实例其实就是AdaptiveExtensionFactory类的实例对象。回到injectExtension方法的objectFactory.getExtension(pt, property)代码上，这里实际上调用的就是AdaptiveExtensionFactory里面的getExtension方法。该方法如下： public &lt;T> T getExtension(Class&lt;T> type, String name) { for (ExtensionFactory factory : factories) { T extension = factory.getExtension(type, name); if (extension != null) { return extension; } } return null; } 其中factories就是所有的ExtensionFactory类的扩展，从所有的扩展点中任意返回一个null的实例返回，dubbo默认有SpringExtensionFactory、SPIExtensionFactory两个，SpringExtensionFactory的实现就是从Spring的IOC容器中拿到对象注入。如果被注入对象类上标注了@SPI注解，那么最终还是交给SPIExtensionFactory对象去处理，该类里面有是通过ExtensionLoader得到一个自适应扩展点。到此，Dubbo的依赖注入完成。类图： 服务发布流程Dubbo是阿里巴巴依赖Spring开源的RPC框架，至于为什么要依赖Spring我们不去深究，大概是因为Spring优秀的IOC，又或者是AOP，介于Spring的高度抽象，灵活的设计模式，便于去扩展，所以，Dubbo基于Spring的扩展区实现Dubbo基于Spring扩展的NameSpaceHandler，Spring容器在启动的时候会调用DubboNamespaceHandler的init()方法，该方法主要是解析Spring配置文件中的Dubbo扩展标签，将其转换成BeanDefinition，以便Spring容器进行管理。Dubbo服务的发布流程是从ServiceBean开始的，因为该类实现了接口InitializingBean，该接口会在依赖注入完成过后调用afterPropertiesSet方法，而afterPropertiesSet方法就是Dubbo启动的关键。首先在afterPropertiesSet方法中经过一些校验，在最后几行代码中，判断，是否支持SpringListener，如果不支持这调用export方法，如果支持，则会在Spring启动过程中执行ServiceBean中onApplicationEvent方法，总之都会调用到export方法，在export方法中主要是调用ServiceBean父类ServiceConfig的export方法，在该方法中，首先也是一堆的校验，最后调用doExport方法，继续往下看，doExportUrls()方法中首先是将所有的注册中心配置拼装成一个URL集合，类似如下：registry://localhost:2181/org.apache.dubbo.registry.RegistryService?application=easyjava-dubbo-provider&amp;dubbo=2.0.2&amp;pid=205792&amp;registry=zookeeper&amp;release=2.7.0&amp;timestamp=1574749134905，然后用循环的方式调用doExportUrlsFor1Protocol，该方法主要作用是将服务拼装成一个URL，如下： dubbo://10.98.217.74:20880/xyz.easyjava.dubbo.api.IHelloService?anyhost=true&amp;application=easyjava-dubbo-provider&amp;bean.name=xyz.easyjava.dubbo.api.IHelloService&amp;bind.ip=10.98.217.74&amp;bind.port=20880&amp;dubbo=2.0.2&amp;generic=false&amp;interface=xyz.easyjava.dubbo.api.IHelloService&amp;methods=sayHello&amp;pid=205792&amp;release=2.7.0&amp;side=provider&amp;timestamp=1574749545179最后将调用一下这句代码 Invoker&lt;?> invoker = proxyFactory.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(Constants.EXPORT_KEY, url.toFullString())); DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this); Exporter&lt;?> exporter = protocol.export(wrapperInvoker); proxyFactory是一个自适应扩展点，是ServiceConfig的成员变量private static final ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension();ProxyFactory默认扩展点是JavassistProxyFactory，并且该扩展点有一个包装器StubProxyFactoryWrapper，所以，proxyFactory实际上是StubProxyFactoryWrapper(JavassistProxyFactory())调用StubProxyFactoryWrapper(JavassistProxyFactory())的getInvoker方法，实际上最终会调用到JavassistProxyFactory的getInvoker方法，传入三个参数，第一个ref是当前服务接口的实现类，例如：HelloServiceImpl，第二个参数(Class) interfaceClass是当前服务接口的类对象，第三个参数是注册中心加上服务地址拼接成的一个注册中心地址，服务地址作为注册中心的export参数，如下： registry://localhost:2181/org.apache.dubbo.registry.RegistryService?application=easyjava-dubbo-provider&amp;dubbo=2.0.2&amp;export=dubbo%3A%2F%2F10.98.217.74%3A20880%2Fxyz.easyjava.dubbo.api.IHelloService%3Fanyhost%3Dtrue%26application%3Deasyjava-dubbo-provider%26bean.name%3Dxyz.easyjava.dubbo.api.IHelloService%26bind.ip%3D10.98.217.74%26bind.port%3D20880%26dubbo%3D2.0.2%26generic%3Dfalse%26interface%3Dxyz.easyjava.dubbo.api.IHelloService%26methods%3DsayHello%26pid%3D205792%26release%3D2.7.0%26side%3Dprovider%26timestamp%3D1574749545179&amp;pid=205792&amp;registry=zookeeper&amp;release=2.7.0&amp;timestamp=1574749134905在该方法中，主要做了两件事情： 创建一个当前实例对象的Wrapper（代理对象），这里为什么需要有这样一层包装，我猜想的话应该是Dubbo的调用是通过URL进行的，我们可以方便的通过传入参数来决定调用哪个方法，我们通过Arthas来看一下Wrapper对象代码： package org.apache.dubbo.common.bytecode; import java.lang.reflect.InvocationTargetException; import java.util.Map; import org.apache.dubbo.common.bytecode.ClassGenerator; import org.apache.dubbo.common.bytecode.NoSuchMethodException; import org.apache.dubbo.common.bytecode.NoSuchPropertyException; import org.apache.dubbo.common.bytecode.Wrapper; import xyz.easyjava.dubbo.provider.service.HelloServiceImpl; public class Wrapper1 extends Wrapper implements ClassGenerator.DC { public static String[] pns; public static Map pts; public static String[] mns; public static String[] dmns; public static Class[] mts0; @Override public String[] getPropertyNames() { return pns; } @Override public boolean hasProperty(String string) { return pts.containsKey(string); } public Class getPropertyType(String string) { return (Class)pts.get(string); } @Override public String[] getMethodNames() { return mns; } @Override public String[] getDeclaredMethodNames() { return dmns; } @Override public void setPropertyValue(Object object, String string, Object object2) { try { HelloServiceImpl helloServiceImpl = (HelloServiceImpl)object; } catch (Throwable throwable) { throw new IllegalArgumentException(throwable); } throw new NoSuchPropertyException(new StringBuffer().append(\"Not found property \\\"\").append(string).append(\"\\\" field or setter method in class xyz.easyjava.dubbo.provider.service.HelloServiceImpl.\").toString()); } @Override public Object getPropertyValue(Object object, String string) { try { HelloServiceImpl helloServiceImpl = (HelloServiceImpl)object; } catch (Throwable throwable) { throw new IllegalArgumentException(throwable); } throw new NoSuchPropertyException(new StringBuffer().append(\"Not found property \\\"\").append(string).append(\"\\\" field or setter method in class xyz.easyjava.dubbo.provider.service.HelloServiceImpl.\").toString()); } public Object invokeMethod(Object object, String string, Class[] arrclass, Object[] arrobject) throws InvocationTargetException { HelloServiceImpl helloServiceImpl; try { helloServiceImpl = (HelloServiceImpl)object; } catch (Throwable throwable) { throw new IllegalArgumentException(throwable); } try { if (\"sayHello\".equals(string) &amp;&amp; arrclass.length == 1) { return helloServiceImpl.sayHello((String)arrobject[0]); } } catch (Throwable throwable) { throw new InvocationTargetException(throwable); } throw new NoSuchMethodException(new StringBuffer().append(\"Not found method \\\"\").append(string).append(\"\\\" in class xyz.easyjava.dubbo.provider.service.HelloServiceImpl.\").toString()); } } 创建一个匿名AbstractProxyInvoker，且doInvoke方法实际上是调用的Wrapper代理对象的invokeMethod方法最后，该方法会返回一个AbstractProxyInvoker，其中doInvoke(T proxy, String methodName,Class&lt;?&gt;[] parameterTypes,Object[] arguments)中会调用代理Wrapper类中wrapper.invokeMethod(proxy, methodName, parameterTypes, arguments);方法,得到invoker过后，再次用DelegateProviderMetaDataInvoker包装一下，通过protocol.export(wrapperInvoker);传入DelegateProviderMetaDataInvoker实例对象，得到一个exporter，那么这里的protocol又是什么实现呢，Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();这里又是一个自适应扩展点，会生成一个Protocol$Adaptive，我们前面已经分析过了，Protocol$Adaptive会通过当前协议动态获取一个扩展点，那么当前URL的协议是registry,所以，这里应该会调用到RegistryProtocol的export方法，在该方法中，会调用getRegistryUrl()方法，这个方法将注册中心协议从registry改为URL中registry参数值作为协议头，如果不存在则默认使用dubbo注册中心。拿到注册中心和服务发布URL过后，该方法核心代码是final ExporterChangeableWrapper&lt;T&gt; exporter = doLocalExport(originInvoker, providerUrl);，这句代码就是暴露服务的关键，服务暴露过后，该方法中还有一句核心代码register(registryUrl, registeredProviderUrl);，这句代码就是将服务地址注册到注册中心，我们一个一个的来分析，dubbo究竟是如何发布服务并且将服务URL注册到注册中心的。首先是服务暴露，通过查看doLocalExport方法，该方法需要两个参数，当前invoker和providerUrl服务地址,该方法源码：private &lt;T> ExporterChangeableWrapper&lt;T> doLocalExport(final Invoker&lt;T> originInvoker, URL providerUrl) { String key = getCacheKey(originInvoker); ExporterChangeableWrapper&lt;T> exporter = (ExporterChangeableWrapper&lt;T>) bounds.get(key); if (exporter == null) { synchronized (bounds) { exporter = (ExporterChangeableWrapper&lt;T>) bounds.get(key); if (exporter == null) { final Invoker&lt;?> invokerDelegete = new InvokerDelegate&lt;T>(originInvoker, providerUrl); exporter = new ExporterChangeableWrapper&lt;T>((Exporter&lt;T>) protocol.export(invokerDelegete), originInvoker); bounds.put(key, exporter); } } } return exporter; } 我们可以看到protocol.export(invokerDelegete)，这里的protocol是什么取决于invokerDelegete中URL协议是什么，这里显然URL是服务地址，所以协议应该是dubbo，所以这里的protocol最终得到的就是DubboProtocol，查看DubboProtocol中的export方法，该方法中会调用openServer(url);，传入服务暴露地址，在openServer(url);方法中首先从缓存中获取一个server，如果缓存中没有，则创建一个，那么我们看server是如何创建的，参看createServer方法，ExchangeServer server; try { server = Exchangers.bind(url, requestHandler); } catch (RemotingException e) { throw new RpcException(\"Fail to start server(url: \" + url + \") \" + e.getMessage(), e); } 通过Exchangers.bind(url, requestHandler);得到一个server，该方法最终会调用到HeaderExchanger中的bind方法，到这里还没完，在HeaderExchanger的bind方法中创建一个HeaderExchangeServer对象，该对象需要一个Server参数，这个Server从Transporters.bind中得来，这里又是一个自适应扩展点，但最终会调到NettyTransporter中的bind方法，最终在这里new了一个NettyServer，发布服务。接下来分析服务注册，在RegistryProtocol的export方法中，有这样一句代码final Registry registry = getRegistry(originInvoker);，这句代码的作用就是活的一个注册中心，我们来分析一下getRegistry方法，private Registry getRegistry(final Invoker&lt;?> originInvoker) { URL registryUrl = getRegistryUrl(originInvoker); return registryFactory.getRegistry(registryUrl); } 从代码中可以看出，首先通过URL得到注册中心的协议地址，这个时候这里应该是zookeeper://...，然后通过registryFactory得到一个注册中心工厂对象，但是这里的registryFactory又是什么，改成员变量有一个setter方法，可见，这里的registryFactory是依赖注入进来的，又是一个RegistryFactory$Adaptive，通过协议地址动态活的一个RegistryFactory，当前协议为zookeeper，所以这里的registryFactory就是ZookeeperRegistryFactory然后调用ZookeeperRegistryFactory的getRegistry方法，发现该类中并没有这个方法，所以会调用父类AbstractRegistryFactory的getRegistry方法，这是一个模板方法，具体实现由子类完成，在该方法中registry = createRegistry(url);就是由子类ZookeeperRegistryFactory实现的，实现如下：@Override public Registry createRegistry(URL url) { return new ZookeeperRegistry(url, zookeeperTransporter); } 回到RegistryProtocol的export方法中，得到一个ZookeeperRegistry注册中心过后，调用``方法，该方法实现如下：public void register(URL registryUrl, URL registeredProviderUrl) { Registry registry = registryFactory.getRegistry(registryUrl); registry.register(registeredProviderUrl); } 得到一个注册中心，并且注册，这里得到的注册中心和getRegistry方法得到注册中心方法一样，得到的都是ZookeeperRegistry，然后看ZookeeperRegistry的register方法，同理，ZookeeperRegistry中没有register则调用父类FailbackRegistry的register方法，并且传入服务暴露URL，改方法又是一个模板方法，最终会调用doRegister，而这个方法在子类ZookeeperRegistry中实现，该方法如下：@Override public void doRegister(URL url) { try { zkClient.create(toUrlPath(url), url.getParameter(Constants.DYNAMIC_KEY, true)); } catch (Throwable e) { throw new RpcException(\"Failed to register \" + url + \" to zookeeper \" + getUrl() + \", cause: \" + e.getMessage(), e); } } 这里直接创建一个zookeeper节点，即服务注册，生成的path路径为：/dubbo/xyz.easyjava.dubbo.api.IHelloService/providers/dubbo%3A%2F%2F10.98.217.74%3A20880%2Fxyz.easyjava.dubbo.api.IHelloService%3Fanyhost%3Dtrue%26application%3Deasyjava-dubbo-provider%26bean.name%3Dxyz.easyjava.dubbo.api.IHelloService%26dubbo%3D2.0.2%26generic%3Dfalse%26interface%3Dxyz.easyjava.dubbo.api.IHelloService%26methods%3DsayHello%26pid%3D212032%26release%3D2.7.0%26side%3Dprovider%26timestamp%3D1574752829404以上就是服务注册已经服务暴露全过程。 服务引用初始化过程Dubbo服务引用的时机有两个，第一个是Spring容器在调用ReferenceBean中afterPropertiesSet方法时，第二个是ReferenceBean对应的服务在被注入到其他对象中时，两者的区别在于第一种是饿汉式的，第二种是懒汉式的，Dubbo默认是懒汉式的，我们可以通过配置&lt;dubbo:reference init=&#39;true&#39;&gt;来将其改为饿汉式。不管服务引用是饿汉还是懒汉模式，Dubbo都会调用ReferenceBean的getObject方法，接下来我们就从getObject方法开始分析，在get方法中，如果ReferenceBean对应的服务引用对象ref已存在，则直接返回，如果不存在，则先调用init方法，服务引用对象ref就是在这里面进行创建的。init方法中除了对配置解析拼接到map中以外，最重要的是ref = createProxy(map);方法，在createProxy方法中，首先是判断是否是本地调用，如果是，则创建InjvmProtocol的refer方法创建InjvmInvoker，则读取直连配置或注册中心URL（这里需要注意的是，如果选择了服务直连的方式，注册中心将失效，该方式用于在开发阶段调试过后一定要记得将其关掉），如果urls只要一个，则直接通过refProtocol.refer()调用，如果urls有多个，则循环调用refprotocol.refer并且将invoker放到invokersList中，最后调用cluster.join(new StaticDirectory(invokers))将多个invoker伪装成一个invoker,并且传入一个StaticDirectory静态目录服务，因为这里要么是多个注册中心，要么是多个服务提供者，而这些invoker是不会动态变化的。这个时候的cluster是一个自适应扩展点Cluster$Adaptive，循环调用时需要注意，如果有多个注册中心，则在URL中添加cluster参数，值为registryaware,同样调用cluster.join(new StaticDirectory(u,invokers))，不过这里在创建StaticDirectory静态目录服务的时候多传入了一个注册中心的URL。这里先不去深究。接下来分析invoker的创建过程，invoker的创建是通过protocol.refer方法，protocol的实现有很多，常用的是RegistryProtocol（注册中心）和DubboProtocol（服务直连使用Dubbo协议），这里只分析这两种协议。 DubboProtocolclass DubboProtocol { //... @Override public &lt;T> Invoker&lt;T> refer(Class&lt;T> serviceType, URL url) throws RpcException { optimizeSerialization(url); // create rpc invoker. DubboInvoker&lt;T> invoker = new DubboInvoker&lt;T>(serviceType, url, getClients(url), invokers); invokers.add(invoker); return invoker; } private ExchangeClient[] getClients(URL url) { // whether to share connection boolean service_share_connect = false; int connections = url.getParameter(Constants.CONNECTIONS_KEY, 0); // if not configured, connection is shared, otherwise, one connection for one service if (connections == 0) { service_share_connect = true; connections = 1; } ExchangeClient[] clients = new ExchangeClient[connections]; for (int i = 0; i &lt; clients.length; i++) { if (service_share_connect) { clients[i] = getSharedClient(url); } else { clients[i] = initClient(url); } } return clients; } //... } DubboProtocol的refer方法很简单，直接创建一个DubboInvoker返回，但是这里值得注意的是getClients(url)方法，该方法中，首先会从url中读取参数connections，该参数在 &lt;dubbo:reference id=\"helloService\" interface=\"xyz.easyjava.dubbo.api.IHelloService\" url=\"dubbo://10.98.217.74:20880;dubbo://10.98.217.73:20880\" connections=\"0\"/> 中被指定，如果不指定，则默认为0，该值有三个，分别是： 0：表示该服务使用JVM共享长连接（缺省） 1：表示该服务使用独立一条长连接 2：表示该服务使用独立两条长连接，这种方式一般使用于负载较大的服务。所以，这里默认使用JVM共享长连接的方法，这个时候代码会执行getSharedClient(url)，该方法中首先从缓存中取，如果缓存未命中，则调用initClient(url)创建一个新的ExchangeClient，最后通过ReferenceCountExchangeClient包装过后放入到缓存最后返回，再来看一下initClient方法，initClient方法首先判断客户端类型，默认为Netty，并且设置默认心跳间隔时间，最后判断是否延迟链接，如果是延迟连接，则创建LazyConnectExchangeClient，否则调用Exchangers.connect(url, requestHandler),延迟LazyConnectExchangeClient在发送请求之前调用Exchangers.connect(url, requestHandler)方法，所以，这里我们直接分析，实际上这里最终调用的是HeaderExchanger.connect(URL url, ExchangeHandler handler)，class HeaderExchanger { //... @Override public ExchangeClient connect(URL url, ExchangeHandler handler) throws RemotingException { return new HeaderExchangeClient(Transporters.connect(url, new DecodeHandler(new HeaderExchangeHandler(handler))), true); } //... } 经过深入分析，Transporters.connect最终调用的是NettyTransporter.connect，方法中直接创建一个NettyClient，最终在NettyClient中连接目标服务，并且保存着客户端和服务间的channel，建立长连接。 RegistryProtocol在RegistryProtocol的refer方法中，首先设置URL协议头，从registry改为Zookeeper，然后通过注册中心工厂得到一个注册中心对象，这里得到的是ZookeeperRegistry，最后通过group判断调用doRefer方法的cluster参数应该是哪一个。这里并不影响主流程，我们接着看doRefer方法，方法代码如下： class RegistryProtocol { //... private &lt;T> Invoker&lt;T> doRefer(Cluster cluster, Registry registry, Class&lt;T> type, URL url) { RegistryDirectory&lt;T> directory = new RegistryDirectory&lt;T>(type, url); directory.setRegistry(registry); directory.setProtocol(protocol); // all attributes of REFER_KEY Map&lt;String, String> parameters = new HashMap&lt;String, String>(directory.getUrl().getParameters()); URL subscribeUrl = new URL(CONSUMER_PROTOCOL, parameters.remove(REGISTER_IP_KEY), 0, type.getName(), parameters); if (!ANY_VALUE.equals(url.getServiceInterface()) &amp;&amp; url.getParameter(REGISTER_KEY, true)) { registry.register(getRegisteredConsumerUrl(subscribeUrl, url)); } directory.buildRouterChain(subscribeUrl); directory.subscribe(subscribeUrl.addParameter(CATEGORY_KEY, PROVIDERS_CATEGORY + \",\" + CONFIGURATORS_CATEGORY + \",\" + ROUTERS_CATEGORY)); Invoker invoker = cluster.join(directory); ProviderConsumerRegTable.registerConsumer(invoker, url, subscribeUrl, directory); return invoker; } //... } 以上代码首先创建注册中心目录服务，并且设置器注册中心对象ZookeeperRegistry和协议Protocol$Adaptive，然后组装消费者URLsubscribeUrl，注册到注册中心，构建路由器链，订阅providers,routers,configurators.最后执行Invoker invoker = cluster.join(directory);并返回invoker，首先来分析，服务订阅过程 directory.subscribe(subscribeUrl.addParameter(CATEGORY_KEY, PROVIDERS_CATEGORY + \",\" + CONFIGURATORS_CATEGORY + \",\" + ROUTERS_CATEGORY)); 服务订阅过程从directory.subscribe开始，在RegistryDirectory中调用registry.subscribe(url, this);，这里的registry是在doRefer方法中注入的，实例为ZookeeperRegistry，在ZookeeperRegistry的subscribe方法中需要两个参数，一个URL和一个Listener，而这里传了this，说明这里this实现了NotifyListener接口，所以，这里传入的是this，接下来看ZookeeperRegistry的subscribe方法，发现该类中并没有此方法，那么必然会调父类的subscribe方法，这里又是一个模板方法，最终还是会调用子类的实现doSubscribe方法，该方法中主要注册Zookeeper监听，如果有如果有节点变动，则会通知到ZookeeperRegistry中notify方法，传入listener，该方法调用链为： ZookeeperRegistry.notify -&gt; ZookeeperRegistry.doNotify -&gt; AbstractRegistry.notify -&gt; listener.notify(categoryList)(RegistryDirectory.notify)categoryList：该参数为providers,routers,configurators节点下的所有URL地址。该方法中首先将注册中心读取到的URL转换成对象，比如Router,Configurator最后调用refreshInvoker，下面看一下refreshInvoker方法的实现： class RegistryDirectory { private void refreshInvoker(List&lt;URL> invokerUrls) { Assert.notNull(invokerUrls, \"invokerUrls should not be null\"); if (invokerUrls.size() == 1 &amp;&amp; invokerUrls.get(0) != null &amp;&amp; Constants.EMPTY_PROTOCOL.equals(invokerUrls .get(0) .getProtocol())) { this.forbidden = true; // Forbid to access this.invokers = Collections.emptyList(); routerChain.setInvokers(this.invokers); destroyAllInvokers(); // Close all invokers } else { this.forbidden = false; // Allow to access Map&lt;String, Invoker&lt;T>> oldUrlInvokerMap = this.urlInvokerMap; // local reference if (invokerUrls == Collections.&lt;URL>emptyList()) { invokerUrls = new ArrayList&lt;>(); } if (invokerUrls.isEmpty() &amp;&amp; this.cachedInvokerUrls != null) { invokerUrls.addAll(this.cachedInvokerUrls); } else { this.cachedInvokerUrls = new HashSet&lt;>(); this.cachedInvokerUrls.addAll(invokerUrls);//Cached invoker urls, convenient for comparison } if (invokerUrls.isEmpty()) { return; } Map&lt;String, Invoker&lt;T>> newUrlInvokerMap = toInvokers(invokerUrls);// Translate url list to Invoker map // state change // If the calculation is wrong, it is not processed. if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0) { logger.error(new IllegalStateException(\"urls to invokers error .invokerUrls.size :\" + invokerUrls.size() + \", invoker.size :0. urls :\" + invokerUrls .toString())); return; } List&lt;Invoker&lt;T>> newInvokers = Collections.unmodifiableList(new ArrayList&lt;>(newUrlInvokerMap.values())); // pre-route and build cache, notice that route cache should build on original Invoker list. // toMergeMethodInvokerMap() will wrap some invokers having different groups, those wrapped invokers not should be routed. routerChain.setInvokers(newInvokers); this.invokers = multiGroup ? toMergeInvokerList(newInvokers) : newInvokers; this.urlInvokerMap = newUrlInvokerMap; try { destroyUnusedInvokers(oldUrlInvokerMap, newUrlInvokerMap); // Close the unused Invoker } catch (Exception e) { logger.warn(\"destroyUnusedInvokers error. \", e); } } } } 首先判断协议地址是否只有一个，并且协议为empty协议，如果是，销毁所有invokers，否则将URL列表转成Invoker（这里根据协议会创建DubboInvoker）列表得到newUrlInvokerMap，最后将赋值给urlInvokerMap，达到刷新urlInvokerMap的目的，并且关闭关闭未使用的Invoker，回到RegistryProtocol的doRefer方法的Invoker invoker = cluster.join(directory);，这行代码将服务目录传入，其目的是做客户端负载均衡和服务容错，总之提供集群服务治理支持，这块后面单独分析。 创建代理不管是DubboProtocol还是RegistryProtocol最后都会返回一个Invoker，这个Invoker就是调用服务的客户端，里面封装了和服务端的长连接。但是如果我们直接将Invoker对象拿到业务代码中调用，这样对于我们的业务来说侵入性太高，所以Dubbo使用代理的方式实现业务的零侵入，回到ReferenceConfig的createProxy方法，在最后一行代码return (T) proxyFactory.getProxy(invoker);返回一个代理对象，这里的proxyFactory是一个JavassistProxyFactory,这里首先会调用父类AbstractProxyFactory的getProxy方法，然后调用JavassistProxyFactory的getProxy方法，代理类就是在该方法中被生成的，接下来看下生成的代理类： package org.apache.dubbo.common.bytecode; import com.alibaba.dubbo.rpc.service.EchoService; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import org.apache.dubbo.common.bytecode.ClassGenerator; import xyz.easyjava.dubbo.api.IHelloService; public class proxy0 implements ClassGenerator.DC, EchoService, IHelloService { public static Method[] methods; private InvocationHandler handler; public String sayHello(String string) { Object[] arrobject = new Object[]{string}; Object object = this.handler.invoke(this, methods[0], arrobject); return (String)object; } @Override public Object $echo(Object object) { Object[] arrobject = new Object[]{object}; Object object2 = this.handler.invoke(this, methods[1], arrobject); return object2; } public proxy0() { } public proxy0(InvocationHandler invocationHandler) { this.handler = invocationHandler; } } 该代理类在创建实例的时候传入了一个InvokerInvocationHandler(invoker)，所以，服务调用时其实最终会调用到InvokerInvocationHandler的invoke方法： public class InvokerInvocationHandler implements InvocationHandler { private static final Logger logger = LoggerFactory.getLogger(InvokerInvocationHandler.class); private final Invoker&lt;?> invoker; public InvokerInvocationHandler(Invoker&lt;?> handler) { this.invoker = handler; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { String methodName = method.getName(); Class&lt;?>[] parameterTypes = method.getParameterTypes(); if (method.getDeclaringClass() == Object.class) { return method.invoke(invoker, args); } if (\"toString\".equals(methodName) &amp;&amp; parameterTypes.length == 0) { return invoker.toString(); } if (\"hashCode\".equals(methodName) &amp;&amp; parameterTypes.length == 0) { return invoker.hashCode(); } if (\"equals\".equals(methodName) &amp;&amp; parameterTypes.length == 1) { return invoker.equals(args[0]); } return invoker.invoke(createInvocation(method, args)).recreate(); } private RpcInvocation createInvocation(Method method, Object[] args) { RpcInvocation invocation = new RpcInvocation(method, args); if (RpcUtils.hasFutureReturnType(method)) { invocation.setAttachment(Constants.FUTURE_RETURNTYPE_KEY, \"true\"); invocation.setAttachment(Constants.ASYNC_KEY, \"true\"); } return invocation; } } 服务目录服务目录在前面将RegistryProtocol引入的时候已经讲过了，其主要作用是列出所有invoker，下面来看一下依赖关系：由上图可见，AbstractDirectory里面实现了list服务列举方法，该方法肯定是一个模板方法，具体实现由子类提供，接下里分析它的两个实现StaticDirectory和RegistryDirectory，顾名思义，StaticDirectory是静态目录服务，即invokers是固定不变的，该目录适用于注册中心，比如有三个注册中心，那么这三个注册中心在运行过程中是不会动态改变的。RegistryDirectory是动态的，具体的invokers会根据服务注册中心的变动而变动。StaticDirectory实现很简单，这里不做过多分析，重点分析RegistryDirectory，RegistryDirectory实现了NotifyListener接口，改接口只有一个方法notify，该方法会在ZookeeperRegistry的doSubscribe（即服务订阅）时被注册，在zookeeper注册中心的服务节点变动时异步通知调用，得到更新过后的URL过后，会调用refreshInvoker方法刷新Invoker列表，改方法在服务引入时分析过了，主要就是将URL列表转换成Invoker列表，放到一个MAP中来达到更新invoker的目的。总结：服务目录可以看成是一个List&lt;Invoker&gt;。 服务路由服务路由的作用是根据用户配置的路由规则来筛选服务提供者。比如有这样一条规则： host = 10.20.153.10 =&gt; host = 10.20.153.11该条规则表示 IP 为 10.20.153.10 的服务消费者只可调用 IP 为 10.20.153.11 机器上的服务，不可调用其他机器上的服务 服务集群集群的工作可以分为两个阶段，第一：服务消费者初始化时创建ClusterInvoker对象，其目的是将Directory包装，伪装成一个invoker返回，第二：服务调用时，这个时候主要是调用AbstractClusterInvoker的invoke方法，该方法又是一个模板方法，最终会调用具体实现类的doInvoke方法，在doInvoke方法中，封装了一些集群容错的机制，就拿缺省的FailoverClusterInvoker来分析，该方式在调用时出现错误，如果是业务异常，则直接抛出，如果不是业务异常，记录异常，然后重试，重试次数可以在retries属性中指定，默认两次，不算第一次。 负载均衡负载均衡是在服务调用过程中被确定的，具体在invoker.invoke方法中被初始化，这里的负载均衡器为LoadBalance$Adaptive，具体使用某个负载均衡器取决于用户配置，默认使用随机算法，这里不深入分析负载均衡算法。 服务调用过程服务调用过程分为两个部分 消费端发送请求 服务端接受请求处理消费端发送请求在分析服务调用之前，先来看一下服务请求发送流程图在前面服务引入创建代理时讲到，客户端是通过代理对象调用发送网络请求的，而代理对象是调用InvokerInvocationHandler的invoke方法，所以，服务调用过程理应从这里开始。该方法中，首先会封装请求参数Invocation对象，然后调用invoker的invoke方法，这里前面分析得出这里的invoker应该是MockClusterInvoker，这里不分析Dubbo的Mock机制，直接调用FailoverClusterInvoker的invoker方法，改方法在父类AbstractClusterInvoker中，在该方法中，主要是初始化了负载均衡器RandomLoadBalance，然后调用FailoverClusterInvoker的doInvoke方法，在该方法中，首先通过负载均衡器拿到一个invoker，这里的invoker是我们在目录服务中RegistryDirectory回调notify通知中创建的，这里创建的是DubboInvoker，所以这里调用AbstractInvoker中的invoke方法，然后该方法会调用DubboInvoker的doInvoke方法，当然，这中间会调用一些Filter这里不展开分析。在doInvoke方法中，会拿到ReferenceCountExchangeClient，然后调用request方法，这里的调用链比较长，如下：ReferenceCountExchangeClient.request -&gt; HeaderExchangeClient.request -&gt; HeaderExchangeChannel.request -&gt; HeaderExchangeClient.send -&gt; HeaderExchangeChannel.send -&gt; NettyChannel.send -&gt; NioSocketChannel.writeAndFlush由上面调用链可以看出，最终会通过Netty的channel调用writeAndFlush发送数据，最后将结果返回。当然这里面的数据编解码序列化在这里不展开。 服务端接受请求处理服务端接受请求的入口在NettyServerHandler类中的channelRead方法，先来看一下调用链 NettyServerHandler.channelRead -&gt; AbstractPeer.received -&gt; MultiMessageHandler.received -&gt; HeartbeatHandler.received -&gt; AllChannelHandler.received(该方法中会创建一个线程去执行) -&gt; ChannelEventRunnable.run -&gt; DecodeHandler.received -&gt; HeaderExchangeHandler.received -&gt; HeaderExchangeHandler.handleRequest -&gt; DubboProtocol$1.reply(这里的DubboProtocol$1是ExchangeHandlerAdapter的子类，定义在DubboProtocol中的匿名内部类，该方法中通过channel和invocation获取invoker对象) -&gt; DelegateProviderMetaDataInvoker.invoke -&gt; Wrapper1.invokeMethod -&gt; HelloServiceImpl.sayHello代码分析到这里，整个服务请求接受处理差不多就调用完了。","categories":[{"name":"Dubbo","slug":"Dubbo","permalink":"http://blog.easyjava.xyz/categories/Dubbo/"}],"tags":[{"name":"SPI","slug":"SPI","permalink":"http://blog.easyjava.xyz/tags/SPI/"}]},{"title":"Spring事务的传播性及隔离级别","slug":"Spring事务的传播性及隔离级别","date":"2019-11-14T02:52:03.000Z","updated":"2020-02-11T01:07:11.897Z","comments":true,"path":"2019/11/14/Spring事务的传播性及隔离级别/","link":"","permalink":"http://blog.easyjava.xyz/2019/11/14/Spring事务的传播性及隔离级别/","excerpt":"","text":"开发中我们对事务并不陌生，但大多数开发者对事务的传播性以及Spring的事务传播性模棱两可，今天就来梳理一下 什么是事务？保证业务（一系列对数据库增删改操作）的原子性，原子：表示不可分割，要么存在要么不存在，是一个最小单位。那么事务就是一批操作视为一个原子操作，要么成功要么失败。 事务的ACID特性 A(Atomic)：原子性，当前事务操作是一个最小单位，不可拆分。 C(Consistency)：一致性，不论事务执行成功还是失败，数据库中的数据始终是一致的。 I(Isolation)：隔离性，多个事务操作同一笔数据时，各个事务处于一个被隔离的空间，是独立的。 D(Durability)：持久性，一旦事务提交，修改的数据是永久性的。 事务的隔离级别 脏读：一个事务读到另一个事务未提交的更新数据，而另一个事务最终回滚，我们称这类数据为脏数据，这种现象称为脏读。 不可重复读：事务T1多次读取同一数据，而事务多T2次对这一数据进行更新，导致T1每次读取的数据不一样。 幻读：事务T1执行一次查询，然后事务T2插入或者删除一条数据，恰好T2这条操作的数据刚好满足T1的检索条件。这时事务T1再执行一次查询，此时得到的数据和第一次查询的数据不一致，这种现象称为幻读。数据库事务隔离级别（4种），Spring除了有数据库的4种还有一种默认。 ISOLATION_DEFAULT：默认使用数据库的事务隔离级别。 ISOLATION_READ_UNCOMMITTED：读未提交，可以读到未提交的数据，该级别可能会出现脏读、不可重复读、幻读等问题。 ISOLATION_READ_COMMITTED：读已提交，只能读到已提交的数据，该级别可以有效避免脏读，但可能会出现不可重复读、幻读的问题。Oracle，SQL Server默认使用此级别。 ISOLATION_REPEATABLE_READ：可重复读，该方式专门为不可重复读这一现象定制，改级别可以避免脏读和不可重复读，但可能会出现幻读。MySQL默认使用此级别。 ISOLATION_SERIALIZABLE：可串行化，将事务按照顺序执行，即多个事务不能同时执行，该级别为最高级别，性能上有较大影响，但能避免脏读、不可重复读、幻读等问题。 Spring事务的传播性事务的传播特性的产生，当多个业务嵌套调用时事务的执行策略，是Spring利用其底层资源特性来实现的。Spring为我们提供了以下其中事务的传播性 PROPAGATION_REQUIRED：必须使用事务，如果当前业务存在一个事务，则加入，如果不存在，则创建一个事务，默认使用此种方式。 PROPAGATION_SUPPORTS：支持事务，如果父业务存在事务，则加入，如果不存在，则不使用事务。 PROPAGATION_MANDATORY：强制使用事务，如果父业务不存在事务，则抛出异常。 PROPAGATION_REQUIRES_NEW：如果当前存在事务，则挂起该事务新建一个事务，如果不存在事务，则同PROPAGATION_REQUIRED PROPAGATION_NOT_SUPPORTED：不支持事务，如果当前存在事务，则挂起，自己不使用事务去执行数据库操作。 PROPAGATION_NEVER：不使用事务，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED：嵌套事务，如果当前存在事务，则开启一个子事务，但是父事务可以控制子事务是否提交和回滚，子事务的回滚父事务可以选择回滚或者提交。如果当前不存在事务，则同PROPAGATION_REQUIRED","categories":[{"name":"Spring","slug":"Spring","permalink":"http://blog.easyjava.xyz/categories/Spring/"}],"tags":[{"name":"事务","slug":"事务","permalink":"http://blog.easyjava.xyz/tags/事务/"},{"name":"Spring","slug":"Spring","permalink":"http://blog.easyjava.xyz/tags/Spring/"}]},{"title":"Linux下MySQL安装","slug":"Linux下MySQL安装","date":"2019-11-10T09:49:20.000Z","updated":"2020-02-11T01:07:11.889Z","comments":true,"path":"2019/11/10/Linux下MySQL安装/","link":"","permalink":"http://blog.easyjava.xyz/2019/11/10/Linux下MySQL安装/","excerpt":"","text":"准备Linux CentOS 7 x64mysql-5.7.27 下载 卸载MariaDB[root@MiWiFi-R3L-srv downloads]# rpm -qa|grep mariadb mariadb-libs-5.5.52-1.el7.x86_64 [root@MiWiFi-R3L-srv downloads]# rpm -e mariadb-libs-5.5.52-1.el7.x86_64 --nodeps 安装MySQL解压MySQL [root@MiWiFi-R3L-srv developer]# tar -xvf ../downloads/mysql-5.7.27-1.el7.x86_64.rpm-bundle.tar -C /env/developer/mysql mysql-community-libs-5.7.27-1.el7.x86_64.rpm mysql-community-embedded-devel-5.7.27-1.el7.x86_64.rpm mysql-community-libs-compat-5.7.27-1.el7.x86_64.rpm mysql-community-devel-5.7.27-1.el7.x86_64.rpm mysql-community-embedded-compat-5.7.27-1.el7.x86_64.rpm mysql-community-common-5.7.27-1.el7.x86_64.rpm mysql-community-client-5.7.27-1.el7.x86_64.rpm mysql-community-server-5.7.27-1.el7.x86_64.rpm mysql-community-test-5.7.27-1.el7.x86_64.rpm mysql-community-embedded-5.7.27-1.el7.x86_64.rpm 安装顺序一定是common、libs、client、server，接下来，开始吧。 [root@MiWiFi-R3L-srv mysql]# rpm -ivh mysql-community-common-5.7.27-1.el7.x86_64.rpm 警告：mysql-community-common-5.7.27-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY 准备中... ################################# [100%] 正在升级/安装... 1:mysql-community-common-5.7.27-1.e################################# [100%] [root@MiWiFi-R3L-srv mysql]# rpm -ivh mysql-community-libs-5.7.27-1.el7.x86_64.rpm 警告：mysql-community-libs-5.7.27-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY 准备中... ################################# [100%] 正在升级/安装... 1:mysql-community-libs-5.7.27-1.el7################################# [100%] [root@MiWiFi-R3L-srv mysql]# rpm -ivh mysql-community-client-5.7.27-1.el7.x86_64.rpm 警告：mysql-community-client-5.7.27-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY 准备中... ################################# [100%] 正在升级/安装... 1:mysql-community-client-5.7.27-1.e################################# [100%] 在安装server的时候，报错如下： [root@MiWiFi-R3L-srv mysql]# rpm -ivh mysql-community-server-5.7.27-1.el7.x86_64.rpm 警告：mysql-community-server-5.7.27-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY 错误：依赖检测失败： /usr/bin/perl 被 mysql-community-server-5.7.27-1.el7.x86_64 需要 net-tools 被 mysql-community-server-5.7.27-1.el7.x86_64 需要 perl(Getopt::Long) 被 mysql-community-server-5.7.27-1.el7.x86_64 需要 perl(strict) 被 mysql-community-server-5.7.27-1.el7.x86_64 需要 可见server安装需要依赖perl、net-tools，我们使用yum -y install perl、yum -y install net-tools安装完成后，我们再执行 [root@MiWiFi-R3L-srv mysql]# rpm -ivh mysql-community-server-5.7.27-1.el7.x86_64.rpm 警告：mysql-community-server-5.7.27-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY 准备中... ################################# [100%] 正在升级/安装... 1:mysql-community-server-5.7.27-1.e################################# [100%] 到此，MySQL已经安装完成 配置MySQL执行mysqld --initialize --user=mysql，其中--initialize参数表示以安全模式初始化，则会在日志文件中生成一个密码，用户在登录数据库过后需要将其修改为自己的密码，相反--initialize-insecure表示非安全模式，则不会生成临时密码。--user=mysql是为了保证数据库目录为与文件的所有者为mysql登陆用户，如果是root身份运行mysql服务，则需要，如果是以mysql身份运行，则可以去掉–user选项。 [root@MiWiFi-R3L-srv /]# cat /var/log/mysqld.log 2019-11-10T11:08:27.878852Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details). 2019-11-10T11:08:29.654413Z 0 [Warning] InnoDB: New log files created, LSN=45790 2019-11-10T11:08:29.914439Z 0 [Warning] InnoDB: Creating foreign key constraint system tables. 2019-11-10T11:08:30.008176Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 6d3a480f-03aa-11ea-a2ef-00e0b41ce34d. 2019-11-10T11:08:30.012039Z 0 [Warning] Gtid table is not ready to be used. Table 'mysql.gtid_executed' cannot be opened. 2019-11-10T11:08:30.014895Z 1 [Note] A temporary password is generated for root@localhost: eFZcxogD#6.i 启动MySQL现在启动mysql数据库systemctl start mysqld.service，也可以将MySQL设置为开机自动启动systemctl enable mysqld.service,然后连接到MySQL修改密码mysql -uroot -p这里必须修改密码，否则将无法使用 mysql> show database; ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'database' at line 1 更改密码 mysql> ALTER USER 'root'@'localhost' IDENTIFIED BY 'cjwan1314+'; Query OK, 0 rows affected (0.00 sec) 开启防火墙查询端口是否开放firewall-cmd --query-port=3306/tcp开放端口firewall-cmd --zone=public --add-port=3306/tcp --permanent重启防火墙systemctl restart firewalld.service MySQL安装到此完毕！！","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.easyjava.xyz/categories/MySQL/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.easyjava.xyz/tags/Linux/"},{"name":"MySQL","slug":"MySQL","permalink":"http://blog.easyjava.xyz/tags/MySQL/"}]},{"title":"Linux硬盘分区删除、创建、格式化、磁盘挂载","slug":"Linux硬盘分区删除、创建、格式化、磁盘挂载","date":"2019-11-10T07:30:58.000Z","updated":"2020-02-11T01:07:11.890Z","comments":true,"path":"2019/11/10/Linux硬盘分区删除、创建、格式化、磁盘挂载/","link":"","permalink":"http://blog.easyjava.xyz/2019/11/10/Linux硬盘分区删除、创建、格式化、磁盘挂载/","excerpt":"","text":"Linux作为日常应用服务器，它的稳定性直接决定着业务的可靠性。今天探讨的是Linux磁盘的扩容。磁盘扩容大致有以下几个步骤：插入磁盘，建立分区，格式化分区，磁盘挂载 建立分区输入fdisk -l，该命令可以看到当前系统有哪些磁盘，这些磁盘的容量，分区，磁盘的逻辑名称。 [root@MiWiFi-R3L-srv env]# fdisk -l 磁盘 /dev/sdb：160.0 GB, 160041885696 字节，312581808 个扇区 Units = 扇区 of 1 * 512 = 512 bytes 扇区大小(逻辑/物理)：512 字节 / 512 字节 I/O 大小(最小/最佳)：512 字节 / 512 字节 磁盘标签类型：dos 磁盘标识符：0x8e502bee 设备 Boot Start End Blocks Id System /dev/sdb1 2048 312581807 156289880 83 Linux WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. 磁盘 /dev/sda：16.0 GB, 16013942784 字节，31277232 个扇区 Units = 扇区 of 1 * 512 = 512 bytes 扇区大小(逻辑/物理)：512 字节 / 512 字节 I/O 大小(最小/最佳)：512 字节 / 512 字节 磁盘标签类型：gpt # Start End Size Type Name 1 2048 411647 200M EFI System EFI System Partition 2 411648 2508799 1G Microsoft basic 3 2508800 31277055 13.7G Linux LVM 得到需要分区的磁盘名称过后，输入fdisk /dev/sdb，该命令可以查询有创建分区等等 [root@MiWiFi-R3L-srv env]# fdisk /dev/sdb 欢迎使用 fdisk (util-linux 2.23.2)。 更改将停留在内存中，直到您决定将更改写入磁盘。 使用写入命令前请三思。 命令(输入 m 获取帮助)：m 命令操作 a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition g create a new empty GPT partition table G create an IRIX (SGI) partition table l list known partition types m print this menu n add a new partition o create a new empty DOS partition table p print the partition table q quit without saving changes s create a new empty Sun disklabel t change a partition's system id u change display/entry units v verify the partition table w write table to disk and exit x extra functionality (experts only) 命令(输入 m 获取帮助)：p 磁盘 /dev/sdb：160.0 GB, 160041885696 字节，312581808 个扇区 Units = 扇区 of 1 * 512 = 512 bytes 扇区大小(逻辑/物理)：512 字节 / 512 字节 I/O 大小(最小/最佳)：512 字节 / 512 字节 磁盘标签类型：dos 磁盘标识符：0x8e502bee 设备 Boot Start End Blocks Id System /dev/sdb1 2048 312581807 156289880 83 Linux 命令(输入 m 获取帮助)：n Partition type: p primary (1 primary, 0 extended, 3 free) e extended Select (default p): p 分区号 (2-4，默认 2)： 在该命令中，输入m查看帮助，n：创建，在创建模式下输入p，表示创建新分区，然后输入分区编号和起始大小，w保存当前分区。 格式化分区输入mkfs.ext4 /dev/sdb1，这里的ext4表示文件系统格式。注意：只有格式化了的分区，才会生成磁盘UUID 挂载磁盘分区有的同学误认为（我之前是这样认为的）将磁盘插入服务器过后，分好区并格式化过后就可以了，其实这个时候并没有真正被使用。我们还需要将某个磁盘分区挂载到某个文件夹输入命令mount /dev/sdb1 /env，表示将/dev/sdb1挂载到/env目录，这个时候我们使用df就可以看到/dev/sdb1被挂载到/env目录了 [root@MiWiFi-R3L-srv env]# df 文件系统 1K-块 已用 可用 已用% 挂载点 /dev/mapper/cl-root 12806144 969624 11836520 8% / devtmpfs 1874080 0 1874080 0% /dev tmpfs 1885416 0 1885416 0% /dev/shm tmpfs 1885416 8716 1876700 1% /run tmpfs 1885416 0 1885416 0% /sys/fs/cgroup /dev/sda2 1038336 134652 903684 13% /boot /dev/sda1 204580 9672 194908 5% /boot/efi /dev/sdb1 153704800 61464 145812460 1% /env tmpfs 377084 0 377084 0% /run/user/0 OK，大功告成，但是当服务器重启过后，挂载点将会消失。怎么办呢，我们可以将其设置为开机自动挂载首先查看磁盘分区的UUIDblkid，将看到如下信息 [root@MiWiFi-R3L-srv env]# blkid /dev/mapper/cl-root: UUID=\"0ebb80a1-9ec8-41c4-86dc-45ae67c55de9\" TYPE=\"xfs\" /dev/sda3: UUID=\"d7HW9s-WSz0-Bjuz-CLIo-3l6A-HZvX-aeLQ59\" TYPE=\"LVM2_member\" PARTUUID=\"bfa0e4d2-8885-47e9-bf84-30349637ecc3\" /dev/sda2: UUID=\"4cd8b6a8-8e73-4ec4-9b92-ff481c2e86d2\" TYPE=\"xfs\" PARTUUID=\"f3757ea1-b200-4b58-b090-b80b3fd0a64b\" /dev/sda1: SEC_TYPE=\"msdos\" UUID=\"BA05-713D\" TYPE=\"vfat\" PARTLABEL=\"EFI System Partition\" PARTUUID=\"54e1380d-0f9a-4951-a82a-03bdfb51baea\" /dev/mapper/cl-swap: UUID=\"4140b465-c638-4008-83c2-80c58e4340e3\" TYPE=\"swap\" /dev/sdb1: UUID=\"a1d5ba39-8bb7-4e26-9946-22dc5368ac85\" TYPE=\"ext4\" /dev/sdb1: UUID=”a1d5ba39-8bb7-4e26-9946-22dc5368ac85” TYPE=”ext4”，其中a1d5ba39-8bb7-4e26-9946-22dc5368ac85就是磁盘的UUID，复制一下，在/etc/fstab文件中添加记录 UUID=a1d5ba39-8bb7-4e26-9946-22dc5368ac85 /env ext4 defaults 1 1 reboot重启，完成。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.easyjava.xyz/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.easyjava.xyz/tags/Linux/"},{"name":"分区","slug":"分区","permalink":"http://blog.easyjava.xyz/tags/分区/"},{"name":"磁盘挂载","slug":"磁盘挂载","permalink":"http://blog.easyjava.xyz/tags/磁盘挂载/"}]},{"title":"Zookeeper基本使用及原理分析","slug":"Zookeeper基本使用及原理分析","date":"2019-11-08T03:09:47.000Z","updated":"2020-02-11T01:07:11.900Z","comments":true,"path":"2019/11/08/Zookeeper基本使用及原理分析/","link":"","permalink":"http://blog.easyjava.xyz/2019/11/08/Zookeeper基本使用及原理分析/","excerpt":"","text":"Zookeeper相信大家都不陌生，应用场景也颇为广泛，注册中心、配置中心、分布式锁这些场景都有它的身影。 Zookeeper是什么Zookeeper是一个分布式协调服务，由雅虎创建，最初的目标是解决分布式服务有序性问题，例如分布式锁，虽然分布式服务协调的问题解决了，单Zookeeper本身的单点问题出现了，所以就有了Zookeeper集群来达到Zookeeper本省的高可用性，那么Zookeeper集群节点间的数据同步该如何解决呢？ Zookeeper安装单机模式 Zookeeper下载 解压tar -zxvf zookeeper-3.4.14.tar.gz 将config文件夹下的zoo_simple.conf修改为zoo.conf 启动Zookeeper sh bin/zkServer.sh start 集群模式 在Zookeeper工作目录（zoo.conf配置文件汇总的dataDir指定的目录）下创建myid文件，配置当前集群id 在zoo.conf配置文件中加入server.id=ip port1 port2，其中id为Zookeeper id，ip为Zookeeper IP，port1为数据同步通信所使用的端口，port2为leader选举所使用的端口，例如：server.1 192.168.3.207 2888 3888注意：第一次启动一个节点时，会报错，原因是没有其他的节点存在 Zookeeper配置项解释 tickTime：Zookeeper服务器和客户端之间的心跳间隔，单位毫秒 initTime：集群模式下服务器接受客户端（这里的客户端并不是客户端连接Zookeeper的客户端，而是follower节点和leader节点中的follower节点）连接的最长心跳次数 dataDir：Zookeeper的数据存储目录 clientPort：对外暴露的客户端连接端口，默认是2181 syncLimit：leader节点和follower节点之间的数据同步超时时间长度，最长不能超过多少个心跳次数 server：集群模式下所有节点信息配置 节点属性通过get命令可以看到Zookeeper的节点属性 [zk: localhost:2181(CONNECTED) 2] get /zookeeper cZxid = 0x0 ctime = Thu Jan 01 08:00:00 CST 1970 mZxid = 0x0 mtime = Thu Jan 01 08:00:00 CST 1970 pZxid = 0x0 cversion = -1 dataVersion = 0 aclVersion = 0 ephemeralOwner = 0x0 dataLength = 0 numChildren = 1 Zxid cZxid：该节点创建时间所对应的格式时间戳 mZxid：该节点修改时间所对应的格式时间戳，若该节点没有经过修改，则mZxid和cZxid对应。 pZxid：该节点和该节点的子节点（不包含孙子节点）的创建和删除时间所对应的格式时间戳Zxid是一个64位的数字，高32位标注epoch，低32位自增（每一个事务操作递增） version版本号 cversion：子节点版本号 dataVersion：节点数据版本号 aclVersion：节点所拥有的权限版本号 time时间 ctime：当前节点创建时间 mtime：当前节点修改时间 其他 ephemeralOwner：临时节点sessionId，如果该节点是临时节点，则该值为客户端和服务器之间的会话ID，如果该节点不是临时节点，该值为0 dataLength：当前节点数据长度 numChildren：子节点数量 Zookeeper节点特性 持久化节点 临时节点 有序节点（有序节点可以是持久化的也可以是临时的） 同级节点下名称必须统一 临时节点下不允许有子节点 集群模式下的数据同步Zookeeper集群中各个节点都是可以接受客户端请求的，Zookeeper会在每次事务请求提交完毕过后将数据同步到所有follower或者observer节点上，当客户端发送一个读的请求时，Zookeeper直接从当前节点返回数据给客户端。当客户端发送的是写请求时，Zookeeper会将写的请求转发给leader节点，进行事务性操作，完成后将数据同步到所有follower和observer节点上。 集群角色 leader：整个集群中唯一调度和处理者，保证集群事务处理顺序性。 follower：处理客户端非事务请求和转发事务请求，参与事务请求投票，参与leader选举投票 observer：可提升集群性能，不参与任何形式的投票（包括事务请求和leader选举投票） Zookeeper改进版2PC提交2PC在分布式系统中，处理分布式事务有很多种方式，最常见的就是两阶段提交，那么什么是两阶段提交呢？其实两阶段提交就是将一个事务性操作拆分成两个阶段提交事务请求和执行事务提交 提交事务请求：TM（事务管理器）将事务操作转发给当前业务的所有事务参与者，然后等待其相应，AP（事务参与者）在收到请求过后去执行事务操作，并将Undo和Redo写入到事务日志中，最后反馈给TM是否能执行该事务。 执行事务提交：TM收到各个事务参与者的返回过后，通过反馈来决定提交或者回滚事务，如果所有参与者返回的ACK为可执行，则提交该事务，如果有一个参与者返回ACK为不能执行，则回滚该事务。 ZAB协议ZAB(Zookeeper Atomic Broadcast，Zookeeper原子广播)协议是Zookeeper专门设计用于处理崩溃恢复的原子广播协议，在Zookeeper中，主要依赖ZAB来实现数据一致性问题。ZAB协议包含两种基本模式： 崩溃恢复 原子广播当整个的leader节点出现宕机或者说集群启动的时候，Zookeeper会进入崩溃恢复模式，在重新选举出新的leader过后，有超过半数以上的节点完成数据通过过后，Zookeeper会进入原子广播模式进行数据同步。 崩溃恢复原理集群中一旦leader几点出现宕机或者由于网络原因leader节点和其他follower节点失去联系已经超过半数以上，那么Zookeeper会认为该leader已经不合法了，就会重新选举出一个新的leader，为了使leader挂了过后系统能过正常工作，ZAB协议需要解决一下两个问题 已经处理的消息不能丢失当leader在收到所有follower的事务反馈ACK后发送commit指令时宕机，假如向follower1发送commit成功过后宕机，这个时候follower1已经执行了该事务请求，而follower2并没有收到，这个时候ZAB需要重新选举新的leader并且保证该事务请求需要被所有节点所执行。 被丢弃的消息不能再次出现当leader在收到客户端的事务请求生成proposal过后出现宕机，这个时候这个事务性消息并没有被广播出去，所有的follower节点均没有收到来自leader的事务请求，这个时候ZAB需要保证新选举的leader需要将该事务请求要被丢弃，就算是原来的leader重启注册完成过后也需要将该proposal丢弃，这样就能和集群保持数据一致。针对以上两个要求，我作出如下假设：如果ZAB的leader选举算法能够保证leader在出现宕机过后选举出目前ZXID最大的follower节点作为leader节点，那么应该就能保证之前已经处理的消息不被丢失，同时，由于每次leader选举，epoch会在原来的基础上自增1（epoch += 1）这样就算旧的leader重启它也不会再被选举成为leader。新的leader会将所有的旧的epoch没有被commit的消息全部清除掉。 原子广播原理当leader在收到消息过后，会给当前消息赋予一个全局唯一的64位自增id(zxid)，后续通过zxid可以实现因果有序的特征。然后将消息广播给所有follower节点，follower将消息写入到磁盘过后给leader返回一个ACK，当集群节点中超过半数以上的节点返回ACK过后，leader会像所有节点发送commit请求。 Leader选举Zookeeper选举方式有多种，默认是fast选举，leader选举有两个场景 集群启动时 leader出现宕机时 服务启动时的leader选举 集群各个节点在启动时，所有节点状态都为LOOKING（节点状态有4中，分别是LOOKING，LEADING，FOLLOWING，OBSERVER） 每个server发出一个投票给集群中的其他节点，例如当前有三个节点，各个节点的基本信息如下： server1:zxid=0,myid=1 server2:zxid=0,myid=2 server3:zxid=0,myid=3server1将投票信息（01）发送给其他两个节点 各个节点在收到投票过后，首先进行校验，如状态校验等 各个节点将自己投票和别人的投票进行PK 首先进行zxid比较，zxid最大的将作为当前集群中的leader 如果zxid一样，则进行myid比较，myid最大的将作为leader对于server1而言，当前自己的投票为01，收到的投票为02，这个时候server1将更新自己的投票数据为02，而对于server2而言，自己的投票为02，收到的投票为01，这个时候server2不需要更新自己的投票。 统计投票，每次投票过后，都会统计投票，只要超过半数以上的节点投票一致，则被投票对象将被选举成为leader 最后改变节点状态，leader节点状态为LEADING，其他节点均为FOLLOWING 运行时Leader选举当集群中的leader宕机或不可用时，这个时候集群已经不能对外提供服务，而是进入新一轮的leader选举，运行时Leader选举和服务启动时的Leader选举过程基本一致，首先会将epoch自增1，然后将所有节点的状态改为LOOKING，进行新一轮的leader选举。","categories":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://blog.easyjava.xyz/categories/Zookeeper/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://blog.easyjava.xyz/tags/Zookeeper/"}]},{"title":"Spring原理分析","slug":"Spring原理分析","date":"2019-11-05T02:18:35.000Z","updated":"2020-02-11T01:07:11.899Z","comments":true,"path":"2019/11/05/Spring原理分析/","link":"","permalink":"http://blog.easyjava.xyz/2019/11/05/Spring原理分析/","excerpt":"","text":"提到Spring，脑海中的第一概念就是IOC（控制反转）、DI（依赖注入）、AOP（面向切面编程），但是在日常编码中，一般的同学都并没有深入了解过这几个概念的实现原理，那么今天就通过分析源码的方式来了解一下。 Spring IOC实现思路什么是IOC将创建对象的控制权交给Spring管理就叫控制反转，说的有点抽象，其实就是让Spring为我们创建管理对象，Spring实现IOC的大致思路如下： 加载配置文件 解析配置文件 注册BeanDefinition 加载配置文件将我们编写的xml配置文件通过类加载、文件、URL等机制加载到内存中 解析配置文件将加载到内存中的配置文件解析成程序能够理解的对象，这里指的是BeanDefinition，Spring支持多种配置文件格式，例如：XML、Properties 注册BeanDefinition将各个BeanDefinition对象注册到IOC容器中，Spring中核心容器是一个Map，使用beanName作为key，BeanDefinition作为value存储 DI基本概念什么是DI从容器中获得某个对象时，当前对象依赖的所有对象一并赋值给当前对象这叫依赖注入 Spring中依赖注入是从getBean开始的，getBean方法大致作用在于将BeanDefinition配置描述对象实例化，然后将依赖的对象递归创建，然后自动注入 循环注入Spring中依赖注入常见循环注入问题，那么什么是循环注入呢？例如：对象A依赖对象B，对象B依赖对象C，对象C依赖对象A，这样就陷入了死循环。那么循环注入该如何避免，Spring中是如何处理循环注入的呢。首先，循环注入常见于两种情况 构造函数循环注入 setter方法循环注入 构造函数循环注入这种方式Spring会抛出BeanCurrentlyInCreationException异常，原因是，当创建对象A的时候，发现构造函数需要依赖B，这个时候A还没有被创建完成，Spring将正在创建中的A对象放到一个正在创建的prototypesCurrentlyInCreation(prototypesCurrentlyInCreation是一个NamedThreadLocal)中，然后继续创建对象B，以此类推，当创建对象C的时候，C对象依赖对象A，这个时候又去创建A，发现prototypesCurrentlyInCreation中存在对象A，这个时候Spring就会抛出BeanCurrentlyInCreationException异常。那么为什么Spring要设计一个正在创建的prototypesCurrentlyInCreation，试想一下，如果Spring不做任何措施，只是单纯的递归创建对象并且自动注入依赖对象，当C对象创建的时候，去注入对象A，这个时候A对象其实并没有完成创建，然后继续创建对象A，如此就陷入了死循环，最终对导致内存溢出。对象在创建完成后从prototypesCurrentlyInCreation中删除。 setter方法循环注入此种方式可以正常完成依赖注入，因为这种方式是先创建对象，再注入依赖对象，拿之前的例子来说，首先创建对象A，发现对象A依赖对象B，这个时候创建对象B，继而创建对象C，在创建完对象C过后，发现对象C依赖对象A，这个时候将已经创建的对象A注入给对象C，所以，这种方式的循环注入并不会出现问题。 SpringMVC实现原理SpringMVC的实现原理可以分为三个阶段，分别是： 配置阶段 初始化阶段 请求执行阶段 配置阶段该阶段主要是配置SpringMVC的核心Servlet以及指定Spring的配置文件位置，配置监听等。 初始化阶段初始化SpringMVC九大组件 this.initMultipartResolver(context); this.initLocaleResolver(context); this.initThemeResolver(context); this.initHandlerMappings(context); this.initHandlerAdapters(context); this.initHandlerExceptionResolvers(context); this.initRequestToViewNameTranslator(context); this.initViewResolvers(context); this.initFlashMapManager(context); 以上组件的作用分别是MultipartResolver：文件处理器LocaleResolver：语言处理器，用于国际化ThemeResolver：主题处理器HandlerMappings：SpringMVC核心请求处理器，简称处理器映射器HandlerAdapters：处理器适配器，用于适配处理器参数，从request中获取参数，自动转型并适配形式参数HandlerExceptionResolvers：异常处理器RequestToViewNameTranslator：视图名称翻译器ViewResolvers：页面渲染处理器FlashMapManager：参数传递管理器 以上最核心的是HandlerMappings、HandlerAdapters、ViewResolvers，HandlerMapping用于管理URI对应的处理器Method，HandlerAdapters用于适配处理器参数，ViewResolvers用于试图渲染 请求执行阶段当SpringMVC应用启动完毕，用户像服务器发送一个请求，首先会通过用户请求的URI进行匹配HandlerMapping，得到HandlerMapping过后，进行参数封装，最后执行方法，最后通过返回的ModelAndView交给ViewResolvers渲染试图 小结SpringMVC的运行流程大致是，配置核心入口DispatcherServlet，初始化HandlerMappings、HandlerAdapters、ViewResolvers，当用户请求时，通过用户请求的URI查找处理器，封装请求参数，执行返回结果，渲染试图。 Spring AOP实现原理Spring中AOP分为两个阶段，第一个阶段为加载和解析配置阶段，第二个阶段为创建代理对象阶段 加载解析配置阶段该阶段主要对AOP的配置进行提起加载解析，在IOC的解析成BeanDefinition的时候进行，其实Spring所有的配置加载都在这一阶段完成，在解析XML配置文件的时候，Spring默认只解析Bean Namespace，当Spring发现配置文件中有引入其他Spring扩展Namespace的时候，Spring会根据配置文件的NamespaceURI进行确定使用哪一个NamespaceHandler来解析当前配置文件中的扩展配置，最后都将封装成一个BeanDefinition然后注册到IOC容器中。值得注意的是，在解析AOP配置的过程中，Spring向容器注册了一个AspectJAwareAdvisorAutoProxyCreator，改类用于创建代理对象。 创建代理对象阶段Spring中不管是创建对象还是依赖注入都是从getBean开始的，通过探究里面真正干活的是AbstractAutowireCapableBeanFactory中的createBean，该方法最终会调到initializeBean，该方法又会调用applyBeanPostProcessorsAfterInitialization方法，在该方法中，会循环调用之前初始化时注册到容器中的所有BeanPostProcessor的postProcessAfterInitialization方法，而AOP在初始化的时候，注册了一个AspectJAwareAdvisorAutoProxyCreator，该类是BeanPostProcessor的子类，所以最终创建代理类的是AspectJAwareAdvisorAutoProxyCreator的父类AbstractAutoProxyCreator的postProcessAfterInitialization方法，在该方法中调用wrapIfNecessary判断是否需要被代理（里面的判断逻辑就是切入点表达式，满足条件的表示该方法被代理），并且应该使用哪种代理方式取决于目标对象是代理接口还是代理类，如果是代理接口则使用JDK动态代理，代理类则使用CGLIB动态代理。代码如下： public class DefaultAopProxyFactory implements AopProxyFactory, Serializable { @Override public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException { if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) { Class&lt;?> targetClass = config.getTargetClass(); if (targetClass == null) { throw new AopConfigException(\"TargetSource cannot determine target class: \" + \"Either an interface or a target is required for proxy creation.\"); } if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) { return new JdkDynamicAopProxy(config); } return new ObjenesisCglibAopProxy(config); } else { return new JdkDynamicAopProxy(config); } } }","categories":[{"name":"Spring","slug":"Spring","permalink":"http://blog.easyjava.xyz/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://blog.easyjava.xyz/tags/Spring/"},{"name":"源码","slug":"源码","permalink":"http://blog.easyjava.xyz/tags/源码/"}]},{"title":"Mybatis中调用存储过程","slug":"Mybatis中调用存储过程","date":"2019-10-12T06:57:54.000Z","updated":"2020-02-11T01:07:11.892Z","comments":true,"path":"2019/10/12/Mybatis中调用存储过程/","link":"","permalink":"http://blog.easyjava.xyz/2019/10/12/Mybatis中调用存储过程/","excerpt":"","text":"很多人对Mybatis调用存储过程模棱两可，不知道该怎么配置，本篇将接受Mybatis如何调用Oracle存储过程（带有入参和出参） 语法需要注意的是调用存储过程的方法应当是select标签，statementType=CALLABLE，这里的parameterType建议必须填写，以免出现问题。 &lt;select id=\"test\" statementType=\"CALLABLE\" parameterType=\"com.juncheng.entity.TestEntity\"> {CALL TEST(#{aa,mode=IN},#{bb,mode=OUT,jdbcType=CURSOR,resultMap=emp},#{cc})} &lt;/select> 参数的mode标识当前参数是入参还是出参，入参使用IN，出参使用OUT，如果即是入参也是出参，可以不用填写 返回值大多数情况下，调用一个存储过程过后，会有返回值，并且这个返回值可能是查询列表，通过OUT参数输出，这个时候存储过程的参数类型应该是游标（SYS_REFCURSOR）类型，在Mybatis中参数的jdbcType=CURSOR，并且需要指定该列表的映射实体resultMap=emp，resultMap代码如下： &lt;resultMap id=\"emp\" type=\"com.juncheng.entity.EmpEntity\"> &lt;id column=\"EMPNO\" property=\"empno\" jdbcType=\"INTEGER\"/> &lt;result column=\"ENAME\" property=\"ename\" jdbcType=\"VARCHAR\"/> &lt;result column=\"JOB\" property=\"job\" jdbcType=\"VARCHAR\"/> &lt;result column=\"MGR\" property=\"mgr\" jdbcType=\"INTEGER\"/> &lt;result column=\"HIREDATE\" property=\"hiredate\" jdbcType=\"TIMESTAMP\"/> &lt;result column=\"SAL\" property=\"sal\" jdbcType=\"INTEGER\"/> &lt;result column=\"COMM\" property=\"comm\" jdbcType=\"INTEGER\"/> &lt;result column=\"DEPTNO\" property=\"deptno\" jdbcType=\"INTEGER\"/> &lt;/resultMap> OUT参数并不是直接通过Mapper接口返回值返回，而是set到参数对象对应的属性中，一般调用存储过程是没有返回值的，所有的OUT参数都返回到Mapper接口的参数中。代码如下： public interface TestMapper { void test(TestEntity entity); } public class TestEntity { private Integer aa; private List&lt;EmpEntity> bb; private Integer cc; //setter getter... } public class EmpEntity { private Integer empno; private String ename; private String job; private Integer mgr; private Date hiredate; private Integer sal; private Integer comm; private Integer deptno; //setter getter... } mybatis-conf.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?> &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"> &lt;configuration> &lt;settings> &lt;setting name=\"mapUnderscoreToCamelCase\" value=\"true\" /> &lt;/settings> &lt;environments default=\"development\"> &lt;environment id=\"development\"> &lt;transactionManager type=\"JDBC\" /> &lt;!-- 配置数据库连接信息 --> &lt;dataSource type=\"POOLED\"> &lt;property name=\"driver\" value=\"oracle.jdbc.driver.OracleDriver\" /> &lt;property name=\"url\" value=\"jdbc:oracle:thin:@127.0.0.1:1521:ORCL\" /> &lt;property name=\"username\" value=\"scott\" /> &lt;property name=\"password\" value=\"scott\" /> &lt;/dataSource> &lt;/environment> &lt;/environments> &lt;mappers> &lt;mapper resource=\"com/juncheng/mapper/TestMapper.xml\">&lt;/mapper> &lt;/mappers> &lt;/configuration> 测试用例，主入口 public class MybatisOracleTest { public static void main(String[] args) throws IOException { String resource = \"mybatis-conf.xml\"; //1.流形式读取mybatis配置文件 InputStream stream = Resources.getResourceAsStream(resource); //2.通过配置文件创建SqlSessionFactory SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(stream); SqlSession sqlSession = factory.openSession(); //以下是测试 TestMapper testMapper = sqlSession.getMapper(TestMapper.class); TestEntity entity = new TestEntity(); entity.setAa(1); entity.setCc(2); testMapper.test(entity); System.out.println(entity); } }","categories":[],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://blog.easyjava.xyz/tags/Mybatis/"},{"name":"存储过程","slug":"存储过程","permalink":"http://blog.easyjava.xyz/tags/存储过程/"},{"name":"Oracle","slug":"Oracle","permalink":"http://blog.easyjava.xyz/tags/Oracle/"}]},{"title":"Docker入门及实战","slug":"Docker入门及实战","date":"2019-10-11T11:46:01.000Z","updated":"2020-02-11T01:07:11.873Z","comments":true,"path":"2019/10/11/Docker入门及实战/","link":"","permalink":"http://blog.easyjava.xyz/2019/10/11/Docker入门及实战/","excerpt":"","text":"我们常常在部署项目的过程中遇到一些莫名其妙的问题，为什么在本地就能跑的项目放到服务器上就跑不起来，这里面的原因有很多，或许是环境的差异导致的，也或许是一些中间件版本不一致导致的，总之，程序本身是没有问题的，这些问题或许在今天能得以解决。 Docker是什么Docker是一个虚拟化的容器，可以看成是一个虚拟化的服务器，但他和服务器的区别是，容器中实际上并没有服务器操作系统，它其实是调用的宿主机的系统内核。 Docker安装这里使用yum安装Docker，默认yum远程仓库中没有docker，所以需要添加repository，添加repository需要用到yum-config-manager，但是在使用yum-config-manager时报找不到该命令，所以需要安装yum-utils步骤如下： 安装yum-utilsyum install -y yum-utils device-mapper-persistent-data lvm2 添加docker yum源yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 安装Docker CE和客户端yum install docker-ce docker-ce-cli containerd.io 启动Dockersystemctl start docker","categories":[{"name":"Docker","slug":"Docker","permalink":"http://blog.easyjava.xyz/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.easyjava.xyz/tags/Docker/"}]},{"title":"Spring中常见的设计模式","slug":"Spring中常见的设计模式","date":"2019-09-20T14:11:31.000Z","updated":"2020-02-11T01:07:11.896Z","comments":true,"path":"2019/09/20/Spring中常见的设计模式/","link":"","permalink":"http://blog.easyjava.xyz/2019/09/20/Spring中常见的设计模式/","excerpt":"","text":"Spring作为Java必选框架，必然有它吸引人之处，不光是实现逻辑的便利性上，还体现在代码质量。可以说，Spring是一个很讲究的框架，似乎不能容忍任何的设计不合理或者追求极致。今天我们就来探讨一下Spring中常用的设计模式 工厂模式概述：只关心产品生产，不做三无产品，spring中常见于BeanFactory，工厂模式也可分为以下几种： 简单工厂：用户需要告诉工厂需要什么产品，由工厂生产 工厂方法：用户根据自己的需求选择相应的工厂 抽象工厂：工厂给出一系列产品族供用户选择 单例模式概述：一个类在程序的生命周期中只会产生一个实例前提：私有化构造方法 饿汉式：不管是否有调用，都会创建一个实例，该方式是线程安全的 懒汉式：当用到实例时，会判断是否已存在该类的实例，如果存在，则直接返回，如果不存在，则创建返回，该方式是线程非安全的，使用时需要考虑线程安全问题，所以效率上会有所差异 注册登记式：在需要单例的类中定义一个map，每次获取实例时在map中get，如果存在，则直接返回，如果不存在，像map中put一个实例，最后返回，spring中单例bean通过该方式实现 枚举式：隶属于注册登记式 序列化和反序列化：通过java的对象序列化实现，类需要实现Seriablizable接口，重写readResovle方法 原型模式概述：将原有对象的属性复制到另一个新的对象中 克隆：实现Cloneable接口，重写clone方法，该方式属于浅克隆（属性中如果包含其他对象，则拷贝其属性对象的引用） 序列化和反序列化：需要实现Seriablizable接口 代理模式概述：为目标类创建一个代理对象，使其业务得到增强 静态代理：一切都是已知的，代理对象须包含目标对象的引用 JDK动态代理：目标对象必须实现接口，生产的代理对象集成自目标对象的所有接口 CGLIB动态代理：通过继承的方式实现代理，CGLIB生产的代理对象继承自目标对象，无需实现任何接口 自定义实现动态代理 动态代理的实现原理（JDK）： 1. 获取目标对象实现的所有接口 2. 动态生成代理java类（实现目标对象的所有接口，增强目标代理方法） 3. 将.java文件编译成.class文件 4. 将字节码文件加载到JVM中 5. 返回代理对象 策略模式概述：用户根据自己的业务逻辑在已存在的一系列算法中选择，切新增算法不会影响原有逻辑，如订单支付，用户可以选择使用支付宝或者微信支付，可以替换掉程序中的switch和if…else if…else…语法 模板模式概述：流程固定，流程中的某一个环节用户可以自定义 JDBC的固定流程如下 加载驱动 建立连接 创建预编译sql语句 执行预编译sql语句 返回结果集 回收资源 以上流程是固定的，无论用户使用哪一种数据库，都会根据上面的步骤执行，但用户可以自定义其中某一个步骤，例如用户可以选择加载oracle驱动或者mysql驱动，结果返回由用户指定结果集接收 委派模式概述：委派模式有些类似于静态代理模式和策略模式，属于静态代理和策略模式中一种特殊的模式 例如老板需要做一个登录的功能，将需求告知给项目经理，项目经理对手上的员工擅长能力都非常了解，项目经理根据员工擅长的领域，选择决定让某一个人来完成这个功能。 这其中项目经理就如同老板的中介，这点有点类似于代理模式中的代理对象，普通员工就是被代理对象，而代理模式中代理对象需要持有被代理对象的引用，而这里的项目经理也需要持有普通员工对象的引用。 项目经理根据员工的擅长领域来做决策，这点类似于策略模式 适配器模式概述：在不改变原有逻辑的情况下扩展（向下兼容），简而言之，将一个类的接口转换成客户端希望的另一个接口 装饰器模式概述：包装者和被包装者都实现同一个接口，且包装者持有被包装者的引用，包装者是被包装者的一种增强，但本质也属于被包装者类型。例如InputStream和DataInputStream的关系 观察者模式概述：被观察者在做完某件事情过后通知观察者，主要是为了解耦","categories":[{"name":"Spring","slug":"Spring","permalink":"http://blog.easyjava.xyz/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://blog.easyjava.xyz/tags/Spring/"},{"name":"设计模式","slug":"设计模式","permalink":"http://blog.easyjava.xyz/tags/设计模式/"}]}]}